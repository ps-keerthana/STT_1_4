{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pydriller\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QImKK-nrankA",
        "outputId": "fc13c4b4-c0c5-45ac-ddc4-38fe5185bc8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydriller\n",
            "  Downloading PyDriller-2.9-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.12/dist-packages (from pydriller) (3.1.45)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from pydriller) (2025.2)\n",
            "Requirement already satisfied: types-pytz in /usr/local/lib/python3.12/dist-packages (from pydriller) (2025.2.0.20250809)\n",
            "Collecting lizard (from pydriller)\n",
            "  Downloading lizard-1.17.31-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython->pydriller) (4.0.12)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from lizard->pydriller) (2.19.2)\n",
            "Collecting pathspec (from lizard->pydriller)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython->pydriller) (5.0.2)\n",
            "Downloading PyDriller-2.9-py3-none-any.whl (36 kB)\n",
            "Downloading lizard-1.17.31-py2.py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: pathspec, lizard, pydriller\n",
            "Successfully installed lizard-1.17.31 pathspec-0.12.1 pydriller-2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydriller import Repository\n",
        "import pandas as pd\n",
        "import csv\n",
        "import subprocess\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------- Helper Functions ----------\n",
        "\n",
        "# Run histogram diff\n",
        "def get_hist_diff(repo_path, commit_hash, file_path):\n",
        "    if file_path is None or file_path == \"nan\":\n",
        "        return \"\"\n",
        "    try:\n",
        "        cmd = [\n",
        "            \"git\", \"-C\", repo_path, \"diff\", \"--histogram\",\n",
        "            f\"{commit_hash}^\", commit_hash, \"--\", file_path\n",
        "        ]\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "        return result.stdout\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Clean diff: remove metadata lines, normalize whitespace\n",
        "def clean_diff(diff_str):\n",
        "    cleaned = []\n",
        "    for line in str(diff_str).splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        # Skip diff metadata lines\n",
        "        if line.startswith(\"diff --git\") or line.startswith(\"index \") \\\n",
        "           or line.startswith(\"---\") or line.startswith(\"+++\") \\\n",
        "           or line.startswith(\"@@\"):\n",
        "            continue\n",
        "        cleaned.append(line)\n",
        "    return \"\\n\".join(cleaned)\n",
        "\n",
        "# Extract commit diffs\n",
        "def extract_repo_diffs(repo_url, local_path, output_csv, repo_name):\n",
        "    # Clone repo if not present\n",
        "    if not os.path.exists(local_path):\n",
        "        print(f\"Cloning {repo_name}...\")\n",
        "        subprocess.run([\"git\", \"clone\", repo_url, local_path])\n",
        "\n",
        "    with open(output_csv, 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            \"repo_name\",\n",
        "            \"old_file_path\", \"new_file_path\",\n",
        "            \"commit_sha\", \"parent_commit_sha\",\n",
        "            \"commit_message\",\n",
        "            \"diff_myers\", \"diff_hist\",\n",
        "            \"file_type\"\n",
        "        ])\n",
        "\n",
        "        for commit in Repository(local_path).traverse_commits():\n",
        "            parent_commits = commit.parents if commit.parents else [\"None\"]\n",
        "            parent_str = \";\".join(parent_commits)\n",
        "\n",
        "            for modified_file in commit.modified_files:\n",
        "                diff_myers = modified_file.diff if modified_file.diff else \"\"\n",
        "                diff_hist = get_hist_diff(local_path, commit.hash, modified_file.new_path)\n",
        "\n",
        "                # Categorize file type\n",
        "                file_path = str(modified_file.new_path).lower() if modified_file.new_path else \"\"\n",
        "                if \"test\" in file_path:\n",
        "                    ftype = \"test\"\n",
        "                elif \"readme\" in file_path:\n",
        "                    ftype = \"readme\"\n",
        "                elif \"license\" in file_path:\n",
        "                    ftype = \"license\"\n",
        "                else:\n",
        "                    ftype = \"source\"\n",
        "\n",
        "                writer.writerow([\n",
        "                    repo_name,\n",
        "                    modified_file.old_path,\n",
        "                    modified_file.new_path,\n",
        "                    commit.hash,\n",
        "                    parent_str,\n",
        "                    commit.msg,\n",
        "                    diff_myers,\n",
        "                    diff_hist,\n",
        "                    ftype\n",
        "                ])\n",
        "\n",
        "# Add discrepancy column\n",
        "def add_discrepancy(input_csv, output_csv):\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    df[\"Discrepancy\"] = [\n",
        "        \"No\" if clean_diff(row[\"diff_myers\"]) == clean_diff(row[\"diff_hist\"]) else \"Yes\"\n",
        "        for _, row in df.iterrows()\n",
        "    ]\n",
        "\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    return df\n",
        "\n",
        "# Generate stats + plot\n",
        "def generate_stats_plot(df, repo_name):\n",
        "    categories = {\"source\": 0, \"test\": 0, \"readme\": 0, \"license\": 0}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        if row[\"Discrepancy\"] == \"Yes\":\n",
        "            ftype = row[\"file_type\"]\n",
        "            if ftype in categories:\n",
        "                categories[ftype] += 1\n",
        "\n",
        "    # Print per file type\n",
        "    print(f\"\\nDiscrepancy counts per file type ({repo_name}):\")\n",
        "    for k, v in categories.items():\n",
        "        print(f\"{k.capitalize()} files: {v}\")\n",
        "\n",
        "    # Plot\n",
        "    plt.bar(categories.keys(), categories.values())\n",
        "    plt.title(f\"Diff Mismatches in {repo_name}\")\n",
        "    plt.xlabel(\"File Type\")\n",
        "    plt.ylabel(\"Mismatches (#)\")\n",
        "    plt.show()\n",
        "\n",
        "# ---------- Main ----------\n",
        "\n",
        "# List of 3 repos with local folder names\n",
        "repos = [\n",
        "    {\"url\": \"https://github.com/AI-Hypercomputer/maxtext\", \"local\": \"maxtext\", \"name\": \"maxtext\"},\n",
        "    {\"url\": \"https://github.com/ai4finance-foundation/elegantrl\", \"local\": \"elegantrl\", \"name\": \"elegantrl\"},\n",
        "    {\"url\": \"https://github.com/assafelovic/gpt-researcher\", \"local\": \"gpt_researcher\", \"name\": \"flask\"}\n",
        "]\n",
        "\n",
        "for repo in repos:\n",
        "    raw_csv = f\"{repo['name']}_diffs.csv\"\n",
        "    final_csv = f\"{repo['name']}_final.csv\"\n",
        "\n",
        "    extract_repo_diffs(repo[\"url\"], repo[\"local\"], raw_csv, repo[\"name\"])\n",
        "    df_final = add_discrepancy(raw_csv, final_csv)\n",
        "\n",
        "    # Overall discrepancy counts\n",
        "    print(f\"\\nOverall Discrepancy counts ({repo['name']}):\")\n",
        "    print(df_final[\"Discrepancy\"].value_counts())\n",
        "\n",
        "    # Per file type stats + plot\n",
        "    generate_stats_plot(df_final, repo[\"name\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QU3uCSOLafiz",
        "outputId": "ee5ed542-c4a3-4ac5-f217-f632427dd7ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning maxtext...\n",
            "\n",
            "Overall Discrepancy counts (maxtext):\n",
            "Discrepancy\n",
            "No     6669\n",
            "Yes    3058\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Discrepancy counts per file type (maxtext):\n",
            "Source files: 2288\n",
            "Test files: 686\n",
            "Readme files: 83\n",
            "License files: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning elegantrl...\n",
            "\n",
            "Overall Discrepancy counts (elegantrl):\n",
            "Discrepancy\n",
            "Yes    6734\n",
            "No     3472\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Discrepancy counts per file type (elegantrl):\n",
            "Source files: 6581\n",
            "Test files: 60\n",
            "Readme files: 54\n",
            "License files: 39\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning flask...\n",
            "\n",
            "Overall Discrepancy counts (flask):\n",
            "Discrepancy\n",
            "No     3701\n",
            "Yes    2256\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Discrepancy counts per file type (flask):\n",
            "Source files: 2143\n",
            "Test files: 58\n",
            "Readme files: 46\n",
            "License files: 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for repo in repos:\n",
        "    raw_csv = f\"{repo['name']}_diffs.csv\"\n",
        "    final_csv = f\"{repo['name']}_final.csv\"\n",
        "\n",
        "    extract_repo_diffs(repo[\"url\"], repo[\"local\"], raw_csv, repo[\"name\"])\n",
        "    df_final = add_discrepancy(raw_csv, final_csv)\n",
        "\n",
        "    # Overall Discrepancy counts\n",
        "    print(f\"\\nOverall Discrepancy counts ({repo['name']}):\")\n",
        "    print(df_final[\"Discrepancy\"].value_counts())\n",
        "\n",
        "    # Per file type stats + plot\n",
        "    generate_stats_plot(df_final, repo[\"name\"])\n",
        "\n",
        "    # --- Algorithm comparison (inside loop) ---\n",
        "    mismatch_df = df_final[df_final[\"Discrepancy\"] == \"Yes\"].copy()\n",
        "    mismatch_df[\"len_myers\"] = mismatch_df[\"diff_myers\"].apply(lambda x: len(str(x).splitlines()))\n",
        "    mismatch_df[\"len_hist\"] = mismatch_df[\"diff_hist\"].apply(lambda x: len(str(x).splitlines()))\n",
        "\n",
        "    avg_myers_len = mismatch_df[\"len_myers\"].mean()\n",
        "    avg_hist_len = mismatch_df[\"len_hist\"].mean()\n",
        "\n",
        "    print(f\"\\nAlgorithm comparison ({repo['name']}):\")\n",
        "    print(f\"Average lines in Myers diffs (for mismatches): {avg_myers_len:.2f}\")\n",
        "    print(f\"Average lines in Histogram diffs (for mismatches): {avg_hist_len:.2f}\")\n",
        "\n",
        "    if avg_myers_len < avg_hist_len:\n",
        "        print(\"Suggestion: Myers diff might be closer to actual code changes.\\n\")\n",
        "    elif avg_hist_len < avg_myers_len:\n",
        "        print(\"Suggestion: Histogram diff might be closer to actual code changes.\\n\")\n",
        "    else:\n",
        "        print(\"Both algorithms perform similarly for this repo.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YkuvG3OEcbMc",
        "outputId": "a80291e3-72a9-4501-de9f-976a52d95257"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall Discrepancy counts (maxtext):\n",
            "Discrepancy\n",
            "No     6669\n",
            "Yes    3058\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Discrepancy counts per file type (maxtext):\n",
            "Source files: 2288\n",
            "Test files: 686\n",
            "Readme files: 83\n",
            "License files: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Algorithm comparison (maxtext):\n",
            "Average lines in Myers diffs (for mismatches): 390.43\n",
            "Average lines in Histogram diffs (for mismatches): 537.61\n",
            "Suggestion: Myers diff might be closer to actual code changes.\n",
            "\n",
            "\n",
            "Overall Discrepancy counts (elegantrl):\n",
            "Discrepancy\n",
            "Yes    6734\n",
            "No     3472\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Discrepancy counts per file type (elegantrl):\n",
            "Source files: 6581\n",
            "Test files: 60\n",
            "Readme files: 54\n",
            "License files: 39\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Algorithm comparison (elegantrl):\n",
            "Average lines in Myers diffs (for mismatches): 904.05\n",
            "Average lines in Histogram diffs (for mismatches): 942.19\n",
            "Suggestion: Myers diff might be closer to actual code changes.\n",
            "\n",
            "\n",
            "Overall Discrepancy counts (flask):\n",
            "Discrepancy\n",
            "No     3701\n",
            "Yes    2256\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Discrepancy counts per file type (flask):\n",
            "Source files: 2143\n",
            "Test files: 58\n",
            "Readme files: 46\n",
            "License files: 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Algorithm comparison (flask):\n",
            "Average lines in Myers diffs (for mismatches): 173.34\n",
            "Average lines in Histogram diffs (for mismatches): 312.88\n",
            "Suggestion: Myers diff might be closer to actual code changes.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "repos = [\n",
        "    {\"name\": \"maxtext\", \"csv\": \"maxtext_final.csv\"},\n",
        "    {\"name\": \"elegantrl\", \"csv\": \"elegantrl_final.csv\"},\n",
        "    {\"name\": \"gpt_researcher\", \"csv\": \"flask_final.csv\"}\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(len(repos), 4, figsize=(18, 12))\n",
        "plt.subplots_adjust(wspace=0.3, hspace=0.4)\n",
        "\n",
        "for i, repo in enumerate(repos):\n",
        "    df = pd.read_csv(repo[\"csv\"])\n",
        "\n",
        "    # ✅ 1. Pie chart\n",
        "    df[\"Discrepancy\"].value_counts().plot.pie(\n",
        "        autopct=\"%1.1f%%\", startangle=90, ax=axes[i, 0], colors=[\"lightgreen\", \"salmon\"]\n",
        "    )\n",
        "    axes[i, 0].set_title(f\"{repo['name']} - Discrepancy Ratio\")\n",
        "    axes[i, 0].set_ylabel(\"\")\n",
        "\n",
        "    # ✅ 2. Grouped bar chart (avg diff length)\n",
        "    mismatch_df = df[df[\"Discrepancy\"] == \"Yes\"].copy()\n",
        "    mismatch_df[\"len_myers\"] = mismatch_df[\"diff_myers\"].apply(lambda x: len(str(x).splitlines()))\n",
        "    mismatch_df[\"len_hist\"] = mismatch_df[\"diff_hist\"].apply(lambda x: len(str(x).splitlines()))\n",
        "\n",
        "    avg_vals = {\n",
        "        \"Myers\": mismatch_df[\"len_myers\"].mean(),\n",
        "        \"Histogram\": mismatch_df[\"len_hist\"].mean()\n",
        "    }\n",
        "    axes[i, 1].bar(avg_vals.keys(), avg_vals.values(), color=[\"skyblue\", \"orange\"])\n",
        "    axes[i, 1].set_title(f\"{repo['name']} - Avg Diff Lengths\")\n",
        "    axes[i, 1].set_ylabel(\"Avg Lines Changed\")\n",
        "\n",
        "    # ✅ 3. Boxplot (diff length distribution)\n",
        "    long_df = pd.melt(\n",
        "        mismatch_df[[\"len_myers\", \"len_hist\"]],\n",
        "        var_name=\"Algorithm\", value_name=\"Diff Length\"\n",
        "    )\n",
        "    sns.boxplot(x=\"Algorithm\", y=\"Diff Length\", data=long_df, ax=axes[i, 2], palette=\"Set2\")\n",
        "    axes[i, 2].set_title(f\"{repo['name']} - Diff Length Spread\")\n",
        "\n",
        "    # ✅ 4. Heatmap (file type vs discrepancy)\n",
        "    heat_data = pd.crosstab(df[\"file_type\"], df[\"Discrepancy\"])\n",
        "    sns.heatmap(heat_data, annot=True, cmap=\"Blues\", fmt=\"d\", ax=axes[i, 3], cbar=False)\n",
        "    axes[i, 3].set_title(f\"{repo['name']} - File Type vs Discrepancy\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iAQREvETixQ1",
        "outputId": "dcfba25b-fc70-4514-966f-d35354348461"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3035123983.py:42: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"Algorithm\", y=\"Diff Length\", data=long_df, ax=axes[i, 2], palette=\"Set2\")\n",
            "/tmp/ipython-input-3035123983.py:42: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"Algorithm\", y=\"Diff Length\", data=long_df, ax=axes[i, 2], palette=\"Set2\")\n",
            "/tmp/ipython-input-3035123983.py:42: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"Algorithm\", y=\"Diff Length\", data=long_df, ax=axes[i, 2], palette=\"Set2\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1200 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/maxtext_diffs.csv\")\n",
        "pd.set_option(\"display.max_colwidth\", None)  # Show full commit messages and diffs\n",
        "display(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5268
        },
        "id": "XQ1_3czxg6fv",
        "outputId": "af597696-2273-46ea-df42-d672da98422e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  repo_name old_file_path              new_file_path  \\\n",
              "0   maxtext           NaN                    LICENSE   \n",
              "1   maxtext           NaN                 .gitignore   \n",
              "2   maxtext           NaN        MaxText/__init__.py   \n",
              "3   maxtext           NaN          MaxText/config.py   \n",
              "4   maxtext           NaN  MaxText/input_pipeline.py   \n",
              "\n",
              "                                 commit_sha  \\\n",
              "0  696b089f888e57a468184d382e56b862985640f2   \n",
              "1  ef558122cde2877c82671fe23fa2ab408552c522   \n",
              "2  ef558122cde2877c82671fe23fa2ab408552c522   \n",
              "3  ef558122cde2877c82671fe23fa2ab408552c522   \n",
              "4  ef558122cde2877c82671fe23fa2ab408552c522   \n",
              "\n",
              "                          parent_commit_sha  \\\n",
              "0                                       NaN   \n",
              "1  696b089f888e57a468184d382e56b862985640f2   \n",
              "2  696b089f888e57a468184d382e56b862985640f2   \n",
              "3  696b089f888e57a468184d382e56b862985640f2   \n",
              "4  696b089f888e57a468184d382e56b862985640f2   \n",
              "\n",
              "                                            commit_message  \\\n",
              "0                                           Initial commit   \n",
              "1  Hard-forking a codebase generously shared by Anselm/JET   \n",
              "2  Hard-forking a codebase generously shared by Anselm/JET   \n",
              "3  Hard-forking a codebase generously shared by Anselm/JET   \n",
              "4  Hard-forking a codebase generously shared by Anselm/JET   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    diff_myers  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           @@ -0,0 +1,201 @@\\n+                                 Apache License\\n+                           Version 2.0, January 2004\\n+                        http://www.apache.org/licenses/\\n+\\n+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n+\\n+   1. Definitions.\\n+\\n+      \"License\" shall mean the terms and conditions for use, reproduction,\\n+      and distribution as defined by Sections 1 through 9 of this document.\\n+\\n+      \"Licensor\" shall mean the copyright owner or entity authorized by\\n+      the copyright owner that is granting the License.\\n+\\n+      \"Legal Entity\" shall mean the union of the acting entity and all\\n+      other entities that control, are controlled by, or are under common\\n+      control with that entity. For the purposes of this definition,\\n+      \"control\" means (i) the power, direct or indirect, to cause the\\n+      direction or management of such entity, whether by contract or\\n+      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n+      outstanding shares, or (iii) beneficial ownership of such entity.\\n+\\n+      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n+      exercising permissions granted by this License.\\n+\\n+      \"Source\" form shall mean the preferred form for making modifications,\\n+      including but not limited to software source code, documentation\\n+      source, and configuration files.\\n+\\n+      \"Object\" form shall mean any form resulting from mechanical\\n+      transformation or translation of a Source form, including but\\n+      not limited to compiled object code, generated documentation,\\n+      and conversions to other media types.\\n+\\n+      \"Work\" shall mean the work of authorship, whether in Source or\\n+      Object form, made available under the License, as indicated by a\\n+      copyright notice that is included in or attached to the work\\n+      (an example is provided in the Appendix below).\\n+\\n+      \"Derivative Works\" shall mean any work, whether in Source or Object\\n+      form, that is based on (or derived from) the Work and for which the\\n+      editorial revisions, annotations, elaborations, or other modifications\\n+      represent, as a whole, an original work of authorship. For the purposes\\n+      of this License, Derivative Works shall not include works that remain\\n+      separable from, or merely link (or bind by name) to the interfaces of,\\n+      the Work and Derivative Works thereof.\\n+\\n+      \"Contribution\" shall mean any work of authorship, including\\n+      the original version of the Work and any modifications or additions\\n+      to that Work or Derivative Works thereof, that is intentionally\\n+      submitted to Licensor for inclusion in the Work by the copyright owner\\n+      or by an individual or Legal Entity authorized to submit on behalf of\\n+      the copyright owner. For the purposes of this definition, \"submitted\"\\n+      means any form of electronic, verbal, or written communication sent\\n+      to the Licensor or its representatives, including but not limited to\\n+      communication on electronic mailing lists, source code control systems,\\n+      and issue tracking systems that are managed by, or on behalf of, the\\n+      Licensor for the purpose of discussing and improving the Work, but\\n+      excluding communication that is conspicuously marked or otherwise\\n+      designated in writing by the copyright owner as \"Not a Contribution.\"\\n+\\n+      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n+      on behalf of whom a Contribution has been received by Licensor and\\n+      subsequently incorporated within the Work.\\n+\\n+   2. Grant of Copyright License. Subject to the terms and conditions of\\n+      this License, each Contributor hereby grants to You a perpetual,\\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n+      copyright license to reproduce, prepare Derivative Works of,\\n+      publicly display, publicly perform, sublicense, and distribute the\\n+      Work and such Derivative Works in Source or Object form.\\n+\\n+   3. Grant of Patent License. Subject to the terms and conditions of\\n+      this License, each Contributor hereby grants to You a perpetual,\\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n+      (except as stated in this section) patent license to make, have made,\\n+      use, offer to sell, sell, import, and otherwise transfer the Work,\\n+      where such license applies only to those patent claims licensable\\n+      by such Contributor that are necessarily infringed by their\\n+      Contribution(s) alone or by combination of their Contribution(s)\\n+      with the Work to which such Contribution(s) was submitted. If You\\n+      institute patent litigation against any entity (including a\\n+      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n+      or a Contribution incorporated within the Work constitutes direct\\n+      or contributory patent infringement, then any patent licenses\\n+      granted to You under this License for that Work shall terminate\\n+      as of the date such litigation is filed.\\n+\\n+   4. Redistribution. You may reproduce and distribute copies of the\\n+      Work or Derivative Works thereof in any medium, with or without\\n+      modifications, and in Source or Object form, provided that You\\n+      meet the following conditions:\\n+\\n+      (a) You must give any other recipients of the Work or\\n+          Derivative Works a copy of this License; and\\n+\\n+      (b) You must cause any modified files to carry prominent notices\\n+          stating that You changed the files; and\\n+\\n+      (c) You must retain, in the Source form of any Derivative Works\\n+          that You distribute, all copyright, patent, trademark, and\\n+          attribution notices from the Source form of the Work,\\n+          excluding those notices that do not pertain to any part of\\n+          the Derivative Works; and\\n+\\n+      (d) If the Work includes a \"NOTICE\" text file as part of its\\n+          distribution, then any Derivative Works that You distribute must\\n+          include a readable copy of the attribution notices contained\\n+          within such NOTICE file, excluding those notices that do not\\n+          pertain to any part of the Derivative Works, in at least one\\n+          of the following places: within a NOTICE text file distributed\\n+          as part of the Derivative Works; within the Source form or\\n+          documentation, if provided along with the Derivative Works; or,\\n+          within a display generated by the Derivative Works, if and\\n+          wherever such third-party notices normally appear. The contents\\n+          of the NOTICE file are for informational purposes only and\\n+          do not modify the License. You may add Your own attribution\\n+          notices within Derivative Works that You distribute, alongside\\n+          or as an addendum to the NOTICE text from the Work, provided\\n+          that such additional attribution notices cannot be construed\\n+          as modifying the License.\\n+\\n+      You may add Your own copyright statement to Your modifications and\\n+      may provide additional or different license terms and conditions\\n+      for use, reproduction, or distribution of Your modifications, or\\n+      for any such Derivative Works as a whole, provided Your use,\\n+      reproduction, and distribution of the Work otherwise complies with\\n+      the conditions stated in this License.\\n+\\n+   5. Submission of Contributions. Unless You explicitly state otherwise,\\n+      any Contribution intentionally submitted for inclusion in the Work\\n+      by You to the Licensor shall be under the terms and conditions of\\n+      this License, without any additional terms or conditions.\\n+      Notwithstanding the above, nothing herein shall supersede or modify\\n+      the terms of any separate license agreement you may have executed\\n+      with Licensor regarding such Contributions.\\n+\\n+   6. Trademarks. This License does not grant permission to use the trade\\n+      names, trademarks, service marks, or product names of the Licensor,\\n+      except as required for reasonable and customary use in describing the\\n+      origin of the Work and reproducing the content of the NOTICE file.\\n+\\n+   7. Disclaimer of Warranty. Unless required by applicable law or\\n+      agreed to in writing, Licensor provides the Work (and each\\n+      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n+      implied, including, without limitation, any warranties or conditions\\n+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n+      PARTICULAR PURPOSE. You are solely responsible for determining the\\n+      appropriateness of using or redistributing the Work and assume any\\n+      risks associated with Your exercise of permissions under this License.\\n+\\n+   8. Limitation of Liability. In no event and under no legal theory,\\n+      whether in tort (including negligence), contract, or otherwise,\\n+      unless required by applicable law (such as deliberate and grossly\\n+      negligent acts) or agreed to in writing, shall any Contributor be\\n+      liable to You for damages, including any direct, indirect, special,\\n+      incidental, or consequential damages of any character arising as a\\n+      result of this License or out of the use or inability to use the\\n+      Work (including but not limited to damages for loss of goodwill,\\n+      work stoppage, computer failure or malfunction, or any and all\\n+      other commercial damages or losses), even if such Contributor\\n+      has been advised of the possibility of such damages.\\n+\\n+   9. Accepting Warranty or Additional Liability. While redistributing\\n+      the Work or Derivative Works thereof, You may choose to offer,\\n+      and charge a fee for, acceptance of support, warranty, indemnity,\\n+      or other liability obligations and/or rights consistent with this\\n+      License. However, in accepting such obligations, You may act only\\n+      on Your own behalf and on Your sole responsibility, not on behalf\\n+      of any other Contributor, and only if You agree to indemnify,\\n+      defend, and hold each Contributor harmless for any liability\\n+      incurred by, or claims asserted against, such Contributor by reason\\n+      of your accepting any such warranty or additional liability.\\n+\\n+   END OF TERMS AND CONDITIONS\\n+\\n+   APPENDIX: How to apply the Apache License to your work.\\n+\\n+      To apply the Apache License to your work, attach the following\\n+      boilerplate notice, with the fields enclosed by brackets \"[]\"\\n+      replaced with your own identifying information. (Don't include\\n+      the brackets!)  The text should be enclosed in the appropriate\\n+      comment syntax for the file format. We also recommend that a\\n+      file or class name and description of purpose be included on the\\n+      same \"printed page\" as the copyright notice for easier\\n+      identification within third-party archives.\\n+\\n+   Copyright [yyyy] [name of copyright owner]\\n+\\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\\n+   you may not use this file except in compliance with the License.\\n+   You may obtain a copy of the License at\\n+\\n+       http://www.apache.org/licenses/LICENSE-2.0\\n+\\n+   Unless required by applicable law or agreed to in writing, software\\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n+   See the License for the specific language governing permissions and\\n+   limitations under the License.\\n   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              @@ -0,0 +1 @@\\n+*__pycache__*\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     @@ -0,0 +1 @@\\n+# adhd\\n   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             @@ -0,0 +1,66 @@\\n+\"\"\"Config for training.\"\"\"\\n+\\n+from typing import Any, Sequence, Tuple\\n+from flax import struct\\n+import jax.numpy as jnp\\n+\\n+\\n+@struct.dataclass\\n+class T5Config:\\n+  \"\"\"Global hyperparameters used to minimize obnoxious kwarg plumbing.\"\"\"\\n+\\n+  # Activation dtypes.\\n+  dtype: Any = jnp.float32\\n+  emb_dim: int = 128\\n+  num_heads: int = 8\\n+  head_dim: int = 16\\n+  mlp_dim: int = 512\\n+  num_decoder_layers: int = 6\\n+  # activation functions are .\\n+  mlp_activations: Sequence[str] = ('relu',)\\n+  dropout_rate: float = 0\\n+  # If `True`, the embedding weights are used in the decoder output layer.\\n+  logits_via_embedding: bool = True  # NOTE: this is True just for testing.\\n+  # minimal, full, or none\\n+  remat_policy: str = 'none'\\n+  scan_layers: bool = False\\n+  param_scan_axis: int = 1\\n+\\n+  # Parallelism\\n+  mesh_shape: Tuple[int] = (4,)\\n+  mesh_axes: Tuple[str] = ('data',)\\n+  logical_axis_rules: Sequence = ( ('batch', 'data'), )\\n+\\n+  # Dataset\\n+  vocab_size: int = 30000\\n+  dataset_name: str = 'lm1b'\\n+  eval_dataset_name: str = 'lm1b'\\n+  eval_split: str = 'test'\\n+  per_device_batch_size: int = 32\\n+  eval_per_device_batch_size: int = 0\\n+  max_corpus_chars: int = 10**7  # for tokenization\\n+\\n+  # Training loop\\n+  steps: int = 20_000_000\\n+  log_period: int = 500\\n+  save_period: int = 2000\\n+  learning_rate: float = 1e-3\\n+  warmup_steps: int = 1000\\n+  save_checkpoints: bool = False\\n+  restore_checkpoints: bool = False\\n+\\n+  # Maximum length cutoff for training examples.\\n+  max_target_length: int = 128\\n+  # Maximum length cutoff for held-out evaluation examples.\\n+  max_eval_target_length: int = 512\\n+\\n+  # Maximum length cutoff for predicted tokens.\\n+  max_predict_length: int = 50\\n+  # Sampling temperature for language model inference.\\n+  sampling_temperature: float = 0.6\\n+  # Top k cutoff for logit sampling. If 0 then no top-k cutoff is used.\\n+  sampling_top_k: int = 20\\n+  eos_id: int = 2  # sentencepiece default\\n+  # Prompt for language model sampling.\\n+  prompt: str = \"I love to \"\\n+\\n   \n",
              "4  @@ -0,0 +1,340 @@\\n+\"\"\"Input pipeline for a LM1B dataset.\"\"\"\\n+\\n+import os\\n+from typing import Dict, Optional, List, Union\\n+\\n+from clu import deterministic_data\\n+import ml_collections\\n+import tensorflow as tf\\n+import tensorflow_datasets as tfds\\n+\\n+from adhd import tokenizer\\n+\\n+AUTOTUNE = tf.data.experimental.AUTOTUNE\\n+Features = Dict[str, tf.Tensor]\\n+\\n+\\n+class NormalizeFeatureNamesOp:\\n+  \"\"\"Normalizes feature names to 'inputs' and 'targets'.\"\"\"\\n+\\n+  def __init__(self, ds_info: tfds.core.DatasetInfo):\\n+    self.ds_info = ds_info\\n+\\n+  def __call__(self, features: Features) -> Features:\\n+    features['inputs'] = features.pop('text')\\n+    # Unnecessary step used for uniformizing with examples/wmt.\\n+    features['targets'] = features['inputs']\\n+    return features\\n+\\n+\\n+def get_raw_dataset(dataset_builder: tfds.core.DatasetBuilder,\\n+                    split: str) -> tf.data.Dataset:\\n+  \"\"\"Loads a raw text dataset and normalizes feature keys.\\n+  Args:\\n+    dataset_builder: TFDS dataset builder that can build `split`.\\n+    split: Split to use. This must be the full split. We shard the split across\\n+      multiple hosts and currently don't support sharding subsplits.\\n+  Returns:\\n+    Dataset with source and target language features mapped to 'inputs' and\\n+    'targets'.\\n+  \"\"\"\\n+  per_host_split = tfds.split_for_jax_process(split, drop_remainder=False)\\n+  ds = dataset_builder.as_dataset(split=per_host_split, shuffle_files=False)\\n+  ds = ds.map(\\n+      NormalizeFeatureNamesOp(dataset_builder.info),\\n+      num_parallel_calls=AUTOTUNE)\\n+  return ds\\n+\\n+\\n+def pack_dataset(dataset: tf.data.Dataset,\\n+                 key2length: Union[int, Dict[str, int]],\\n+                 keys: Optional[List[str]] = None) -> tf.data.Dataset:\\n+  \"\"\"Creates a 'packed' version of a dataset on-the-fly.\\n+  Adapted from the mesh-tf implementation.\\n+  This is meant to replace the irritation of having to create a separate\\n+  \"packed\" version of a dataset to train efficiently on TPU.\\n+  Each example in the output dataset represents several examples in the\\n+  input dataset.\\n+  For each key in the input dataset, two additional keys are created:\\n+  <key>_segmentation: an int32 tensor identifying the parts\\n+     representing the original example.\\n+  <key>_position: an int32 tensor identifying the position within the original\\n+     example.\\n+  Example:\\n+  Two input examples get combined to form an output example.\\n+  The input examples are:\\n+  {\"inputs\": [8, 7, 1, 0], \"targets\":[4, 1, 0]}\\n+  {\"inputs\": [2, 3, 4, 1], \"targets\":[5, 6, 1]}\\n+  The output example is:\\n+  {\\n+                 \"inputs\": [8, 7, 1, 2, 3, 4, 1, 0, 0, 0]\\n+    \"inputs_segmentation\": [1, 1, 1, 2, 2, 2, 2, 0, 0, 0]\\n+        \"inputs_position\": [0, 1, 2, 0, 1, 2, 3, 0, 0, 0]\\n+                \"targets\": [4, 1, 5, 6, 1, 0, 0, 0, 0, 0]\\n+   \"targets_segmentation\": [1, 1, 2, 2, 2, 0, 0, 0, 0, 0]\\n+       \"targets_position\": [0, 1, 0, 1, 2, 0, 0, 0, 0, 0]\\n+  }\\n+  0 represents padding in both the inputs and the outputs.\\n+  Sequences in the incoming examples are truncated to length \"length\", and the\\n+  sequences in the output examples all have fixed (padded) length \"length\".\\n+  Args:\\n+    dataset: a tf.data.Dataset\\n+    key2length: an integer, or a dict from feature-key to integer\\n+    keys: a list of strings (e.g. [\"inputs\", \"targets\"])\\n+  Returns:\\n+    a tf.data.Dataset\\n+  \"\"\"\\n+  shapes = tf.nest.map_structure(lambda spec: spec.shape, dataset.element_spec)\\n+  if keys is None:\\n+    keys = list(shapes.keys())\\n+  for k in keys:\\n+    if k not in shapes:\\n+      raise ValueError('Key %s not found in dataset.  Available keys are %s' %\\n+                       (k, shapes.keys()))\\n+    if not shapes[k].is_compatible_with(tf.TensorShape([None])):\\n+      raise ValueError('Tensors to be packed must be one-dimensional.')\\n+  # make sure that the length dictionary contains all keys as well as the\\n+  # keys suffixed by \"_segmentation\" and \"_position\"\\n+  if isinstance(key2length, int):\\n+    key2length = {k: key2length for k in keys}\\n+  for k in keys:\\n+    for suffix in ['_segmentation', '_position']:\\n+      key2length[k + suffix] = key2length[k]\\n+\\n+  # trim to length\\n+  dataset = dataset.map(\\n+      lambda x: {k: x[k][:key2length[k]] for k in keys},\\n+      num_parallel_calls=AUTOTUNE)\\n+  # Setting batch_size=length ensures that the concatenated sequences (if they\\n+  # have length >=1) are sufficient to fill at least one packed example.\\n+  batch_size = max(key2length.values())\\n+  dataset = dataset.padded_batch(\\n+      batch_size, padded_shapes={k: [-1] for k in keys})\\n+  dataset = _pack_with_tf_ops(dataset, keys, key2length)\\n+\\n+  # Set the Tensor shapes correctly since they get lost in the process.\\n+  def my_fn(x):\\n+    return {k: tf.reshape(v, [key2length[k]]) for k, v in x.items()}\\n+\\n+  return dataset.map(my_fn, num_parallel_calls=AUTOTUNE)\\n+\\n+\\n+def _pack_with_tf_ops(dataset: tf.data.Dataset, keys: List[str],\\n+                      key2length: Dict[str, int]) -> tf.data.Dataset:\\n+  \"\"\"Helper-function for packing a dataset which has already been batched.\\n+  Helper for pack_dataset()  Uses tf.while_loop.\\n+  Args:\\n+    dataset: a dataset containing padded batches of examples.\\n+    keys: a list of strings\\n+    key2length: an dict from feature-key to integer\\n+  Returns:\\n+    a dataset.\\n+  \"\"\"\\n+  empty_example = {}\\n+  for k in keys:\\n+    empty_example[k] = tf.zeros([0], dtype=tf.int32)\\n+    empty_example[k + '_position'] = tf.zeros([0], dtype=tf.int32)\\n+  keys_etc = empty_example.keys()\\n+\\n+  def write_packed_example(partial, outputs):\\n+    new_partial = empty_example.copy()\\n+    new_outputs = {}\\n+    for k in keys_etc:\\n+      new_outputs[k] = outputs[k].write(\\n+          outputs[k].size(),\\n+          tf.pad(partial[k], [[0, key2length[k] - tf.size(partial[k])]]))\\n+    return new_partial, new_outputs\\n+\\n+  def map_fn(x):\\n+    \"\"\"Internal function to flat_map over.\\n+    Consumes a batch of input examples and produces a variable number of output\\n+    examples.\\n+    Args:\\n+      x: a single example\\n+    Returns:\\n+      a tf.data.Dataset\\n+    \"\"\"\\n+    partial = empty_example.copy()\\n+    i = tf.zeros([], dtype=tf.int32)\\n+    dynamic_batch_size = tf.shape(x[keys[0]])[0]\\n+    outputs = {}\\n+    for k in keys:\\n+      outputs[k] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+      outputs[k + '_position'] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+\\n+    def body_fn(i, partial, outputs):\\n+      \"\"\"Body function for while_loop.\\n+      Args:\\n+        i: integer scalar\\n+        partial: dictionary of Tensor (partially-constructed example)\\n+        outputs: dictionary of TensorArray\\n+      Returns:\\n+        A triple containing the new values of the inputs.\\n+      \"\"\"\\n+      can_append = True\\n+      one_example = {}\\n+      for k in keys:\\n+        val = tf.cast(x[k][i], tf.int32)\\n+        val = val[:tf.reduce_sum(tf.cast(tf.not_equal(val, 0), tf.int32))]\\n+        one_example[k] = val\\n+      for k in keys:\\n+        can_append = tf.logical_and(\\n+            can_append,\\n+            tf.less_equal(\\n+                tf.size(partial[k]) + tf.size(one_example[k]), key2length[k]))\\n+\\n+      def false_fn():\\n+        return write_packed_example(partial, outputs)\\n+\\n+      def true_fn():\\n+        return partial, outputs\\n+\\n+      partial, outputs = tf.cond(can_append, true_fn, false_fn)\\n+      new_partial = {}\\n+      for k in keys:\\n+        new_seq = one_example[k][:key2length[k]]\\n+        new_seq_len = tf.size(new_seq)\\n+        new_partial[k] = tf.concat([partial[k], new_seq], 0)\\n+        new_partial[k + '_position'] = tf.concat(\\n+            [partial[k + '_position'],\\n+             tf.range(new_seq_len)], 0)\\n+      partial = new_partial\\n+      return i + 1, partial, outputs\\n+\\n+    # For loop over all examples in the batch.\\n+    i, partial, outputs = tf.while_loop(\\n+        cond=lambda *_: True,\\n+        body=body_fn,\\n+        loop_vars=(i, partial, outputs),\\n+        shape_invariants=(\\n+            tf.TensorShape([]),\\n+            {k: tf.TensorShape([None]) for k in keys_etc},\\n+            {k: tf.TensorShape(None) for k in keys_etc},\\n+        ),\\n+        maximum_iterations=dynamic_batch_size)\\n+    _, outputs = write_packed_example(partial, outputs)\\n+    packed = {k: outputs[k].stack() for k in keys_etc}\\n+    for k in keys:\\n+      packed[k + '_segmentation'] = (\\n+          tf.cumsum(\\n+              tf.cast(tf.equal(packed[k + '_position'], 0), tf.int32), axis=1) *\\n+          tf.cast(tf.not_equal(packed[k], 0), tf.int32))\\n+    return packed\\n+\\n+  dataset = dataset.map(map_fn, num_parallel_calls=AUTOTUNE)\\n+  return dataset.unbatch()\\n+\\n+\\n+# -----------------------------------------------------------------------------\\n+# Main dataset prep routines.\\n+# -----------------------------------------------------------------------------\\n+def preprocess_data(dataset,\\n+                    shuffle: bool,\\n+                    num_epochs: Optional[int] = 1,\\n+                    pack_examples: bool = True,\\n+                    shuffle_buffer_size: int = 1024,\\n+                    max_length: int = 512,\\n+                    batch_size: int = 256,\\n+                    drop_remainder: bool = True,\\n+                    prefetch_size: int = AUTOTUNE):\\n+  \"\"\"Shuffle and batch/pack the given dataset.\"\"\"\\n+\\n+  def length_filter(max_len):\\n+\\n+    def filter_fn(x):\\n+      source, target = x['inputs'], x['targets']\\n+      l = tf.maximum(tf.shape(source)[0], tf.shape(target)[0])\\n+      return tf.less(l, max_len + 1)\\n+\\n+    return filter_fn\\n+\\n+  if max_length > 0:\\n+    dataset = dataset.filter(length_filter(max_length))\\n+\\n+  if shuffle:\\n+    dataset = dataset.shuffle(shuffle_buffer_size)\\n+  dataset = dataset.repeat(num_epochs)\\n+\\n+  if pack_examples:\\n+    dataset = pack_dataset(dataset, max_length)\\n+    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\\n+  else:  # simple (static-shape) padded batching\\n+    dataset = dataset.padded_batch(\\n+        batch_size,\\n+        padded_shapes={\\n+            'inputs': max_length,\\n+            'targets': max_length\\n+        },\\n+        padding_values={\\n+            'inputs': 0,\\n+            'targets': 0\\n+        },\\n+        drop_remainder=drop_remainder)\\n+\\n+  if prefetch_size:\\n+    dataset = dataset.prefetch(prefetch_size)\\n+\\n+  return dataset\\n+\\n+\\n+def get_datasets(config: ml_collections.ConfigDict,\\n+                 *,\\n+                 n_devices: int,\\n+                 vocab_path: Optional[str] = None):\\n+  \"\"\"Load and return dataset of batched examples for use during training.\"\"\"\\n+  if vocab_path is None:\\n+    vocab_path = os.path.expanduser('~/lm1b_sentencepiece_model')\\n+\\n+  train_ds_builder = tfds.builder(config.dataset_name)\\n+  train_ds_builder.download_and_prepare()\\n+  train_data = get_raw_dataset(train_ds_builder, 'train')\\n+\\n+  if config.eval_dataset_name:\\n+    eval_ds_builder = tfds.builder(config.eval_dataset_name)\\n+  else:\\n+    eval_ds_builder = train_ds_builder\\n+  eval_data = get_raw_dataset(eval_ds_builder, config.eval_split)\\n+\\n+  # Tokenize data.\\n+  sp_tokenizer = tokenizer.load_or_train_tokenizer(\\n+      train_data,\\n+      vocab_path=vocab_path,\\n+      vocab_size=config.vocab_size,\\n+      max_corpus_chars=config.max_corpus_chars)\\n+  train_data = train_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+  eval_data = eval_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+\\n+  batch_size = config.per_device_batch_size * n_devices\\n+  if config.eval_per_device_batch_size > 0:\\n+    eval_batch_size = config.eval_per_device_batch_size * n_devices\\n+  else:\\n+    eval_batch_size = batch_size\\n+\\n+  train_ds = preprocess_data(\\n+      train_data,\\n+      shuffle=True,\\n+      num_epochs=None,\\n+      pack_examples=True,\\n+      batch_size=batch_size,\\n+      max_length=config.max_target_length)\\n+\\n+  eval_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_eval_target_length)\\n+\\n+  predict_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_predict_length,\\n+      drop_remainder=False)\\n+\\n+  return train_ds, eval_ds, predict_ds, sp_tokenizer\\n   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         diff_hist  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Command '['git', '-C', 'maxtext', 'diff', '--histogram', '696b089f888e57a468184d382e56b862985640f2^', '696b089f888e57a468184d382e56b862985640f2', '--', 'LICENSE']' returned non-zero exit status 128.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           diff --git a/.gitignore b/.gitignore\\nnew file mode 100644\\nindex 00000000..cd4c22c4\\n--- /dev/null\\n+++ b/.gitignore\\n@@ -0,0 +1 @@\\n+*__pycache__*\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       diff --git a/MaxText/__init__.py b/MaxText/__init__.py\\nnew file mode 100644\\nindex 00000000..f424dbec\\n--- /dev/null\\n+++ b/MaxText/__init__.py\\n@@ -0,0 +1 @@\\n+# adhd\\n   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     diff --git a/MaxText/config.py b/MaxText/config.py\\nnew file mode 100644\\nindex 00000000..71317091\\n--- /dev/null\\n+++ b/MaxText/config.py\\n@@ -0,0 +1,66 @@\\n+\"\"\"Config for training.\"\"\"\\n+\\n+from typing import Any, Sequence, Tuple\\n+from flax import struct\\n+import jax.numpy as jnp\\n+\\n+\\n+@struct.dataclass\\n+class T5Config:\\n+  \"\"\"Global hyperparameters used to minimize obnoxious kwarg plumbing.\"\"\"\\n+\\n+  # Activation dtypes.\\n+  dtype: Any = jnp.float32\\n+  emb_dim: int = 128\\n+  num_heads: int = 8\\n+  head_dim: int = 16\\n+  mlp_dim: int = 512\\n+  num_decoder_layers: int = 6\\n+  # activation functions are .\\n+  mlp_activations: Sequence[str] = ('relu',)\\n+  dropout_rate: float = 0\\n+  # If `True`, the embedding weights are used in the decoder output layer.\\n+  logits_via_embedding: bool = True  # NOTE: this is True just for testing.\\n+  # minimal, full, or none\\n+  remat_policy: str = 'none'\\n+  scan_layers: bool = False\\n+  param_scan_axis: int = 1\\n+\\n+  # Parallelism\\n+  mesh_shape: Tuple[int] = (4,)\\n+  mesh_axes: Tuple[str] = ('data',)\\n+  logical_axis_rules: Sequence = ( ('batch', 'data'), )\\n+\\n+  # Dataset\\n+  vocab_size: int = 30000\\n+  dataset_name: str = 'lm1b'\\n+  eval_dataset_name: str = 'lm1b'\\n+  eval_split: str = 'test'\\n+  per_device_batch_size: int = 32\\n+  eval_per_device_batch_size: int = 0\\n+  max_corpus_chars: int = 10**7  # for tokenization\\n+\\n+  # Training loop\\n+  steps: int = 20_000_000\\n+  log_period: int = 500\\n+  save_period: int = 2000\\n+  learning_rate: float = 1e-3\\n+  warmup_steps: int = 1000\\n+  save_checkpoints: bool = False\\n+  restore_checkpoints: bool = False\\n+\\n+  # Maximum length cutoff for training examples.\\n+  max_target_length: int = 128\\n+  # Maximum length cutoff for held-out evaluation examples.\\n+  max_eval_target_length: int = 512\\n+\\n+  # Maximum length cutoff for predicted tokens.\\n+  max_predict_length: int = 50\\n+  # Sampling temperature for language model inference.\\n+  sampling_temperature: float = 0.6\\n+  # Top k cutoff for logit sampling. If 0 then no top-k cutoff is used.\\n+  sampling_top_k: int = 20\\n+  eos_id: int = 2  # sentencepiece default\\n+  # Prompt for language model sampling.\\n+  prompt: str = \"I love to \"\\n+\\n   \n",
              "4  diff --git a/MaxText/input_pipeline.py b/MaxText/input_pipeline.py\\nnew file mode 100644\\nindex 00000000..8328ccad\\n--- /dev/null\\n+++ b/MaxText/input_pipeline.py\\n@@ -0,0 +1,340 @@\\n+\"\"\"Input pipeline for a LM1B dataset.\"\"\"\\n+\\n+import os\\n+from typing import Dict, Optional, List, Union\\n+\\n+from clu import deterministic_data\\n+import ml_collections\\n+import tensorflow as tf\\n+import tensorflow_datasets as tfds\\n+\\n+from adhd import tokenizer\\n+\\n+AUTOTUNE = tf.data.experimental.AUTOTUNE\\n+Features = Dict[str, tf.Tensor]\\n+\\n+\\n+class NormalizeFeatureNamesOp:\\n+  \"\"\"Normalizes feature names to 'inputs' and 'targets'.\"\"\"\\n+\\n+  def __init__(self, ds_info: tfds.core.DatasetInfo):\\n+    self.ds_info = ds_info\\n+\\n+  def __call__(self, features: Features) -> Features:\\n+    features['inputs'] = features.pop('text')\\n+    # Unnecessary step used for uniformizing with examples/wmt.\\n+    features['targets'] = features['inputs']\\n+    return features\\n+\\n+\\n+def get_raw_dataset(dataset_builder: tfds.core.DatasetBuilder,\\n+                    split: str) -> tf.data.Dataset:\\n+  \"\"\"Loads a raw text dataset and normalizes feature keys.\\n+  Args:\\n+    dataset_builder: TFDS dataset builder that can build `split`.\\n+    split: Split to use. This must be the full split. We shard the split across\\n+      multiple hosts and currently don't support sharding subsplits.\\n+  Returns:\\n+    Dataset with source and target language features mapped to 'inputs' and\\n+    'targets'.\\n+  \"\"\"\\n+  per_host_split = tfds.split_for_jax_process(split, drop_remainder=False)\\n+  ds = dataset_builder.as_dataset(split=per_host_split, shuffle_files=False)\\n+  ds = ds.map(\\n+      NormalizeFeatureNamesOp(dataset_builder.info),\\n+      num_parallel_calls=AUTOTUNE)\\n+  return ds\\n+\\n+\\n+def pack_dataset(dataset: tf.data.Dataset,\\n+                 key2length: Union[int, Dict[str, int]],\\n+                 keys: Optional[List[str]] = None) -> tf.data.Dataset:\\n+  \"\"\"Creates a 'packed' version of a dataset on-the-fly.\\n+  Adapted from the mesh-tf implementation.\\n+  This is meant to replace the irritation of having to create a separate\\n+  \"packed\" version of a dataset to train efficiently on TPU.\\n+  Each example in the output dataset represents several examples in the\\n+  input dataset.\\n+  For each key in the input dataset, two additional keys are created:\\n+  <key>_segmentation: an int32 tensor identifying the parts\\n+     representing the original example.\\n+  <key>_position: an int32 tensor identifying the position within the original\\n+     example.\\n+  Example:\\n+  Two input examples get combined to form an output example.\\n+  The input examples are:\\n+  {\"inputs\": [8, 7, 1, 0], \"targets\":[4, 1, 0]}\\n+  {\"inputs\": [2, 3, 4, 1], \"targets\":[5, 6, 1]}\\n+  The output example is:\\n+  {\\n+                 \"inputs\": [8, 7, 1, 2, 3, 4, 1, 0, 0, 0]\\n+    \"inputs_segmentation\": [1, 1, 1, 2, 2, 2, 2, 0, 0, 0]\\n+        \"inputs_position\": [0, 1, 2, 0, 1, 2, 3, 0, 0, 0]\\n+                \"targets\": [4, 1, 5, 6, 1, 0, 0, 0, 0, 0]\\n+   \"targets_segmentation\": [1, 1, 2, 2, 2, 0, 0, 0, 0, 0]\\n+       \"targets_position\": [0, 1, 0, 1, 2, 0, 0, 0, 0, 0]\\n+  }\\n+  0 represents padding in both the inputs and the outputs.\\n+  Sequences in the incoming examples are truncated to length \"length\", and the\\n+  sequences in the output examples all have fixed (padded) length \"length\".\\n+  Args:\\n+    dataset: a tf.data.Dataset\\n+    key2length: an integer, or a dict from feature-key to integer\\n+    keys: a list of strings (e.g. [\"inputs\", \"targets\"])\\n+  Returns:\\n+    a tf.data.Dataset\\n+  \"\"\"\\n+  shapes = tf.nest.map_structure(lambda spec: spec.shape, dataset.element_spec)\\n+  if keys is None:\\n+    keys = list(shapes.keys())\\n+  for k in keys:\\n+    if k not in shapes:\\n+      raise ValueError('Key %s not found in dataset.  Available keys are %s' %\\n+                       (k, shapes.keys()))\\n+    if not shapes[k].is_compatible_with(tf.TensorShape([None])):\\n+      raise ValueError('Tensors to be packed must be one-dimensional.')\\n+  # make sure that the length dictionary contains all keys as well as the\\n+  # keys suffixed by \"_segmentation\" and \"_position\"\\n+  if isinstance(key2length, int):\\n+    key2length = {k: key2length for k in keys}\\n+  for k in keys:\\n+    for suffix in ['_segmentation', '_position']:\\n+      key2length[k + suffix] = key2length[k]\\n+\\n+  # trim to length\\n+  dataset = dataset.map(\\n+      lambda x: {k: x[k][:key2length[k]] for k in keys},\\n+      num_parallel_calls=AUTOTUNE)\\n+  # Setting batch_size=length ensures that the concatenated sequences (if they\\n+  # have length >=1) are sufficient to fill at least one packed example.\\n+  batch_size = max(key2length.values())\\n+  dataset = dataset.padded_batch(\\n+      batch_size, padded_shapes={k: [-1] for k in keys})\\n+  dataset = _pack_with_tf_ops(dataset, keys, key2length)\\n+\\n+  # Set the Tensor shapes correctly since they get lost in the process.\\n+  def my_fn(x):\\n+    return {k: tf.reshape(v, [key2length[k]]) for k, v in x.items()}\\n+\\n+  return dataset.map(my_fn, num_parallel_calls=AUTOTUNE)\\n+\\n+\\n+def _pack_with_tf_ops(dataset: tf.data.Dataset, keys: List[str],\\n+                      key2length: Dict[str, int]) -> tf.data.Dataset:\\n+  \"\"\"Helper-function for packing a dataset which has already been batched.\\n+  Helper for pack_dataset()  Uses tf.while_loop.\\n+  Args:\\n+    dataset: a dataset containing padded batches of examples.\\n+    keys: a list of strings\\n+    key2length: an dict from feature-key to integer\\n+  Returns:\\n+    a dataset.\\n+  \"\"\"\\n+  empty_example = {}\\n+  for k in keys:\\n+    empty_example[k] = tf.zeros([0], dtype=tf.int32)\\n+    empty_example[k + '_position'] = tf.zeros([0], dtype=tf.int32)\\n+  keys_etc = empty_example.keys()\\n+\\n+  def write_packed_example(partial, outputs):\\n+    new_partial = empty_example.copy()\\n+    new_outputs = {}\\n+    for k in keys_etc:\\n+      new_outputs[k] = outputs[k].write(\\n+          outputs[k].size(),\\n+          tf.pad(partial[k], [[0, key2length[k] - tf.size(partial[k])]]))\\n+    return new_partial, new_outputs\\n+\\n+  def map_fn(x):\\n+    \"\"\"Internal function to flat_map over.\\n+    Consumes a batch of input examples and produces a variable number of output\\n+    examples.\\n+    Args:\\n+      x: a single example\\n+    Returns:\\n+      a tf.data.Dataset\\n+    \"\"\"\\n+    partial = empty_example.copy()\\n+    i = tf.zeros([], dtype=tf.int32)\\n+    dynamic_batch_size = tf.shape(x[keys[0]])[0]\\n+    outputs = {}\\n+    for k in keys:\\n+      outputs[k] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+      outputs[k + '_position'] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+\\n+    def body_fn(i, partial, outputs):\\n+      \"\"\"Body function for while_loop.\\n+      Args:\\n+        i: integer scalar\\n+        partial: dictionary of Tensor (partially-constructed example)\\n+        outputs: dictionary of TensorArray\\n+      Returns:\\n+        A triple containing the new values of the inputs.\\n+      \"\"\"\\n+      can_append = True\\n+      one_example = {}\\n+      for k in keys:\\n+        val = tf.cast(x[k][i], tf.int32)\\n+        val = val[:tf.reduce_sum(tf.cast(tf.not_equal(val, 0), tf.int32))]\\n+        one_example[k] = val\\n+      for k in keys:\\n+        can_append = tf.logical_and(\\n+            can_append,\\n+            tf.less_equal(\\n+                tf.size(partial[k]) + tf.size(one_example[k]), key2length[k]))\\n+\\n+      def false_fn():\\n+        return write_packed_example(partial, outputs)\\n+\\n+      def true_fn():\\n+        return partial, outputs\\n+\\n+      partial, outputs = tf.cond(can_append, true_fn, false_fn)\\n+      new_partial = {}\\n+      for k in keys:\\n+        new_seq = one_example[k][:key2length[k]]\\n+        new_seq_len = tf.size(new_seq)\\n+        new_partial[k] = tf.concat([partial[k], new_seq], 0)\\n+        new_partial[k + '_position'] = tf.concat(\\n+            [partial[k + '_position'],\\n+             tf.range(new_seq_len)], 0)\\n+      partial = new_partial\\n+      return i + 1, partial, outputs\\n+\\n+    # For loop over all examples in the batch.\\n+    i, partial, outputs = tf.while_loop(\\n+        cond=lambda *_: True,\\n+        body=body_fn,\\n+        loop_vars=(i, partial, outputs),\\n+        shape_invariants=(\\n+            tf.TensorShape([]),\\n+            {k: tf.TensorShape([None]) for k in keys_etc},\\n+            {k: tf.TensorShape(None) for k in keys_etc},\\n+        ),\\n+        maximum_iterations=dynamic_batch_size)\\n+    _, outputs = write_packed_example(partial, outputs)\\n+    packed = {k: outputs[k].stack() for k in keys_etc}\\n+    for k in keys:\\n+      packed[k + '_segmentation'] = (\\n+          tf.cumsum(\\n+              tf.cast(tf.equal(packed[k + '_position'], 0), tf.int32), axis=1) *\\n+          tf.cast(tf.not_equal(packed[k], 0), tf.int32))\\n+    return packed\\n+\\n+  dataset = dataset.map(map_fn, num_parallel_calls=AUTOTUNE)\\n+  return dataset.unbatch()\\n+\\n+\\n+# -----------------------------------------------------------------------------\\n+# Main dataset prep routines.\\n+# -----------------------------------------------------------------------------\\n+def preprocess_data(dataset,\\n+                    shuffle: bool,\\n+                    num_epochs: Optional[int] = 1,\\n+                    pack_examples: bool = True,\\n+                    shuffle_buffer_size: int = 1024,\\n+                    max_length: int = 512,\\n+                    batch_size: int = 256,\\n+                    drop_remainder: bool = True,\\n+                    prefetch_size: int = AUTOTUNE):\\n+  \"\"\"Shuffle and batch/pack the given dataset.\"\"\"\\n+\\n+  def length_filter(max_len):\\n+\\n+    def filter_fn(x):\\n+      source, target = x['inputs'], x['targets']\\n+      l = tf.maximum(tf.shape(source)[0], tf.shape(target)[0])\\n+      return tf.less(l, max_len + 1)\\n+\\n+    return filter_fn\\n+\\n+  if max_length > 0:\\n+    dataset = dataset.filter(length_filter(max_length))\\n+\\n+  if shuffle:\\n+    dataset = dataset.shuffle(shuffle_buffer_size)\\n+  dataset = dataset.repeat(num_epochs)\\n+\\n+  if pack_examples:\\n+    dataset = pack_dataset(dataset, max_length)\\n+    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\\n+  else:  # simple (static-shape) padded batching\\n+    dataset = dataset.padded_batch(\\n+        batch_size,\\n+        padded_shapes={\\n+            'inputs': max_length,\\n+            'targets': max_length\\n+        },\\n+        padding_values={\\n+            'inputs': 0,\\n+            'targets': 0\\n+        },\\n+        drop_remainder=drop_remainder)\\n+\\n+  if prefetch_size:\\n+    dataset = dataset.prefetch(prefetch_size)\\n+\\n+  return dataset\\n+\\n+\\n+def get_datasets(config: ml_collections.ConfigDict,\\n+                 *,\\n+                 n_devices: int,\\n+                 vocab_path: Optional[str] = None):\\n+  \"\"\"Load and return dataset of batched examples for use during training.\"\"\"\\n+  if vocab_path is None:\\n+    vocab_path = os.path.expanduser('~/lm1b_sentencepiece_model')\\n+\\n+  train_ds_builder = tfds.builder(config.dataset_name)\\n+  train_ds_builder.download_and_prepare()\\n+  train_data = get_raw_dataset(train_ds_builder, 'train')\\n+\\n+  if config.eval_dataset_name:\\n+    eval_ds_builder = tfds.builder(config.eval_dataset_name)\\n+  else:\\n+    eval_ds_builder = train_ds_builder\\n+  eval_data = get_raw_dataset(eval_ds_builder, config.eval_split)\\n+\\n+  # Tokenize data.\\n+  sp_tokenizer = tokenizer.load_or_train_tokenizer(\\n+      train_data,\\n+      vocab_path=vocab_path,\\n+      vocab_size=config.vocab_size,\\n+      max_corpus_chars=config.max_corpus_chars)\\n+  train_data = train_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+  eval_data = eval_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+\\n+  batch_size = config.per_device_batch_size * n_devices\\n+  if config.eval_per_device_batch_size > 0:\\n+    eval_batch_size = config.eval_per_device_batch_size * n_devices\\n+  else:\\n+    eval_batch_size = batch_size\\n+\\n+  train_ds = preprocess_data(\\n+      train_data,\\n+      shuffle=True,\\n+      num_epochs=None,\\n+      pack_examples=True,\\n+      batch_size=batch_size,\\n+      max_length=config.max_target_length)\\n+\\n+  eval_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_eval_target_length)\\n+\\n+  predict_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_predict_length,\\n+      drop_remainder=False)\\n+\\n+  return train_ds, eval_ds, predict_ds, sp_tokenizer\\n   \n",
              "\n",
              "  file_type  \n",
              "0   license  \n",
              "1    source  \n",
              "2    source  \n",
              "3    source  \n",
              "4    source  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92a53358-4096-49c1-9766-32cb9717ff58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo_name</th>\n",
              "      <th>old_file_path</th>\n",
              "      <th>new_file_path</th>\n",
              "      <th>commit_sha</th>\n",
              "      <th>parent_commit_sha</th>\n",
              "      <th>commit_message</th>\n",
              "      <th>diff_myers</th>\n",
              "      <th>diff_hist</th>\n",
              "      <th>file_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>maxtext</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LICENSE</td>\n",
              "      <td>696b089f888e57a468184d382e56b862985640f2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initial commit</td>\n",
              "      <td>@@ -0,0 +1,201 @@\\n+                                 Apache License\\n+                           Version 2.0, January 2004\\n+                        http://www.apache.org/licenses/\\n+\\n+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n+\\n+   1. Definitions.\\n+\\n+      \"License\" shall mean the terms and conditions for use, reproduction,\\n+      and distribution as defined by Sections 1 through 9 of this document.\\n+\\n+      \"Licensor\" shall mean the copyright owner or entity authorized by\\n+      the copyright owner that is granting the License.\\n+\\n+      \"Legal Entity\" shall mean the union of the acting entity and all\\n+      other entities that control, are controlled by, or are under common\\n+      control with that entity. For the purposes of this definition,\\n+      \"control\" means (i) the power, direct or indirect, to cause the\\n+      direction or management of such entity, whether by contract or\\n+      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n+      outstanding shares, or (iii) beneficial ownership of such entity.\\n+\\n+      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n+      exercising permissions granted by this License.\\n+\\n+      \"Source\" form shall mean the preferred form for making modifications,\\n+      including but not limited to software source code, documentation\\n+      source, and configuration files.\\n+\\n+      \"Object\" form shall mean any form resulting from mechanical\\n+      transformation or translation of a Source form, including but\\n+      not limited to compiled object code, generated documentation,\\n+      and conversions to other media types.\\n+\\n+      \"Work\" shall mean the work of authorship, whether in Source or\\n+      Object form, made available under the License, as indicated by a\\n+      copyright notice that is included in or attached to the work\\n+      (an example is provided in the Appendix below).\\n+\\n+      \"Derivative Works\" shall mean any work, whether in Source or Object\\n+      form, that is based on (or derived from) the Work and for which the\\n+      editorial revisions, annotations, elaborations, or other modifications\\n+      represent, as a whole, an original work of authorship. For the purposes\\n+      of this License, Derivative Works shall not include works that remain\\n+      separable from, or merely link (or bind by name) to the interfaces of,\\n+      the Work and Derivative Works thereof.\\n+\\n+      \"Contribution\" shall mean any work of authorship, including\\n+      the original version of the Work and any modifications or additions\\n+      to that Work or Derivative Works thereof, that is intentionally\\n+      submitted to Licensor for inclusion in the Work by the copyright owner\\n+      or by an individual or Legal Entity authorized to submit on behalf of\\n+      the copyright owner. For the purposes of this definition, \"submitted\"\\n+      means any form of electronic, verbal, or written communication sent\\n+      to the Licensor or its representatives, including but not limited to\\n+      communication on electronic mailing lists, source code control systems,\\n+      and issue tracking systems that are managed by, or on behalf of, the\\n+      Licensor for the purpose of discussing and improving the Work, but\\n+      excluding communication that is conspicuously marked or otherwise\\n+      designated in writing by the copyright owner as \"Not a Contribution.\"\\n+\\n+      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n+      on behalf of whom a Contribution has been received by Licensor and\\n+      subsequently incorporated within the Work.\\n+\\n+   2. Grant of Copyright License. Subject to the terms and conditions of\\n+      this License, each Contributor hereby grants to You a perpetual,\\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n+      copyright license to reproduce, prepare Derivative Works of,\\n+      publicly display, publicly perform, sublicense, and distribute the\\n+      Work and such Derivative Works in Source or Object form.\\n+\\n+   3. Grant of Patent License. Subject to the terms and conditions of\\n+      this License, each Contributor hereby grants to You a perpetual,\\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n+      (except as stated in this section) patent license to make, have made,\\n+      use, offer to sell, sell, import, and otherwise transfer the Work,\\n+      where such license applies only to those patent claims licensable\\n+      by such Contributor that are necessarily infringed by their\\n+      Contribution(s) alone or by combination of their Contribution(s)\\n+      with the Work to which such Contribution(s) was submitted. If You\\n+      institute patent litigation against any entity (including a\\n+      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n+      or a Contribution incorporated within the Work constitutes direct\\n+      or contributory patent infringement, then any patent licenses\\n+      granted to You under this License for that Work shall terminate\\n+      as of the date such litigation is filed.\\n+\\n+   4. Redistribution. You may reproduce and distribute copies of the\\n+      Work or Derivative Works thereof in any medium, with or without\\n+      modifications, and in Source or Object form, provided that You\\n+      meet the following conditions:\\n+\\n+      (a) You must give any other recipients of the Work or\\n+          Derivative Works a copy of this License; and\\n+\\n+      (b) You must cause any modified files to carry prominent notices\\n+          stating that You changed the files; and\\n+\\n+      (c) You must retain, in the Source form of any Derivative Works\\n+          that You distribute, all copyright, patent, trademark, and\\n+          attribution notices from the Source form of the Work,\\n+          excluding those notices that do not pertain to any part of\\n+          the Derivative Works; and\\n+\\n+      (d) If the Work includes a \"NOTICE\" text file as part of its\\n+          distribution, then any Derivative Works that You distribute must\\n+          include a readable copy of the attribution notices contained\\n+          within such NOTICE file, excluding those notices that do not\\n+          pertain to any part of the Derivative Works, in at least one\\n+          of the following places: within a NOTICE text file distributed\\n+          as part of the Derivative Works; within the Source form or\\n+          documentation, if provided along with the Derivative Works; or,\\n+          within a display generated by the Derivative Works, if and\\n+          wherever such third-party notices normally appear. The contents\\n+          of the NOTICE file are for informational purposes only and\\n+          do not modify the License. You may add Your own attribution\\n+          notices within Derivative Works that You distribute, alongside\\n+          or as an addendum to the NOTICE text from the Work, provided\\n+          that such additional attribution notices cannot be construed\\n+          as modifying the License.\\n+\\n+      You may add Your own copyright statement to Your modifications and\\n+      may provide additional or different license terms and conditions\\n+      for use, reproduction, or distribution of Your modifications, or\\n+      for any such Derivative Works as a whole, provided Your use,\\n+      reproduction, and distribution of the Work otherwise complies with\\n+      the conditions stated in this License.\\n+\\n+   5. Submission of Contributions. Unless You explicitly state otherwise,\\n+      any Contribution intentionally submitted for inclusion in the Work\\n+      by You to the Licensor shall be under the terms and conditions of\\n+      this License, without any additional terms or conditions.\\n+      Notwithstanding the above, nothing herein shall supersede or modify\\n+      the terms of any separate license agreement you may have executed\\n+      with Licensor regarding such Contributions.\\n+\\n+   6. Trademarks. This License does not grant permission to use the trade\\n+      names, trademarks, service marks, or product names of the Licensor,\\n+      except as required for reasonable and customary use in describing the\\n+      origin of the Work and reproducing the content of the NOTICE file.\\n+\\n+   7. Disclaimer of Warranty. Unless required by applicable law or\\n+      agreed to in writing, Licensor provides the Work (and each\\n+      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n+      implied, including, without limitation, any warranties or conditions\\n+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n+      PARTICULAR PURPOSE. You are solely responsible for determining the\\n+      appropriateness of using or redistributing the Work and assume any\\n+      risks associated with Your exercise of permissions under this License.\\n+\\n+   8. Limitation of Liability. In no event and under no legal theory,\\n+      whether in tort (including negligence), contract, or otherwise,\\n+      unless required by applicable law (such as deliberate and grossly\\n+      negligent acts) or agreed to in writing, shall any Contributor be\\n+      liable to You for damages, including any direct, indirect, special,\\n+      incidental, or consequential damages of any character arising as a\\n+      result of this License or out of the use or inability to use the\\n+      Work (including but not limited to damages for loss of goodwill,\\n+      work stoppage, computer failure or malfunction, or any and all\\n+      other commercial damages or losses), even if such Contributor\\n+      has been advised of the possibility of such damages.\\n+\\n+   9. Accepting Warranty or Additional Liability. While redistributing\\n+      the Work or Derivative Works thereof, You may choose to offer,\\n+      and charge a fee for, acceptance of support, warranty, indemnity,\\n+      or other liability obligations and/or rights consistent with this\\n+      License. However, in accepting such obligations, You may act only\\n+      on Your own behalf and on Your sole responsibility, not on behalf\\n+      of any other Contributor, and only if You agree to indemnify,\\n+      defend, and hold each Contributor harmless for any liability\\n+      incurred by, or claims asserted against, such Contributor by reason\\n+      of your accepting any such warranty or additional liability.\\n+\\n+   END OF TERMS AND CONDITIONS\\n+\\n+   APPENDIX: How to apply the Apache License to your work.\\n+\\n+      To apply the Apache License to your work, attach the following\\n+      boilerplate notice, with the fields enclosed by brackets \"[]\"\\n+      replaced with your own identifying information. (Don't include\\n+      the brackets!)  The text should be enclosed in the appropriate\\n+      comment syntax for the file format. We also recommend that a\\n+      file or class name and description of purpose be included on the\\n+      same \"printed page\" as the copyright notice for easier\\n+      identification within third-party archives.\\n+\\n+   Copyright [yyyy] [name of copyright owner]\\n+\\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\\n+   you may not use this file except in compliance with the License.\\n+   You may obtain a copy of the License at\\n+\\n+       http://www.apache.org/licenses/LICENSE-2.0\\n+\\n+   Unless required by applicable law or agreed to in writing, software\\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n+   See the License for the specific language governing permissions and\\n+   limitations under the License.\\n</td>\n",
              "      <td>Command '['git', '-C', 'maxtext', 'diff', '--histogram', '696b089f888e57a468184d382e56b862985640f2^', '696b089f888e57a468184d382e56b862985640f2', '--', 'LICENSE']' returned non-zero exit status 128.</td>\n",
              "      <td>license</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>maxtext</td>\n",
              "      <td>NaN</td>\n",
              "      <td>.gitignore</td>\n",
              "      <td>ef558122cde2877c82671fe23fa2ab408552c522</td>\n",
              "      <td>696b089f888e57a468184d382e56b862985640f2</td>\n",
              "      <td>Hard-forking a codebase generously shared by Anselm/JET</td>\n",
              "      <td>@@ -0,0 +1 @@\\n+*__pycache__*\\n</td>\n",
              "      <td>diff --git a/.gitignore b/.gitignore\\nnew file mode 100644\\nindex 00000000..cd4c22c4\\n--- /dev/null\\n+++ b/.gitignore\\n@@ -0,0 +1 @@\\n+*__pycache__*\\n</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>maxtext</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MaxText/__init__.py</td>\n",
              "      <td>ef558122cde2877c82671fe23fa2ab408552c522</td>\n",
              "      <td>696b089f888e57a468184d382e56b862985640f2</td>\n",
              "      <td>Hard-forking a codebase generously shared by Anselm/JET</td>\n",
              "      <td>@@ -0,0 +1 @@\\n+# adhd\\n</td>\n",
              "      <td>diff --git a/MaxText/__init__.py b/MaxText/__init__.py\\nnew file mode 100644\\nindex 00000000..f424dbec\\n--- /dev/null\\n+++ b/MaxText/__init__.py\\n@@ -0,0 +1 @@\\n+# adhd\\n</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>maxtext</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MaxText/config.py</td>\n",
              "      <td>ef558122cde2877c82671fe23fa2ab408552c522</td>\n",
              "      <td>696b089f888e57a468184d382e56b862985640f2</td>\n",
              "      <td>Hard-forking a codebase generously shared by Anselm/JET</td>\n",
              "      <td>@@ -0,0 +1,66 @@\\n+\"\"\"Config for training.\"\"\"\\n+\\n+from typing import Any, Sequence, Tuple\\n+from flax import struct\\n+import jax.numpy as jnp\\n+\\n+\\n+@struct.dataclass\\n+class T5Config:\\n+  \"\"\"Global hyperparameters used to minimize obnoxious kwarg plumbing.\"\"\"\\n+\\n+  # Activation dtypes.\\n+  dtype: Any = jnp.float32\\n+  emb_dim: int = 128\\n+  num_heads: int = 8\\n+  head_dim: int = 16\\n+  mlp_dim: int = 512\\n+  num_decoder_layers: int = 6\\n+  # activation functions are .\\n+  mlp_activations: Sequence[str] = ('relu',)\\n+  dropout_rate: float = 0\\n+  # If `True`, the embedding weights are used in the decoder output layer.\\n+  logits_via_embedding: bool = True  # NOTE: this is True just for testing.\\n+  # minimal, full, or none\\n+  remat_policy: str = 'none'\\n+  scan_layers: bool = False\\n+  param_scan_axis: int = 1\\n+\\n+  # Parallelism\\n+  mesh_shape: Tuple[int] = (4,)\\n+  mesh_axes: Tuple[str] = ('data',)\\n+  logical_axis_rules: Sequence = ( ('batch', 'data'), )\\n+\\n+  # Dataset\\n+  vocab_size: int = 30000\\n+  dataset_name: str = 'lm1b'\\n+  eval_dataset_name: str = 'lm1b'\\n+  eval_split: str = 'test'\\n+  per_device_batch_size: int = 32\\n+  eval_per_device_batch_size: int = 0\\n+  max_corpus_chars: int = 10**7  # for tokenization\\n+\\n+  # Training loop\\n+  steps: int = 20_000_000\\n+  log_period: int = 500\\n+  save_period: int = 2000\\n+  learning_rate: float = 1e-3\\n+  warmup_steps: int = 1000\\n+  save_checkpoints: bool = False\\n+  restore_checkpoints: bool = False\\n+\\n+  # Maximum length cutoff for training examples.\\n+  max_target_length: int = 128\\n+  # Maximum length cutoff for held-out evaluation examples.\\n+  max_eval_target_length: int = 512\\n+\\n+  # Maximum length cutoff for predicted tokens.\\n+  max_predict_length: int = 50\\n+  # Sampling temperature for language model inference.\\n+  sampling_temperature: float = 0.6\\n+  # Top k cutoff for logit sampling. If 0 then no top-k cutoff is used.\\n+  sampling_top_k: int = 20\\n+  eos_id: int = 2  # sentencepiece default\\n+  # Prompt for language model sampling.\\n+  prompt: str = \"I love to \"\\n+\\n</td>\n",
              "      <td>diff --git a/MaxText/config.py b/MaxText/config.py\\nnew file mode 100644\\nindex 00000000..71317091\\n--- /dev/null\\n+++ b/MaxText/config.py\\n@@ -0,0 +1,66 @@\\n+\"\"\"Config for training.\"\"\"\\n+\\n+from typing import Any, Sequence, Tuple\\n+from flax import struct\\n+import jax.numpy as jnp\\n+\\n+\\n+@struct.dataclass\\n+class T5Config:\\n+  \"\"\"Global hyperparameters used to minimize obnoxious kwarg plumbing.\"\"\"\\n+\\n+  # Activation dtypes.\\n+  dtype: Any = jnp.float32\\n+  emb_dim: int = 128\\n+  num_heads: int = 8\\n+  head_dim: int = 16\\n+  mlp_dim: int = 512\\n+  num_decoder_layers: int = 6\\n+  # activation functions are .\\n+  mlp_activations: Sequence[str] = ('relu',)\\n+  dropout_rate: float = 0\\n+  # If `True`, the embedding weights are used in the decoder output layer.\\n+  logits_via_embedding: bool = True  # NOTE: this is True just for testing.\\n+  # minimal, full, or none\\n+  remat_policy: str = 'none'\\n+  scan_layers: bool = False\\n+  param_scan_axis: int = 1\\n+\\n+  # Parallelism\\n+  mesh_shape: Tuple[int] = (4,)\\n+  mesh_axes: Tuple[str] = ('data',)\\n+  logical_axis_rules: Sequence = ( ('batch', 'data'), )\\n+\\n+  # Dataset\\n+  vocab_size: int = 30000\\n+  dataset_name: str = 'lm1b'\\n+  eval_dataset_name: str = 'lm1b'\\n+  eval_split: str = 'test'\\n+  per_device_batch_size: int = 32\\n+  eval_per_device_batch_size: int = 0\\n+  max_corpus_chars: int = 10**7  # for tokenization\\n+\\n+  # Training loop\\n+  steps: int = 20_000_000\\n+  log_period: int = 500\\n+  save_period: int = 2000\\n+  learning_rate: float = 1e-3\\n+  warmup_steps: int = 1000\\n+  save_checkpoints: bool = False\\n+  restore_checkpoints: bool = False\\n+\\n+  # Maximum length cutoff for training examples.\\n+  max_target_length: int = 128\\n+  # Maximum length cutoff for held-out evaluation examples.\\n+  max_eval_target_length: int = 512\\n+\\n+  # Maximum length cutoff for predicted tokens.\\n+  max_predict_length: int = 50\\n+  # Sampling temperature for language model inference.\\n+  sampling_temperature: float = 0.6\\n+  # Top k cutoff for logit sampling. If 0 then no top-k cutoff is used.\\n+  sampling_top_k: int = 20\\n+  eos_id: int = 2  # sentencepiece default\\n+  # Prompt for language model sampling.\\n+  prompt: str = \"I love to \"\\n+\\n</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>maxtext</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MaxText/input_pipeline.py</td>\n",
              "      <td>ef558122cde2877c82671fe23fa2ab408552c522</td>\n",
              "      <td>696b089f888e57a468184d382e56b862985640f2</td>\n",
              "      <td>Hard-forking a codebase generously shared by Anselm/JET</td>\n",
              "      <td>@@ -0,0 +1,340 @@\\n+\"\"\"Input pipeline for a LM1B dataset.\"\"\"\\n+\\n+import os\\n+from typing import Dict, Optional, List, Union\\n+\\n+from clu import deterministic_data\\n+import ml_collections\\n+import tensorflow as tf\\n+import tensorflow_datasets as tfds\\n+\\n+from adhd import tokenizer\\n+\\n+AUTOTUNE = tf.data.experimental.AUTOTUNE\\n+Features = Dict[str, tf.Tensor]\\n+\\n+\\n+class NormalizeFeatureNamesOp:\\n+  \"\"\"Normalizes feature names to 'inputs' and 'targets'.\"\"\"\\n+\\n+  def __init__(self, ds_info: tfds.core.DatasetInfo):\\n+    self.ds_info = ds_info\\n+\\n+  def __call__(self, features: Features) -&gt; Features:\\n+    features['inputs'] = features.pop('text')\\n+    # Unnecessary step used for uniformizing with examples/wmt.\\n+    features['targets'] = features['inputs']\\n+    return features\\n+\\n+\\n+def get_raw_dataset(dataset_builder: tfds.core.DatasetBuilder,\\n+                    split: str) -&gt; tf.data.Dataset:\\n+  \"\"\"Loads a raw text dataset and normalizes feature keys.\\n+  Args:\\n+    dataset_builder: TFDS dataset builder that can build `split`.\\n+    split: Split to use. This must be the full split. We shard the split across\\n+      multiple hosts and currently don't support sharding subsplits.\\n+  Returns:\\n+    Dataset with source and target language features mapped to 'inputs' and\\n+    'targets'.\\n+  \"\"\"\\n+  per_host_split = tfds.split_for_jax_process(split, drop_remainder=False)\\n+  ds = dataset_builder.as_dataset(split=per_host_split, shuffle_files=False)\\n+  ds = ds.map(\\n+      NormalizeFeatureNamesOp(dataset_builder.info),\\n+      num_parallel_calls=AUTOTUNE)\\n+  return ds\\n+\\n+\\n+def pack_dataset(dataset: tf.data.Dataset,\\n+                 key2length: Union[int, Dict[str, int]],\\n+                 keys: Optional[List[str]] = None) -&gt; tf.data.Dataset:\\n+  \"\"\"Creates a 'packed' version of a dataset on-the-fly.\\n+  Adapted from the mesh-tf implementation.\\n+  This is meant to replace the irritation of having to create a separate\\n+  \"packed\" version of a dataset to train efficiently on TPU.\\n+  Each example in the output dataset represents several examples in the\\n+  input dataset.\\n+  For each key in the input dataset, two additional keys are created:\\n+  &lt;key&gt;_segmentation: an int32 tensor identifying the parts\\n+     representing the original example.\\n+  &lt;key&gt;_position: an int32 tensor identifying the position within the original\\n+     example.\\n+  Example:\\n+  Two input examples get combined to form an output example.\\n+  The input examples are:\\n+  {\"inputs\": [8, 7, 1, 0], \"targets\":[4, 1, 0]}\\n+  {\"inputs\": [2, 3, 4, 1], \"targets\":[5, 6, 1]}\\n+  The output example is:\\n+  {\\n+                 \"inputs\": [8, 7, 1, 2, 3, 4, 1, 0, 0, 0]\\n+    \"inputs_segmentation\": [1, 1, 1, 2, 2, 2, 2, 0, 0, 0]\\n+        \"inputs_position\": [0, 1, 2, 0, 1, 2, 3, 0, 0, 0]\\n+                \"targets\": [4, 1, 5, 6, 1, 0, 0, 0, 0, 0]\\n+   \"targets_segmentation\": [1, 1, 2, 2, 2, 0, 0, 0, 0, 0]\\n+       \"targets_position\": [0, 1, 0, 1, 2, 0, 0, 0, 0, 0]\\n+  }\\n+  0 represents padding in both the inputs and the outputs.\\n+  Sequences in the incoming examples are truncated to length \"length\", and the\\n+  sequences in the output examples all have fixed (padded) length \"length\".\\n+  Args:\\n+    dataset: a tf.data.Dataset\\n+    key2length: an integer, or a dict from feature-key to integer\\n+    keys: a list of strings (e.g. [\"inputs\", \"targets\"])\\n+  Returns:\\n+    a tf.data.Dataset\\n+  \"\"\"\\n+  shapes = tf.nest.map_structure(lambda spec: spec.shape, dataset.element_spec)\\n+  if keys is None:\\n+    keys = list(shapes.keys())\\n+  for k in keys:\\n+    if k not in shapes:\\n+      raise ValueError('Key %s not found in dataset.  Available keys are %s' %\\n+                       (k, shapes.keys()))\\n+    if not shapes[k].is_compatible_with(tf.TensorShape([None])):\\n+      raise ValueError('Tensors to be packed must be one-dimensional.')\\n+  # make sure that the length dictionary contains all keys as well as the\\n+  # keys suffixed by \"_segmentation\" and \"_position\"\\n+  if isinstance(key2length, int):\\n+    key2length = {k: key2length for k in keys}\\n+  for k in keys:\\n+    for suffix in ['_segmentation', '_position']:\\n+      key2length[k + suffix] = key2length[k]\\n+\\n+  # trim to length\\n+  dataset = dataset.map(\\n+      lambda x: {k: x[k][:key2length[k]] for k in keys},\\n+      num_parallel_calls=AUTOTUNE)\\n+  # Setting batch_size=length ensures that the concatenated sequences (if they\\n+  # have length &gt;=1) are sufficient to fill at least one packed example.\\n+  batch_size = max(key2length.values())\\n+  dataset = dataset.padded_batch(\\n+      batch_size, padded_shapes={k: [-1] for k in keys})\\n+  dataset = _pack_with_tf_ops(dataset, keys, key2length)\\n+\\n+  # Set the Tensor shapes correctly since they get lost in the process.\\n+  def my_fn(x):\\n+    return {k: tf.reshape(v, [key2length[k]]) for k, v in x.items()}\\n+\\n+  return dataset.map(my_fn, num_parallel_calls=AUTOTUNE)\\n+\\n+\\n+def _pack_with_tf_ops(dataset: tf.data.Dataset, keys: List[str],\\n+                      key2length: Dict[str, int]) -&gt; tf.data.Dataset:\\n+  \"\"\"Helper-function for packing a dataset which has already been batched.\\n+  Helper for pack_dataset()  Uses tf.while_loop.\\n+  Args:\\n+    dataset: a dataset containing padded batches of examples.\\n+    keys: a list of strings\\n+    key2length: an dict from feature-key to integer\\n+  Returns:\\n+    a dataset.\\n+  \"\"\"\\n+  empty_example = {}\\n+  for k in keys:\\n+    empty_example[k] = tf.zeros([0], dtype=tf.int32)\\n+    empty_example[k + '_position'] = tf.zeros([0], dtype=tf.int32)\\n+  keys_etc = empty_example.keys()\\n+\\n+  def write_packed_example(partial, outputs):\\n+    new_partial = empty_example.copy()\\n+    new_outputs = {}\\n+    for k in keys_etc:\\n+      new_outputs[k] = outputs[k].write(\\n+          outputs[k].size(),\\n+          tf.pad(partial[k], [[0, key2length[k] - tf.size(partial[k])]]))\\n+    return new_partial, new_outputs\\n+\\n+  def map_fn(x):\\n+    \"\"\"Internal function to flat_map over.\\n+    Consumes a batch of input examples and produces a variable number of output\\n+    examples.\\n+    Args:\\n+      x: a single example\\n+    Returns:\\n+      a tf.data.Dataset\\n+    \"\"\"\\n+    partial = empty_example.copy()\\n+    i = tf.zeros([], dtype=tf.int32)\\n+    dynamic_batch_size = tf.shape(x[keys[0]])[0]\\n+    outputs = {}\\n+    for k in keys:\\n+      outputs[k] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+      outputs[k + '_position'] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+\\n+    def body_fn(i, partial, outputs):\\n+      \"\"\"Body function for while_loop.\\n+      Args:\\n+        i: integer scalar\\n+        partial: dictionary of Tensor (partially-constructed example)\\n+        outputs: dictionary of TensorArray\\n+      Returns:\\n+        A triple containing the new values of the inputs.\\n+      \"\"\"\\n+      can_append = True\\n+      one_example = {}\\n+      for k in keys:\\n+        val = tf.cast(x[k][i], tf.int32)\\n+        val = val[:tf.reduce_sum(tf.cast(tf.not_equal(val, 0), tf.int32))]\\n+        one_example[k] = val\\n+      for k in keys:\\n+        can_append = tf.logical_and(\\n+            can_append,\\n+            tf.less_equal(\\n+                tf.size(partial[k]) + tf.size(one_example[k]), key2length[k]))\\n+\\n+      def false_fn():\\n+        return write_packed_example(partial, outputs)\\n+\\n+      def true_fn():\\n+        return partial, outputs\\n+\\n+      partial, outputs = tf.cond(can_append, true_fn, false_fn)\\n+      new_partial = {}\\n+      for k in keys:\\n+        new_seq = one_example[k][:key2length[k]]\\n+        new_seq_len = tf.size(new_seq)\\n+        new_partial[k] = tf.concat([partial[k], new_seq], 0)\\n+        new_partial[k + '_position'] = tf.concat(\\n+            [partial[k + '_position'],\\n+             tf.range(new_seq_len)], 0)\\n+      partial = new_partial\\n+      return i + 1, partial, outputs\\n+\\n+    # For loop over all examples in the batch.\\n+    i, partial, outputs = tf.while_loop(\\n+        cond=lambda *_: True,\\n+        body=body_fn,\\n+        loop_vars=(i, partial, outputs),\\n+        shape_invariants=(\\n+            tf.TensorShape([]),\\n+            {k: tf.TensorShape([None]) for k in keys_etc},\\n+            {k: tf.TensorShape(None) for k in keys_etc},\\n+        ),\\n+        maximum_iterations=dynamic_batch_size)\\n+    _, outputs = write_packed_example(partial, outputs)\\n+    packed = {k: outputs[k].stack() for k in keys_etc}\\n+    for k in keys:\\n+      packed[k + '_segmentation'] = (\\n+          tf.cumsum(\\n+              tf.cast(tf.equal(packed[k + '_position'], 0), tf.int32), axis=1) *\\n+          tf.cast(tf.not_equal(packed[k], 0), tf.int32))\\n+    return packed\\n+\\n+  dataset = dataset.map(map_fn, num_parallel_calls=AUTOTUNE)\\n+  return dataset.unbatch()\\n+\\n+\\n+# -----------------------------------------------------------------------------\\n+# Main dataset prep routines.\\n+# -----------------------------------------------------------------------------\\n+def preprocess_data(dataset,\\n+                    shuffle: bool,\\n+                    num_epochs: Optional[int] = 1,\\n+                    pack_examples: bool = True,\\n+                    shuffle_buffer_size: int = 1024,\\n+                    max_length: int = 512,\\n+                    batch_size: int = 256,\\n+                    drop_remainder: bool = True,\\n+                    prefetch_size: int = AUTOTUNE):\\n+  \"\"\"Shuffle and batch/pack the given dataset.\"\"\"\\n+\\n+  def length_filter(max_len):\\n+\\n+    def filter_fn(x):\\n+      source, target = x['inputs'], x['targets']\\n+      l = tf.maximum(tf.shape(source)[0], tf.shape(target)[0])\\n+      return tf.less(l, max_len + 1)\\n+\\n+    return filter_fn\\n+\\n+  if max_length &gt; 0:\\n+    dataset = dataset.filter(length_filter(max_length))\\n+\\n+  if shuffle:\\n+    dataset = dataset.shuffle(shuffle_buffer_size)\\n+  dataset = dataset.repeat(num_epochs)\\n+\\n+  if pack_examples:\\n+    dataset = pack_dataset(dataset, max_length)\\n+    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\\n+  else:  # simple (static-shape) padded batching\\n+    dataset = dataset.padded_batch(\\n+        batch_size,\\n+        padded_shapes={\\n+            'inputs': max_length,\\n+            'targets': max_length\\n+        },\\n+        padding_values={\\n+            'inputs': 0,\\n+            'targets': 0\\n+        },\\n+        drop_remainder=drop_remainder)\\n+\\n+  if prefetch_size:\\n+    dataset = dataset.prefetch(prefetch_size)\\n+\\n+  return dataset\\n+\\n+\\n+def get_datasets(config: ml_collections.ConfigDict,\\n+                 *,\\n+                 n_devices: int,\\n+                 vocab_path: Optional[str] = None):\\n+  \"\"\"Load and return dataset of batched examples for use during training.\"\"\"\\n+  if vocab_path is None:\\n+    vocab_path = os.path.expanduser('~/lm1b_sentencepiece_model')\\n+\\n+  train_ds_builder = tfds.builder(config.dataset_name)\\n+  train_ds_builder.download_and_prepare()\\n+  train_data = get_raw_dataset(train_ds_builder, 'train')\\n+\\n+  if config.eval_dataset_name:\\n+    eval_ds_builder = tfds.builder(config.eval_dataset_name)\\n+  else:\\n+    eval_ds_builder = train_ds_builder\\n+  eval_data = get_raw_dataset(eval_ds_builder, config.eval_split)\\n+\\n+  # Tokenize data.\\n+  sp_tokenizer = tokenizer.load_or_train_tokenizer(\\n+      train_data,\\n+      vocab_path=vocab_path,\\n+      vocab_size=config.vocab_size,\\n+      max_corpus_chars=config.max_corpus_chars)\\n+  train_data = train_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+  eval_data = eval_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+\\n+  batch_size = config.per_device_batch_size * n_devices\\n+  if config.eval_per_device_batch_size &gt; 0:\\n+    eval_batch_size = config.eval_per_device_batch_size * n_devices\\n+  else:\\n+    eval_batch_size = batch_size\\n+\\n+  train_ds = preprocess_data(\\n+      train_data,\\n+      shuffle=True,\\n+      num_epochs=None,\\n+      pack_examples=True,\\n+      batch_size=batch_size,\\n+      max_length=config.max_target_length)\\n+\\n+  eval_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_eval_target_length)\\n+\\n+  predict_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_predict_length,\\n+      drop_remainder=False)\\n+\\n+  return train_ds, eval_ds, predict_ds, sp_tokenizer\\n</td>\n",
              "      <td>diff --git a/MaxText/input_pipeline.py b/MaxText/input_pipeline.py\\nnew file mode 100644\\nindex 00000000..8328ccad\\n--- /dev/null\\n+++ b/MaxText/input_pipeline.py\\n@@ -0,0 +1,340 @@\\n+\"\"\"Input pipeline for a LM1B dataset.\"\"\"\\n+\\n+import os\\n+from typing import Dict, Optional, List, Union\\n+\\n+from clu import deterministic_data\\n+import ml_collections\\n+import tensorflow as tf\\n+import tensorflow_datasets as tfds\\n+\\n+from adhd import tokenizer\\n+\\n+AUTOTUNE = tf.data.experimental.AUTOTUNE\\n+Features = Dict[str, tf.Tensor]\\n+\\n+\\n+class NormalizeFeatureNamesOp:\\n+  \"\"\"Normalizes feature names to 'inputs' and 'targets'.\"\"\"\\n+\\n+  def __init__(self, ds_info: tfds.core.DatasetInfo):\\n+    self.ds_info = ds_info\\n+\\n+  def __call__(self, features: Features) -&gt; Features:\\n+    features['inputs'] = features.pop('text')\\n+    # Unnecessary step used for uniformizing with examples/wmt.\\n+    features['targets'] = features['inputs']\\n+    return features\\n+\\n+\\n+def get_raw_dataset(dataset_builder: tfds.core.DatasetBuilder,\\n+                    split: str) -&gt; tf.data.Dataset:\\n+  \"\"\"Loads a raw text dataset and normalizes feature keys.\\n+  Args:\\n+    dataset_builder: TFDS dataset builder that can build `split`.\\n+    split: Split to use. This must be the full split. We shard the split across\\n+      multiple hosts and currently don't support sharding subsplits.\\n+  Returns:\\n+    Dataset with source and target language features mapped to 'inputs' and\\n+    'targets'.\\n+  \"\"\"\\n+  per_host_split = tfds.split_for_jax_process(split, drop_remainder=False)\\n+  ds = dataset_builder.as_dataset(split=per_host_split, shuffle_files=False)\\n+  ds = ds.map(\\n+      NormalizeFeatureNamesOp(dataset_builder.info),\\n+      num_parallel_calls=AUTOTUNE)\\n+  return ds\\n+\\n+\\n+def pack_dataset(dataset: tf.data.Dataset,\\n+                 key2length: Union[int, Dict[str, int]],\\n+                 keys: Optional[List[str]] = None) -&gt; tf.data.Dataset:\\n+  \"\"\"Creates a 'packed' version of a dataset on-the-fly.\\n+  Adapted from the mesh-tf implementation.\\n+  This is meant to replace the irritation of having to create a separate\\n+  \"packed\" version of a dataset to train efficiently on TPU.\\n+  Each example in the output dataset represents several examples in the\\n+  input dataset.\\n+  For each key in the input dataset, two additional keys are created:\\n+  &lt;key&gt;_segmentation: an int32 tensor identifying the parts\\n+     representing the original example.\\n+  &lt;key&gt;_position: an int32 tensor identifying the position within the original\\n+     example.\\n+  Example:\\n+  Two input examples get combined to form an output example.\\n+  The input examples are:\\n+  {\"inputs\": [8, 7, 1, 0], \"targets\":[4, 1, 0]}\\n+  {\"inputs\": [2, 3, 4, 1], \"targets\":[5, 6, 1]}\\n+  The output example is:\\n+  {\\n+                 \"inputs\": [8, 7, 1, 2, 3, 4, 1, 0, 0, 0]\\n+    \"inputs_segmentation\": [1, 1, 1, 2, 2, 2, 2, 0, 0, 0]\\n+        \"inputs_position\": [0, 1, 2, 0, 1, 2, 3, 0, 0, 0]\\n+                \"targets\": [4, 1, 5, 6, 1, 0, 0, 0, 0, 0]\\n+   \"targets_segmentation\": [1, 1, 2, 2, 2, 0, 0, 0, 0, 0]\\n+       \"targets_position\": [0, 1, 0, 1, 2, 0, 0, 0, 0, 0]\\n+  }\\n+  0 represents padding in both the inputs and the outputs.\\n+  Sequences in the incoming examples are truncated to length \"length\", and the\\n+  sequences in the output examples all have fixed (padded) length \"length\".\\n+  Args:\\n+    dataset: a tf.data.Dataset\\n+    key2length: an integer, or a dict from feature-key to integer\\n+    keys: a list of strings (e.g. [\"inputs\", \"targets\"])\\n+  Returns:\\n+    a tf.data.Dataset\\n+  \"\"\"\\n+  shapes = tf.nest.map_structure(lambda spec: spec.shape, dataset.element_spec)\\n+  if keys is None:\\n+    keys = list(shapes.keys())\\n+  for k in keys:\\n+    if k not in shapes:\\n+      raise ValueError('Key %s not found in dataset.  Available keys are %s' %\\n+                       (k, shapes.keys()))\\n+    if not shapes[k].is_compatible_with(tf.TensorShape([None])):\\n+      raise ValueError('Tensors to be packed must be one-dimensional.')\\n+  # make sure that the length dictionary contains all keys as well as the\\n+  # keys suffixed by \"_segmentation\" and \"_position\"\\n+  if isinstance(key2length, int):\\n+    key2length = {k: key2length for k in keys}\\n+  for k in keys:\\n+    for suffix in ['_segmentation', '_position']:\\n+      key2length[k + suffix] = key2length[k]\\n+\\n+  # trim to length\\n+  dataset = dataset.map(\\n+      lambda x: {k: x[k][:key2length[k]] for k in keys},\\n+      num_parallel_calls=AUTOTUNE)\\n+  # Setting batch_size=length ensures that the concatenated sequences (if they\\n+  # have length &gt;=1) are sufficient to fill at least one packed example.\\n+  batch_size = max(key2length.values())\\n+  dataset = dataset.padded_batch(\\n+      batch_size, padded_shapes={k: [-1] for k in keys})\\n+  dataset = _pack_with_tf_ops(dataset, keys, key2length)\\n+\\n+  # Set the Tensor shapes correctly since they get lost in the process.\\n+  def my_fn(x):\\n+    return {k: tf.reshape(v, [key2length[k]]) for k, v in x.items()}\\n+\\n+  return dataset.map(my_fn, num_parallel_calls=AUTOTUNE)\\n+\\n+\\n+def _pack_with_tf_ops(dataset: tf.data.Dataset, keys: List[str],\\n+                      key2length: Dict[str, int]) -&gt; tf.data.Dataset:\\n+  \"\"\"Helper-function for packing a dataset which has already been batched.\\n+  Helper for pack_dataset()  Uses tf.while_loop.\\n+  Args:\\n+    dataset: a dataset containing padded batches of examples.\\n+    keys: a list of strings\\n+    key2length: an dict from feature-key to integer\\n+  Returns:\\n+    a dataset.\\n+  \"\"\"\\n+  empty_example = {}\\n+  for k in keys:\\n+    empty_example[k] = tf.zeros([0], dtype=tf.int32)\\n+    empty_example[k + '_position'] = tf.zeros([0], dtype=tf.int32)\\n+  keys_etc = empty_example.keys()\\n+\\n+  def write_packed_example(partial, outputs):\\n+    new_partial = empty_example.copy()\\n+    new_outputs = {}\\n+    for k in keys_etc:\\n+      new_outputs[k] = outputs[k].write(\\n+          outputs[k].size(),\\n+          tf.pad(partial[k], [[0, key2length[k] - tf.size(partial[k])]]))\\n+    return new_partial, new_outputs\\n+\\n+  def map_fn(x):\\n+    \"\"\"Internal function to flat_map over.\\n+    Consumes a batch of input examples and produces a variable number of output\\n+    examples.\\n+    Args:\\n+      x: a single example\\n+    Returns:\\n+      a tf.data.Dataset\\n+    \"\"\"\\n+    partial = empty_example.copy()\\n+    i = tf.zeros([], dtype=tf.int32)\\n+    dynamic_batch_size = tf.shape(x[keys[0]])[0]\\n+    outputs = {}\\n+    for k in keys:\\n+      outputs[k] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+      outputs[k + '_position'] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+\\n+    def body_fn(i, partial, outputs):\\n+      \"\"\"Body function for while_loop.\\n+      Args:\\n+        i: integer scalar\\n+        partial: dictionary of Tensor (partially-constructed example)\\n+        outputs: dictionary of TensorArray\\n+      Returns:\\n+        A triple containing the new values of the inputs.\\n+      \"\"\"\\n+      can_append = True\\n+      one_example = {}\\n+      for k in keys:\\n+        val = tf.cast(x[k][i], tf.int32)\\n+        val = val[:tf.reduce_sum(tf.cast(tf.not_equal(val, 0), tf.int32))]\\n+        one_example[k] = val\\n+      for k in keys:\\n+        can_append = tf.logical_and(\\n+            can_append,\\n+            tf.less_equal(\\n+                tf.size(partial[k]) + tf.size(one_example[k]), key2length[k]))\\n+\\n+      def false_fn():\\n+        return write_packed_example(partial, outputs)\\n+\\n+      def true_fn():\\n+        return partial, outputs\\n+\\n+      partial, outputs = tf.cond(can_append, true_fn, false_fn)\\n+      new_partial = {}\\n+      for k in keys:\\n+        new_seq = one_example[k][:key2length[k]]\\n+        new_seq_len = tf.size(new_seq)\\n+        new_partial[k] = tf.concat([partial[k], new_seq], 0)\\n+        new_partial[k + '_position'] = tf.concat(\\n+            [partial[k + '_position'],\\n+             tf.range(new_seq_len)], 0)\\n+      partial = new_partial\\n+      return i + 1, partial, outputs\\n+\\n+    # For loop over all examples in the batch.\\n+    i, partial, outputs = tf.while_loop(\\n+        cond=lambda *_: True,\\n+        body=body_fn,\\n+        loop_vars=(i, partial, outputs),\\n+        shape_invariants=(\\n+            tf.TensorShape([]),\\n+            {k: tf.TensorShape([None]) for k in keys_etc},\\n+            {k: tf.TensorShape(None) for k in keys_etc},\\n+        ),\\n+        maximum_iterations=dynamic_batch_size)\\n+    _, outputs = write_packed_example(partial, outputs)\\n+    packed = {k: outputs[k].stack() for k in keys_etc}\\n+    for k in keys:\\n+      packed[k + '_segmentation'] = (\\n+          tf.cumsum(\\n+              tf.cast(tf.equal(packed[k + '_position'], 0), tf.int32), axis=1) *\\n+          tf.cast(tf.not_equal(packed[k], 0), tf.int32))\\n+    return packed\\n+\\n+  dataset = dataset.map(map_fn, num_parallel_calls=AUTOTUNE)\\n+  return dataset.unbatch()\\n+\\n+\\n+# -----------------------------------------------------------------------------\\n+# Main dataset prep routines.\\n+# -----------------------------------------------------------------------------\\n+def preprocess_data(dataset,\\n+                    shuffle: bool,\\n+                    num_epochs: Optional[int] = 1,\\n+                    pack_examples: bool = True,\\n+                    shuffle_buffer_size: int = 1024,\\n+                    max_length: int = 512,\\n+                    batch_size: int = 256,\\n+                    drop_remainder: bool = True,\\n+                    prefetch_size: int = AUTOTUNE):\\n+  \"\"\"Shuffle and batch/pack the given dataset.\"\"\"\\n+\\n+  def length_filter(max_len):\\n+\\n+    def filter_fn(x):\\n+      source, target = x['inputs'], x['targets']\\n+      l = tf.maximum(tf.shape(source)[0], tf.shape(target)[0])\\n+      return tf.less(l, max_len + 1)\\n+\\n+    return filter_fn\\n+\\n+  if max_length &gt; 0:\\n+    dataset = dataset.filter(length_filter(max_length))\\n+\\n+  if shuffle:\\n+    dataset = dataset.shuffle(shuffle_buffer_size)\\n+  dataset = dataset.repeat(num_epochs)\\n+\\n+  if pack_examples:\\n+    dataset = pack_dataset(dataset, max_length)\\n+    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\\n+  else:  # simple (static-shape) padded batching\\n+    dataset = dataset.padded_batch(\\n+        batch_size,\\n+        padded_shapes={\\n+            'inputs': max_length,\\n+            'targets': max_length\\n+        },\\n+        padding_values={\\n+            'inputs': 0,\\n+            'targets': 0\\n+        },\\n+        drop_remainder=drop_remainder)\\n+\\n+  if prefetch_size:\\n+    dataset = dataset.prefetch(prefetch_size)\\n+\\n+  return dataset\\n+\\n+\\n+def get_datasets(config: ml_collections.ConfigDict,\\n+                 *,\\n+                 n_devices: int,\\n+                 vocab_path: Optional[str] = None):\\n+  \"\"\"Load and return dataset of batched examples for use during training.\"\"\"\\n+  if vocab_path is None:\\n+    vocab_path = os.path.expanduser('~/lm1b_sentencepiece_model')\\n+\\n+  train_ds_builder = tfds.builder(config.dataset_name)\\n+  train_ds_builder.download_and_prepare()\\n+  train_data = get_raw_dataset(train_ds_builder, 'train')\\n+\\n+  if config.eval_dataset_name:\\n+    eval_ds_builder = tfds.builder(config.eval_dataset_name)\\n+  else:\\n+    eval_ds_builder = train_ds_builder\\n+  eval_data = get_raw_dataset(eval_ds_builder, config.eval_split)\\n+\\n+  # Tokenize data.\\n+  sp_tokenizer = tokenizer.load_or_train_tokenizer(\\n+      train_data,\\n+      vocab_path=vocab_path,\\n+      vocab_size=config.vocab_size,\\n+      max_corpus_chars=config.max_corpus_chars)\\n+  train_data = train_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+  eval_data = eval_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+\\n+  batch_size = config.per_device_batch_size * n_devices\\n+  if config.eval_per_device_batch_size &gt; 0:\\n+    eval_batch_size = config.eval_per_device_batch_size * n_devices\\n+  else:\\n+    eval_batch_size = batch_size\\n+\\n+  train_ds = preprocess_data(\\n+      train_data,\\n+      shuffle=True,\\n+      num_epochs=None,\\n+      pack_examples=True,\\n+      batch_size=batch_size,\\n+      max_length=config.max_target_length)\\n+\\n+  eval_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_eval_target_length)\\n+\\n+  predict_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_predict_length,\\n+      drop_remainder=False)\\n+\\n+  return train_ds, eval_ds, predict_ds, sp_tokenizer\\n</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92a53358-4096-49c1-9766-32cb9717ff58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92a53358-4096-49c1-9766-32cb9717ff58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92a53358-4096-49c1-9766-32cb9717ff58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fa392901-7afe-430e-98ac-efb6928ae522\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa392901-7afe-430e-98ac-efb6928ae522')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fa392901-7afe-430e-98ac-efb6928ae522 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/maxtext_final.csv\")\n",
        "pd.set_option(\"display.max_colwidth\", None)  # Show full commit messages and diffs\n",
        "display(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vTatO7Xng8uW",
        "outputId": "576322b8-4033-45c7-e023-89b1173ccd83"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  repo_name old_file_path              new_file_path  \\\n",
              "0   maxtext           NaN                    LICENSE   \n",
              "1   maxtext           NaN                 .gitignore   \n",
              "2   maxtext           NaN        MaxText/__init__.py   \n",
              "3   maxtext           NaN          MaxText/config.py   \n",
              "4   maxtext           NaN  MaxText/input_pipeline.py   \n",
              "\n",
              "                                 commit_sha  \\\n",
              "0  696b089f888e57a468184d382e56b862985640f2   \n",
              "1  ef558122cde2877c82671fe23fa2ab408552c522   \n",
              "2  ef558122cde2877c82671fe23fa2ab408552c522   \n",
              "3  ef558122cde2877c82671fe23fa2ab408552c522   \n",
              "4  ef558122cde2877c82671fe23fa2ab408552c522   \n",
              "\n",
              "                          parent_commit_sha  \\\n",
              "0                                       NaN   \n",
              "1  696b089f888e57a468184d382e56b862985640f2   \n",
              "2  696b089f888e57a468184d382e56b862985640f2   \n",
              "3  696b089f888e57a468184d382e56b862985640f2   \n",
              "4  696b089f888e57a468184d382e56b862985640f2   \n",
              "\n",
              "                                            commit_message  \\\n",
              "0                                           Initial commit   \n",
              "1  Hard-forking a codebase generously shared by Anselm/JET   \n",
              "2  Hard-forking a codebase generously shared by Anselm/JET   \n",
              "3  Hard-forking a codebase generously shared by Anselm/JET   \n",
              "4  Hard-forking a codebase generously shared by Anselm/JET   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    diff_myers  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           @@ -0,0 +1,201 @@\\n+                                 Apache License\\n+                           Version 2.0, January 2004\\n+                        http://www.apache.org/licenses/\\n+\\n+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n+\\n+   1. Definitions.\\n+\\n+      \"License\" shall mean the terms and conditions for use, reproduction,\\n+      and distribution as defined by Sections 1 through 9 of this document.\\n+\\n+      \"Licensor\" shall mean the copyright owner or entity authorized by\\n+      the copyright owner that is granting the License.\\n+\\n+      \"Legal Entity\" shall mean the union of the acting entity and all\\n+      other entities that control, are controlled by, or are under common\\n+      control with that entity. For the purposes of this definition,\\n+      \"control\" means (i) the power, direct or indirect, to cause the\\n+      direction or management of such entity, whether by contract or\\n+      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n+      outstanding shares, or (iii) beneficial ownership of such entity.\\n+\\n+      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n+      exercising permissions granted by this License.\\n+\\n+      \"Source\" form shall mean the preferred form for making modifications,\\n+      including but not limited to software source code, documentation\\n+      source, and configuration files.\\n+\\n+      \"Object\" form shall mean any form resulting from mechanical\\n+      transformation or translation of a Source form, including but\\n+      not limited to compiled object code, generated documentation,\\n+      and conversions to other media types.\\n+\\n+      \"Work\" shall mean the work of authorship, whether in Source or\\n+      Object form, made available under the License, as indicated by a\\n+      copyright notice that is included in or attached to the work\\n+      (an example is provided in the Appendix below).\\n+\\n+      \"Derivative Works\" shall mean any work, whether in Source or Object\\n+      form, that is based on (or derived from) the Work and for which the\\n+      editorial revisions, annotations, elaborations, or other modifications\\n+      represent, as a whole, an original work of authorship. For the purposes\\n+      of this License, Derivative Works shall not include works that remain\\n+      separable from, or merely link (or bind by name) to the interfaces of,\\n+      the Work and Derivative Works thereof.\\n+\\n+      \"Contribution\" shall mean any work of authorship, including\\n+      the original version of the Work and any modifications or additions\\n+      to that Work or Derivative Works thereof, that is intentionally\\n+      submitted to Licensor for inclusion in the Work by the copyright owner\\n+      or by an individual or Legal Entity authorized to submit on behalf of\\n+      the copyright owner. For the purposes of this definition, \"submitted\"\\n+      means any form of electronic, verbal, or written communication sent\\n+      to the Licensor or its representatives, including but not limited to\\n+      communication on electronic mailing lists, source code control systems,\\n+      and issue tracking systems that are managed by, or on behalf of, the\\n+      Licensor for the purpose of discussing and improving the Work, but\\n+      excluding communication that is conspicuously marked or otherwise\\n+      designated in writing by the copyright owner as \"Not a Contribution.\"\\n+\\n+      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n+      on behalf of whom a Contribution has been received by Licensor and\\n+      subsequently incorporated within the Work.\\n+\\n+   2. Grant of Copyright License. Subject to the terms and conditions of\\n+      this License, each Contributor hereby grants to You a perpetual,\\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n+      copyright license to reproduce, prepare Derivative Works of,\\n+      publicly display, publicly perform, sublicense, and distribute the\\n+      Work and such Derivative Works in Source or Object form.\\n+\\n+   3. Grant of Patent License. Subject to the terms and conditions of\\n+      this License, each Contributor hereby grants to You a perpetual,\\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n+      (except as stated in this section) patent license to make, have made,\\n+      use, offer to sell, sell, import, and otherwise transfer the Work,\\n+      where such license applies only to those patent claims licensable\\n+      by such Contributor that are necessarily infringed by their\\n+      Contribution(s) alone or by combination of their Contribution(s)\\n+      with the Work to which such Contribution(s) was submitted. If You\\n+      institute patent litigation against any entity (including a\\n+      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n+      or a Contribution incorporated within the Work constitutes direct\\n+      or contributory patent infringement, then any patent licenses\\n+      granted to You under this License for that Work shall terminate\\n+      as of the date such litigation is filed.\\n+\\n+   4. Redistribution. You may reproduce and distribute copies of the\\n+      Work or Derivative Works thereof in any medium, with or without\\n+      modifications, and in Source or Object form, provided that You\\n+      meet the following conditions:\\n+\\n+      (a) You must give any other recipients of the Work or\\n+          Derivative Works a copy of this License; and\\n+\\n+      (b) You must cause any modified files to carry prominent notices\\n+          stating that You changed the files; and\\n+\\n+      (c) You must retain, in the Source form of any Derivative Works\\n+          that You distribute, all copyright, patent, trademark, and\\n+          attribution notices from the Source form of the Work,\\n+          excluding those notices that do not pertain to any part of\\n+          the Derivative Works; and\\n+\\n+      (d) If the Work includes a \"NOTICE\" text file as part of its\\n+          distribution, then any Derivative Works that You distribute must\\n+          include a readable copy of the attribution notices contained\\n+          within such NOTICE file, excluding those notices that do not\\n+          pertain to any part of the Derivative Works, in at least one\\n+          of the following places: within a NOTICE text file distributed\\n+          as part of the Derivative Works; within the Source form or\\n+          documentation, if provided along with the Derivative Works; or,\\n+          within a display generated by the Derivative Works, if and\\n+          wherever such third-party notices normally appear. The contents\\n+          of the NOTICE file are for informational purposes only and\\n+          do not modify the License. You may add Your own attribution\\n+          notices within Derivative Works that You distribute, alongside\\n+          or as an addendum to the NOTICE text from the Work, provided\\n+          that such additional attribution notices cannot be construed\\n+          as modifying the License.\\n+\\n+      You may add Your own copyright statement to Your modifications and\\n+      may provide additional or different license terms and conditions\\n+      for use, reproduction, or distribution of Your modifications, or\\n+      for any such Derivative Works as a whole, provided Your use,\\n+      reproduction, and distribution of the Work otherwise complies with\\n+      the conditions stated in this License.\\n+\\n+   5. Submission of Contributions. Unless You explicitly state otherwise,\\n+      any Contribution intentionally submitted for inclusion in the Work\\n+      by You to the Licensor shall be under the terms and conditions of\\n+      this License, without any additional terms or conditions.\\n+      Notwithstanding the above, nothing herein shall supersede or modify\\n+      the terms of any separate license agreement you may have executed\\n+      with Licensor regarding such Contributions.\\n+\\n+   6. Trademarks. This License does not grant permission to use the trade\\n+      names, trademarks, service marks, or product names of the Licensor,\\n+      except as required for reasonable and customary use in describing the\\n+      origin of the Work and reproducing the content of the NOTICE file.\\n+\\n+   7. Disclaimer of Warranty. Unless required by applicable law or\\n+      agreed to in writing, Licensor provides the Work (and each\\n+      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n+      implied, including, without limitation, any warranties or conditions\\n+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n+      PARTICULAR PURPOSE. You are solely responsible for determining the\\n+      appropriateness of using or redistributing the Work and assume any\\n+      risks associated with Your exercise of permissions under this License.\\n+\\n+   8. Limitation of Liability. In no event and under no legal theory,\\n+      whether in tort (including negligence), contract, or otherwise,\\n+      unless required by applicable law (such as deliberate and grossly\\n+      negligent acts) or agreed to in writing, shall any Contributor be\\n+      liable to You for damages, including any direct, indirect, special,\\n+      incidental, or consequential damages of any character arising as a\\n+      result of this License or out of the use or inability to use the\\n+      Work (including but not limited to damages for loss of goodwill,\\n+      work stoppage, computer failure or malfunction, or any and all\\n+      other commercial damages or losses), even if such Contributor\\n+      has been advised of the possibility of such damages.\\n+\\n+   9. Accepting Warranty or Additional Liability. While redistributing\\n+      the Work or Derivative Works thereof, You may choose to offer,\\n+      and charge a fee for, acceptance of support, warranty, indemnity,\\n+      or other liability obligations and/or rights consistent with this\\n+      License. However, in accepting such obligations, You may act only\\n+      on Your own behalf and on Your sole responsibility, not on behalf\\n+      of any other Contributor, and only if You agree to indemnify,\\n+      defend, and hold each Contributor harmless for any liability\\n+      incurred by, or claims asserted against, such Contributor by reason\\n+      of your accepting any such warranty or additional liability.\\n+\\n+   END OF TERMS AND CONDITIONS\\n+\\n+   APPENDIX: How to apply the Apache License to your work.\\n+\\n+      To apply the Apache License to your work, attach the following\\n+      boilerplate notice, with the fields enclosed by brackets \"[]\"\\n+      replaced with your own identifying information. (Don't include\\n+      the brackets!)  The text should be enclosed in the appropriate\\n+      comment syntax for the file format. We also recommend that a\\n+      file or class name and description of purpose be included on the\\n+      same \"printed page\" as the copyright notice for easier\\n+      identification within third-party archives.\\n+\\n+   Copyright [yyyy] [name of copyright owner]\\n+\\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\\n+   you may not use this file except in compliance with the License.\\n+   You may obtain a copy of the License at\\n+\\n+       http://www.apache.org/licenses/LICENSE-2.0\\n+\\n+   Unless required by applicable law or agreed to in writing, software\\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n+   See the License for the specific language governing permissions and\\n+   limitations under the License.\\n   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              @@ -0,0 +1 @@\\n+*__pycache__*\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     @@ -0,0 +1 @@\\n+# adhd\\n   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             @@ -0,0 +1,66 @@\\n+\"\"\"Config for training.\"\"\"\\n+\\n+from typing import Any, Sequence, Tuple\\n+from flax import struct\\n+import jax.numpy as jnp\\n+\\n+\\n+@struct.dataclass\\n+class T5Config:\\n+  \"\"\"Global hyperparameters used to minimize obnoxious kwarg plumbing.\"\"\"\\n+\\n+  # Activation dtypes.\\n+  dtype: Any = jnp.float32\\n+  emb_dim: int = 128\\n+  num_heads: int = 8\\n+  head_dim: int = 16\\n+  mlp_dim: int = 512\\n+  num_decoder_layers: int = 6\\n+  # activation functions are .\\n+  mlp_activations: Sequence[str] = ('relu',)\\n+  dropout_rate: float = 0\\n+  # If `True`, the embedding weights are used in the decoder output layer.\\n+  logits_via_embedding: bool = True  # NOTE: this is True just for testing.\\n+  # minimal, full, or none\\n+  remat_policy: str = 'none'\\n+  scan_layers: bool = False\\n+  param_scan_axis: int = 1\\n+\\n+  # Parallelism\\n+  mesh_shape: Tuple[int] = (4,)\\n+  mesh_axes: Tuple[str] = ('data',)\\n+  logical_axis_rules: Sequence = ( ('batch', 'data'), )\\n+\\n+  # Dataset\\n+  vocab_size: int = 30000\\n+  dataset_name: str = 'lm1b'\\n+  eval_dataset_name: str = 'lm1b'\\n+  eval_split: str = 'test'\\n+  per_device_batch_size: int = 32\\n+  eval_per_device_batch_size: int = 0\\n+  max_corpus_chars: int = 10**7  # for tokenization\\n+\\n+  # Training loop\\n+  steps: int = 20_000_000\\n+  log_period: int = 500\\n+  save_period: int = 2000\\n+  learning_rate: float = 1e-3\\n+  warmup_steps: int = 1000\\n+  save_checkpoints: bool = False\\n+  restore_checkpoints: bool = False\\n+\\n+  # Maximum length cutoff for training examples.\\n+  max_target_length: int = 128\\n+  # Maximum length cutoff for held-out evaluation examples.\\n+  max_eval_target_length: int = 512\\n+\\n+  # Maximum length cutoff for predicted tokens.\\n+  max_predict_length: int = 50\\n+  # Sampling temperature for language model inference.\\n+  sampling_temperature: float = 0.6\\n+  # Top k cutoff for logit sampling. If 0 then no top-k cutoff is used.\\n+  sampling_top_k: int = 20\\n+  eos_id: int = 2  # sentencepiece default\\n+  # Prompt for language model sampling.\\n+  prompt: str = \"I love to \"\\n+\\n   \n",
              "4  @@ -0,0 +1,340 @@\\n+\"\"\"Input pipeline for a LM1B dataset.\"\"\"\\n+\\n+import os\\n+from typing import Dict, Optional, List, Union\\n+\\n+from clu import deterministic_data\\n+import ml_collections\\n+import tensorflow as tf\\n+import tensorflow_datasets as tfds\\n+\\n+from adhd import tokenizer\\n+\\n+AUTOTUNE = tf.data.experimental.AUTOTUNE\\n+Features = Dict[str, tf.Tensor]\\n+\\n+\\n+class NormalizeFeatureNamesOp:\\n+  \"\"\"Normalizes feature names to 'inputs' and 'targets'.\"\"\"\\n+\\n+  def __init__(self, ds_info: tfds.core.DatasetInfo):\\n+    self.ds_info = ds_info\\n+\\n+  def __call__(self, features: Features) -> Features:\\n+    features['inputs'] = features.pop('text')\\n+    # Unnecessary step used for uniformizing with examples/wmt.\\n+    features['targets'] = features['inputs']\\n+    return features\\n+\\n+\\n+def get_raw_dataset(dataset_builder: tfds.core.DatasetBuilder,\\n+                    split: str) -> tf.data.Dataset:\\n+  \"\"\"Loads a raw text dataset and normalizes feature keys.\\n+  Args:\\n+    dataset_builder: TFDS dataset builder that can build `split`.\\n+    split: Split to use. This must be the full split. We shard the split across\\n+      multiple hosts and currently don't support sharding subsplits.\\n+  Returns:\\n+    Dataset with source and target language features mapped to 'inputs' and\\n+    'targets'.\\n+  \"\"\"\\n+  per_host_split = tfds.split_for_jax_process(split, drop_remainder=False)\\n+  ds = dataset_builder.as_dataset(split=per_host_split, shuffle_files=False)\\n+  ds = ds.map(\\n+      NormalizeFeatureNamesOp(dataset_builder.info),\\n+      num_parallel_calls=AUTOTUNE)\\n+  return ds\\n+\\n+\\n+def pack_dataset(dataset: tf.data.Dataset,\\n+                 key2length: Union[int, Dict[str, int]],\\n+                 keys: Optional[List[str]] = None) -> tf.data.Dataset:\\n+  \"\"\"Creates a 'packed' version of a dataset on-the-fly.\\n+  Adapted from the mesh-tf implementation.\\n+  This is meant to replace the irritation of having to create a separate\\n+  \"packed\" version of a dataset to train efficiently on TPU.\\n+  Each example in the output dataset represents several examples in the\\n+  input dataset.\\n+  For each key in the input dataset, two additional keys are created:\\n+  <key>_segmentation: an int32 tensor identifying the parts\\n+     representing the original example.\\n+  <key>_position: an int32 tensor identifying the position within the original\\n+     example.\\n+  Example:\\n+  Two input examples get combined to form an output example.\\n+  The input examples are:\\n+  {\"inputs\": [8, 7, 1, 0], \"targets\":[4, 1, 0]}\\n+  {\"inputs\": [2, 3, 4, 1], \"targets\":[5, 6, 1]}\\n+  The output example is:\\n+  {\\n+                 \"inputs\": [8, 7, 1, 2, 3, 4, 1, 0, 0, 0]\\n+    \"inputs_segmentation\": [1, 1, 1, 2, 2, 2, 2, 0, 0, 0]\\n+        \"inputs_position\": [0, 1, 2, 0, 1, 2, 3, 0, 0, 0]\\n+                \"targets\": [4, 1, 5, 6, 1, 0, 0, 0, 0, 0]\\n+   \"targets_segmentation\": [1, 1, 2, 2, 2, 0, 0, 0, 0, 0]\\n+       \"targets_position\": [0, 1, 0, 1, 2, 0, 0, 0, 0, 0]\\n+  }\\n+  0 represents padding in both the inputs and the outputs.\\n+  Sequences in the incoming examples are truncated to length \"length\", and the\\n+  sequences in the output examples all have fixed (padded) length \"length\".\\n+  Args:\\n+    dataset: a tf.data.Dataset\\n+    key2length: an integer, or a dict from feature-key to integer\\n+    keys: a list of strings (e.g. [\"inputs\", \"targets\"])\\n+  Returns:\\n+    a tf.data.Dataset\\n+  \"\"\"\\n+  shapes = tf.nest.map_structure(lambda spec: spec.shape, dataset.element_spec)\\n+  if keys is None:\\n+    keys = list(shapes.keys())\\n+  for k in keys:\\n+    if k not in shapes:\\n+      raise ValueError('Key %s not found in dataset.  Available keys are %s' %\\n+                       (k, shapes.keys()))\\n+    if not shapes[k].is_compatible_with(tf.TensorShape([None])):\\n+      raise ValueError('Tensors to be packed must be one-dimensional.')\\n+  # make sure that the length dictionary contains all keys as well as the\\n+  # keys suffixed by \"_segmentation\" and \"_position\"\\n+  if isinstance(key2length, int):\\n+    key2length = {k: key2length for k in keys}\\n+  for k in keys:\\n+    for suffix in ['_segmentation', '_position']:\\n+      key2length[k + suffix] = key2length[k]\\n+\\n+  # trim to length\\n+  dataset = dataset.map(\\n+      lambda x: {k: x[k][:key2length[k]] for k in keys},\\n+      num_parallel_calls=AUTOTUNE)\\n+  # Setting batch_size=length ensures that the concatenated sequences (if they\\n+  # have length >=1) are sufficient to fill at least one packed example.\\n+  batch_size = max(key2length.values())\\n+  dataset = dataset.padded_batch(\\n+      batch_size, padded_shapes={k: [-1] for k in keys})\\n+  dataset = _pack_with_tf_ops(dataset, keys, key2length)\\n+\\n+  # Set the Tensor shapes correctly since they get lost in the process.\\n+  def my_fn(x):\\n+    return {k: tf.reshape(v, [key2length[k]]) for k, v in x.items()}\\n+\\n+  return dataset.map(my_fn, num_parallel_calls=AUTOTUNE)\\n+\\n+\\n+def _pack_with_tf_ops(dataset: tf.data.Dataset, keys: List[str],\\n+                      key2length: Dict[str, int]) -> tf.data.Dataset:\\n+  \"\"\"Helper-function for packing a dataset which has already been batched.\\n+  Helper for pack_dataset()  Uses tf.while_loop.\\n+  Args:\\n+    dataset: a dataset containing padded batches of examples.\\n+    keys: a list of strings\\n+    key2length: an dict from feature-key to integer\\n+  Returns:\\n+    a dataset.\\n+  \"\"\"\\n+  empty_example = {}\\n+  for k in keys:\\n+    empty_example[k] = tf.zeros([0], dtype=tf.int32)\\n+    empty_example[k + '_position'] = tf.zeros([0], dtype=tf.int32)\\n+  keys_etc = empty_example.keys()\\n+\\n+  def write_packed_example(partial, outputs):\\n+    new_partial = empty_example.copy()\\n+    new_outputs = {}\\n+    for k in keys_etc:\\n+      new_outputs[k] = outputs[k].write(\\n+          outputs[k].size(),\\n+          tf.pad(partial[k], [[0, key2length[k] - tf.size(partial[k])]]))\\n+    return new_partial, new_outputs\\n+\\n+  def map_fn(x):\\n+    \"\"\"Internal function to flat_map over.\\n+    Consumes a batch of input examples and produces a variable number of output\\n+    examples.\\n+    Args:\\n+      x: a single example\\n+    Returns:\\n+      a tf.data.Dataset\\n+    \"\"\"\\n+    partial = empty_example.copy()\\n+    i = tf.zeros([], dtype=tf.int32)\\n+    dynamic_batch_size = tf.shape(x[keys[0]])[0]\\n+    outputs = {}\\n+    for k in keys:\\n+      outputs[k] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+      outputs[k + '_position'] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+\\n+    def body_fn(i, partial, outputs):\\n+      \"\"\"Body function for while_loop.\\n+      Args:\\n+        i: integer scalar\\n+        partial: dictionary of Tensor (partially-constructed example)\\n+        outputs: dictionary of TensorArray\\n+      Returns:\\n+        A triple containing the new values of the inputs.\\n+      \"\"\"\\n+      can_append = True\\n+      one_example = {}\\n+      for k in keys:\\n+        val = tf.cast(x[k][i], tf.int32)\\n+        val = val[:tf.reduce_sum(tf.cast(tf.not_equal(val, 0), tf.int32))]\\n+        one_example[k] = val\\n+      for k in keys:\\n+        can_append = tf.logical_and(\\n+            can_append,\\n+            tf.less_equal(\\n+                tf.size(partial[k]) + tf.size(one_example[k]), key2length[k]))\\n+\\n+      def false_fn():\\n+        return write_packed_example(partial, outputs)\\n+\\n+      def true_fn():\\n+        return partial, outputs\\n+\\n+      partial, outputs = tf.cond(can_append, true_fn, false_fn)\\n+      new_partial = {}\\n+      for k in keys:\\n+        new_seq = one_example[k][:key2length[k]]\\n+        new_seq_len = tf.size(new_seq)\\n+        new_partial[k] = tf.concat([partial[k], new_seq], 0)\\n+        new_partial[k + '_position'] = tf.concat(\\n+            [partial[k + '_position'],\\n+             tf.range(new_seq_len)], 0)\\n+      partial = new_partial\\n+      return i + 1, partial, outputs\\n+\\n+    # For loop over all examples in the batch.\\n+    i, partial, outputs = tf.while_loop(\\n+        cond=lambda *_: True,\\n+        body=body_fn,\\n+        loop_vars=(i, partial, outputs),\\n+        shape_invariants=(\\n+            tf.TensorShape([]),\\n+            {k: tf.TensorShape([None]) for k in keys_etc},\\n+            {k: tf.TensorShape(None) for k in keys_etc},\\n+        ),\\n+        maximum_iterations=dynamic_batch_size)\\n+    _, outputs = write_packed_example(partial, outputs)\\n+    packed = {k: outputs[k].stack() for k in keys_etc}\\n+    for k in keys:\\n+      packed[k + '_segmentation'] = (\\n+          tf.cumsum(\\n+              tf.cast(tf.equal(packed[k + '_position'], 0), tf.int32), axis=1) *\\n+          tf.cast(tf.not_equal(packed[k], 0), tf.int32))\\n+    return packed\\n+\\n+  dataset = dataset.map(map_fn, num_parallel_calls=AUTOTUNE)\\n+  return dataset.unbatch()\\n+\\n+\\n+# -----------------------------------------------------------------------------\\n+# Main dataset prep routines.\\n+# -----------------------------------------------------------------------------\\n+def preprocess_data(dataset,\\n+                    shuffle: bool,\\n+                    num_epochs: Optional[int] = 1,\\n+                    pack_examples: bool = True,\\n+                    shuffle_buffer_size: int = 1024,\\n+                    max_length: int = 512,\\n+                    batch_size: int = 256,\\n+                    drop_remainder: bool = True,\\n+                    prefetch_size: int = AUTOTUNE):\\n+  \"\"\"Shuffle and batch/pack the given dataset.\"\"\"\\n+\\n+  def length_filter(max_len):\\n+\\n+    def filter_fn(x):\\n+      source, target = x['inputs'], x['targets']\\n+      l = tf.maximum(tf.shape(source)[0], tf.shape(target)[0])\\n+      return tf.less(l, max_len + 1)\\n+\\n+    return filter_fn\\n+\\n+  if max_length > 0:\\n+    dataset = dataset.filter(length_filter(max_length))\\n+\\n+  if shuffle:\\n+    dataset = dataset.shuffle(shuffle_buffer_size)\\n+  dataset = dataset.repeat(num_epochs)\\n+\\n+  if pack_examples:\\n+    dataset = pack_dataset(dataset, max_length)\\n+    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\\n+  else:  # simple (static-shape) padded batching\\n+    dataset = dataset.padded_batch(\\n+        batch_size,\\n+        padded_shapes={\\n+            'inputs': max_length,\\n+            'targets': max_length\\n+        },\\n+        padding_values={\\n+            'inputs': 0,\\n+            'targets': 0\\n+        },\\n+        drop_remainder=drop_remainder)\\n+\\n+  if prefetch_size:\\n+    dataset = dataset.prefetch(prefetch_size)\\n+\\n+  return dataset\\n+\\n+\\n+def get_datasets(config: ml_collections.ConfigDict,\\n+                 *,\\n+                 n_devices: int,\\n+                 vocab_path: Optional[str] = None):\\n+  \"\"\"Load and return dataset of batched examples for use during training.\"\"\"\\n+  if vocab_path is None:\\n+    vocab_path = os.path.expanduser('~/lm1b_sentencepiece_model')\\n+\\n+  train_ds_builder = tfds.builder(config.dataset_name)\\n+  train_ds_builder.download_and_prepare()\\n+  train_data = get_raw_dataset(train_ds_builder, 'train')\\n+\\n+  if config.eval_dataset_name:\\n+    eval_ds_builder = tfds.builder(config.eval_dataset_name)\\n+  else:\\n+    eval_ds_builder = train_ds_builder\\n+  eval_data = get_raw_dataset(eval_ds_builder, config.eval_split)\\n+\\n+  # Tokenize data.\\n+  sp_tokenizer = tokenizer.load_or_train_tokenizer(\\n+      train_data,\\n+      vocab_path=vocab_path,\\n+      vocab_size=config.vocab_size,\\n+      max_corpus_chars=config.max_corpus_chars)\\n+  train_data = train_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+  eval_data = eval_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+\\n+  batch_size = config.per_device_batch_size * n_devices\\n+  if config.eval_per_device_batch_size > 0:\\n+    eval_batch_size = config.eval_per_device_batch_size * n_devices\\n+  else:\\n+    eval_batch_size = batch_size\\n+\\n+  train_ds = preprocess_data(\\n+      train_data,\\n+      shuffle=True,\\n+      num_epochs=None,\\n+      pack_examples=True,\\n+      batch_size=batch_size,\\n+      max_length=config.max_target_length)\\n+\\n+  eval_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_eval_target_length)\\n+\\n+  predict_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_predict_length,\\n+      drop_remainder=False)\\n+\\n+  return train_ds, eval_ds, predict_ds, sp_tokenizer\\n   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         diff_hist  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Command '['git', '-C', 'maxtext', 'diff', '--histogram', '696b089f888e57a468184d382e56b862985640f2^', '696b089f888e57a468184d382e56b862985640f2', '--', 'LICENSE']' returned non-zero exit status 128.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           diff --git a/.gitignore b/.gitignore\\nnew file mode 100644\\nindex 00000000..cd4c22c4\\n--- /dev/null\\n+++ b/.gitignore\\n@@ -0,0 +1 @@\\n+*__pycache__*\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       diff --git a/MaxText/__init__.py b/MaxText/__init__.py\\nnew file mode 100644\\nindex 00000000..f424dbec\\n--- /dev/null\\n+++ b/MaxText/__init__.py\\n@@ -0,0 +1 @@\\n+# adhd\\n   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     diff --git a/MaxText/config.py b/MaxText/config.py\\nnew file mode 100644\\nindex 00000000..71317091\\n--- /dev/null\\n+++ b/MaxText/config.py\\n@@ -0,0 +1,66 @@\\n+\"\"\"Config for training.\"\"\"\\n+\\n+from typing import Any, Sequence, Tuple\\n+from flax import struct\\n+import jax.numpy as jnp\\n+\\n+\\n+@struct.dataclass\\n+class T5Config:\\n+  \"\"\"Global hyperparameters used to minimize obnoxious kwarg plumbing.\"\"\"\\n+\\n+  # Activation dtypes.\\n+  dtype: Any = jnp.float32\\n+  emb_dim: int = 128\\n+  num_heads: int = 8\\n+  head_dim: int = 16\\n+  mlp_dim: int = 512\\n+  num_decoder_layers: int = 6\\n+  # activation functions are .\\n+  mlp_activations: Sequence[str] = ('relu',)\\n+  dropout_rate: float = 0\\n+  # If `True`, the embedding weights are used in the decoder output layer.\\n+  logits_via_embedding: bool = True  # NOTE: this is True just for testing.\\n+  # minimal, full, or none\\n+  remat_policy: str = 'none'\\n+  scan_layers: bool = False\\n+  param_scan_axis: int = 1\\n+\\n+  # Parallelism\\n+  mesh_shape: Tuple[int] = (4,)\\n+  mesh_axes: Tuple[str] = ('data',)\\n+  logical_axis_rules: Sequence = ( ('batch', 'data'), )\\n+\\n+  # Dataset\\n+  vocab_size: int = 30000\\n+  dataset_name: str = 'lm1b'\\n+  eval_dataset_name: str = 'lm1b'\\n+  eval_split: str = 'test'\\n+  per_device_batch_size: int = 32\\n+  eval_per_device_batch_size: int = 0\\n+  max_corpus_chars: int = 10**7  # for tokenization\\n+\\n+  # Training loop\\n+  steps: int = 20_000_000\\n+  log_period: int = 500\\n+  save_period: int = 2000\\n+  learning_rate: float = 1e-3\\n+  warmup_steps: int = 1000\\n+  save_checkpoints: bool = False\\n+  restore_checkpoints: bool = False\\n+\\n+  # Maximum length cutoff for training examples.\\n+  max_target_length: int = 128\\n+  # Maximum length cutoff for held-out evaluation examples.\\n+  max_eval_target_length: int = 512\\n+\\n+  # Maximum length cutoff for predicted tokens.\\n+  max_predict_length: int = 50\\n+  # Sampling temperature for language model inference.\\n+  sampling_temperature: float = 0.6\\n+  # Top k cutoff for logit sampling. If 0 then no top-k cutoff is used.\\n+  sampling_top_k: int = 20\\n+  eos_id: int = 2  # sentencepiece default\\n+  # Prompt for language model sampling.\\n+  prompt: str = \"I love to \"\\n+\\n   \n",
              "4  diff --git a/MaxText/input_pipeline.py b/MaxText/input_pipeline.py\\nnew file mode 100644\\nindex 00000000..8328ccad\\n--- /dev/null\\n+++ b/MaxText/input_pipeline.py\\n@@ -0,0 +1,340 @@\\n+\"\"\"Input pipeline for a LM1B dataset.\"\"\"\\n+\\n+import os\\n+from typing import Dict, Optional, List, Union\\n+\\n+from clu import deterministic_data\\n+import ml_collections\\n+import tensorflow as tf\\n+import tensorflow_datasets as tfds\\n+\\n+from adhd import tokenizer\\n+\\n+AUTOTUNE = tf.data.experimental.AUTOTUNE\\n+Features = Dict[str, tf.Tensor]\\n+\\n+\\n+class NormalizeFeatureNamesOp:\\n+  \"\"\"Normalizes feature names to 'inputs' and 'targets'.\"\"\"\\n+\\n+  def __init__(self, ds_info: tfds.core.DatasetInfo):\\n+    self.ds_info = ds_info\\n+\\n+  def __call__(self, features: Features) -> Features:\\n+    features['inputs'] = features.pop('text')\\n+    # Unnecessary step used for uniformizing with examples/wmt.\\n+    features['targets'] = features['inputs']\\n+    return features\\n+\\n+\\n+def get_raw_dataset(dataset_builder: tfds.core.DatasetBuilder,\\n+                    split: str) -> tf.data.Dataset:\\n+  \"\"\"Loads a raw text dataset and normalizes feature keys.\\n+  Args:\\n+    dataset_builder: TFDS dataset builder that can build `split`.\\n+    split: Split to use. This must be the full split. We shard the split across\\n+      multiple hosts and currently don't support sharding subsplits.\\n+  Returns:\\n+    Dataset with source and target language features mapped to 'inputs' and\\n+    'targets'.\\n+  \"\"\"\\n+  per_host_split = tfds.split_for_jax_process(split, drop_remainder=False)\\n+  ds = dataset_builder.as_dataset(split=per_host_split, shuffle_files=False)\\n+  ds = ds.map(\\n+      NormalizeFeatureNamesOp(dataset_builder.info),\\n+      num_parallel_calls=AUTOTUNE)\\n+  return ds\\n+\\n+\\n+def pack_dataset(dataset: tf.data.Dataset,\\n+                 key2length: Union[int, Dict[str, int]],\\n+                 keys: Optional[List[str]] = None) -> tf.data.Dataset:\\n+  \"\"\"Creates a 'packed' version of a dataset on-the-fly.\\n+  Adapted from the mesh-tf implementation.\\n+  This is meant to replace the irritation of having to create a separate\\n+  \"packed\" version of a dataset to train efficiently on TPU.\\n+  Each example in the output dataset represents several examples in the\\n+  input dataset.\\n+  For each key in the input dataset, two additional keys are created:\\n+  <key>_segmentation: an int32 tensor identifying the parts\\n+     representing the original example.\\n+  <key>_position: an int32 tensor identifying the position within the original\\n+     example.\\n+  Example:\\n+  Two input examples get combined to form an output example.\\n+  The input examples are:\\n+  {\"inputs\": [8, 7, 1, 0], \"targets\":[4, 1, 0]}\\n+  {\"inputs\": [2, 3, 4, 1], \"targets\":[5, 6, 1]}\\n+  The output example is:\\n+  {\\n+                 \"inputs\": [8, 7, 1, 2, 3, 4, 1, 0, 0, 0]\\n+    \"inputs_segmentation\": [1, 1, 1, 2, 2, 2, 2, 0, 0, 0]\\n+        \"inputs_position\": [0, 1, 2, 0, 1, 2, 3, 0, 0, 0]\\n+                \"targets\": [4, 1, 5, 6, 1, 0, 0, 0, 0, 0]\\n+   \"targets_segmentation\": [1, 1, 2, 2, 2, 0, 0, 0, 0, 0]\\n+       \"targets_position\": [0, 1, 0, 1, 2, 0, 0, 0, 0, 0]\\n+  }\\n+  0 represents padding in both the inputs and the outputs.\\n+  Sequences in the incoming examples are truncated to length \"length\", and the\\n+  sequences in the output examples all have fixed (padded) length \"length\".\\n+  Args:\\n+    dataset: a tf.data.Dataset\\n+    key2length: an integer, or a dict from feature-key to integer\\n+    keys: a list of strings (e.g. [\"inputs\", \"targets\"])\\n+  Returns:\\n+    a tf.data.Dataset\\n+  \"\"\"\\n+  shapes = tf.nest.map_structure(lambda spec: spec.shape, dataset.element_spec)\\n+  if keys is None:\\n+    keys = list(shapes.keys())\\n+  for k in keys:\\n+    if k not in shapes:\\n+      raise ValueError('Key %s not found in dataset.  Available keys are %s' %\\n+                       (k, shapes.keys()))\\n+    if not shapes[k].is_compatible_with(tf.TensorShape([None])):\\n+      raise ValueError('Tensors to be packed must be one-dimensional.')\\n+  # make sure that the length dictionary contains all keys as well as the\\n+  # keys suffixed by \"_segmentation\" and \"_position\"\\n+  if isinstance(key2length, int):\\n+    key2length = {k: key2length for k in keys}\\n+  for k in keys:\\n+    for suffix in ['_segmentation', '_position']:\\n+      key2length[k + suffix] = key2length[k]\\n+\\n+  # trim to length\\n+  dataset = dataset.map(\\n+      lambda x: {k: x[k][:key2length[k]] for k in keys},\\n+      num_parallel_calls=AUTOTUNE)\\n+  # Setting batch_size=length ensures that the concatenated sequences (if they\\n+  # have length >=1) are sufficient to fill at least one packed example.\\n+  batch_size = max(key2length.values())\\n+  dataset = dataset.padded_batch(\\n+      batch_size, padded_shapes={k: [-1] for k in keys})\\n+  dataset = _pack_with_tf_ops(dataset, keys, key2length)\\n+\\n+  # Set the Tensor shapes correctly since they get lost in the process.\\n+  def my_fn(x):\\n+    return {k: tf.reshape(v, [key2length[k]]) for k, v in x.items()}\\n+\\n+  return dataset.map(my_fn, num_parallel_calls=AUTOTUNE)\\n+\\n+\\n+def _pack_with_tf_ops(dataset: tf.data.Dataset, keys: List[str],\\n+                      key2length: Dict[str, int]) -> tf.data.Dataset:\\n+  \"\"\"Helper-function for packing a dataset which has already been batched.\\n+  Helper for pack_dataset()  Uses tf.while_loop.\\n+  Args:\\n+    dataset: a dataset containing padded batches of examples.\\n+    keys: a list of strings\\n+    key2length: an dict from feature-key to integer\\n+  Returns:\\n+    a dataset.\\n+  \"\"\"\\n+  empty_example = {}\\n+  for k in keys:\\n+    empty_example[k] = tf.zeros([0], dtype=tf.int32)\\n+    empty_example[k + '_position'] = tf.zeros([0], dtype=tf.int32)\\n+  keys_etc = empty_example.keys()\\n+\\n+  def write_packed_example(partial, outputs):\\n+    new_partial = empty_example.copy()\\n+    new_outputs = {}\\n+    for k in keys_etc:\\n+      new_outputs[k] = outputs[k].write(\\n+          outputs[k].size(),\\n+          tf.pad(partial[k], [[0, key2length[k] - tf.size(partial[k])]]))\\n+    return new_partial, new_outputs\\n+\\n+  def map_fn(x):\\n+    \"\"\"Internal function to flat_map over.\\n+    Consumes a batch of input examples and produces a variable number of output\\n+    examples.\\n+    Args:\\n+      x: a single example\\n+    Returns:\\n+      a tf.data.Dataset\\n+    \"\"\"\\n+    partial = empty_example.copy()\\n+    i = tf.zeros([], dtype=tf.int32)\\n+    dynamic_batch_size = tf.shape(x[keys[0]])[0]\\n+    outputs = {}\\n+    for k in keys:\\n+      outputs[k] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+      outputs[k + '_position'] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+\\n+    def body_fn(i, partial, outputs):\\n+      \"\"\"Body function for while_loop.\\n+      Args:\\n+        i: integer scalar\\n+        partial: dictionary of Tensor (partially-constructed example)\\n+        outputs: dictionary of TensorArray\\n+      Returns:\\n+        A triple containing the new values of the inputs.\\n+      \"\"\"\\n+      can_append = True\\n+      one_example = {}\\n+      for k in keys:\\n+        val = tf.cast(x[k][i], tf.int32)\\n+        val = val[:tf.reduce_sum(tf.cast(tf.not_equal(val, 0), tf.int32))]\\n+        one_example[k] = val\\n+      for k in keys:\\n+        can_append = tf.logical_and(\\n+            can_append,\\n+            tf.less_equal(\\n+                tf.size(partial[k]) + tf.size(one_example[k]), key2length[k]))\\n+\\n+      def false_fn():\\n+        return write_packed_example(partial, outputs)\\n+\\n+      def true_fn():\\n+        return partial, outputs\\n+\\n+      partial, outputs = tf.cond(can_append, true_fn, false_fn)\\n+      new_partial = {}\\n+      for k in keys:\\n+        new_seq = one_example[k][:key2length[k]]\\n+        new_seq_len = tf.size(new_seq)\\n+        new_partial[k] = tf.concat([partial[k], new_seq], 0)\\n+        new_partial[k + '_position'] = tf.concat(\\n+            [partial[k + '_position'],\\n+             tf.range(new_seq_len)], 0)\\n+      partial = new_partial\\n+      return i + 1, partial, outputs\\n+\\n+    # For loop over all examples in the batch.\\n+    i, partial, outputs = tf.while_loop(\\n+        cond=lambda *_: True,\\n+        body=body_fn,\\n+        loop_vars=(i, partial, outputs),\\n+        shape_invariants=(\\n+            tf.TensorShape([]),\\n+            {k: tf.TensorShape([None]) for k in keys_etc},\\n+            {k: tf.TensorShape(None) for k in keys_etc},\\n+        ),\\n+        maximum_iterations=dynamic_batch_size)\\n+    _, outputs = write_packed_example(partial, outputs)\\n+    packed = {k: outputs[k].stack() for k in keys_etc}\\n+    for k in keys:\\n+      packed[k + '_segmentation'] = (\\n+          tf.cumsum(\\n+              tf.cast(tf.equal(packed[k + '_position'], 0), tf.int32), axis=1) *\\n+          tf.cast(tf.not_equal(packed[k], 0), tf.int32))\\n+    return packed\\n+\\n+  dataset = dataset.map(map_fn, num_parallel_calls=AUTOTUNE)\\n+  return dataset.unbatch()\\n+\\n+\\n+# -----------------------------------------------------------------------------\\n+# Main dataset prep routines.\\n+# -----------------------------------------------------------------------------\\n+def preprocess_data(dataset,\\n+                    shuffle: bool,\\n+                    num_epochs: Optional[int] = 1,\\n+                    pack_examples: bool = True,\\n+                    shuffle_buffer_size: int = 1024,\\n+                    max_length: int = 512,\\n+                    batch_size: int = 256,\\n+                    drop_remainder: bool = True,\\n+                    prefetch_size: int = AUTOTUNE):\\n+  \"\"\"Shuffle and batch/pack the given dataset.\"\"\"\\n+\\n+  def length_filter(max_len):\\n+\\n+    def filter_fn(x):\\n+      source, target = x['inputs'], x['targets']\\n+      l = tf.maximum(tf.shape(source)[0], tf.shape(target)[0])\\n+      return tf.less(l, max_len + 1)\\n+\\n+    return filter_fn\\n+\\n+  if max_length > 0:\\n+    dataset = dataset.filter(length_filter(max_length))\\n+\\n+  if shuffle:\\n+    dataset = dataset.shuffle(shuffle_buffer_size)\\n+  dataset = dataset.repeat(num_epochs)\\n+\\n+  if pack_examples:\\n+    dataset = pack_dataset(dataset, max_length)\\n+    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\\n+  else:  # simple (static-shape) padded batching\\n+    dataset = dataset.padded_batch(\\n+        batch_size,\\n+        padded_shapes={\\n+            'inputs': max_length,\\n+            'targets': max_length\\n+        },\\n+        padding_values={\\n+            'inputs': 0,\\n+            'targets': 0\\n+        },\\n+        drop_remainder=drop_remainder)\\n+\\n+  if prefetch_size:\\n+    dataset = dataset.prefetch(prefetch_size)\\n+\\n+  return dataset\\n+\\n+\\n+def get_datasets(config: ml_collections.ConfigDict,\\n+                 *,\\n+                 n_devices: int,\\n+                 vocab_path: Optional[str] = None):\\n+  \"\"\"Load and return dataset of batched examples for use during training.\"\"\"\\n+  if vocab_path is None:\\n+    vocab_path = os.path.expanduser('~/lm1b_sentencepiece_model')\\n+\\n+  train_ds_builder = tfds.builder(config.dataset_name)\\n+  train_ds_builder.download_and_prepare()\\n+  train_data = get_raw_dataset(train_ds_builder, 'train')\\n+\\n+  if config.eval_dataset_name:\\n+    eval_ds_builder = tfds.builder(config.eval_dataset_name)\\n+  else:\\n+    eval_ds_builder = train_ds_builder\\n+  eval_data = get_raw_dataset(eval_ds_builder, config.eval_split)\\n+\\n+  # Tokenize data.\\n+  sp_tokenizer = tokenizer.load_or_train_tokenizer(\\n+      train_data,\\n+      vocab_path=vocab_path,\\n+      vocab_size=config.vocab_size,\\n+      max_corpus_chars=config.max_corpus_chars)\\n+  train_data = train_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+  eval_data = eval_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+\\n+  batch_size = config.per_device_batch_size * n_devices\\n+  if config.eval_per_device_batch_size > 0:\\n+    eval_batch_size = config.eval_per_device_batch_size * n_devices\\n+  else:\\n+    eval_batch_size = batch_size\\n+\\n+  train_ds = preprocess_data(\\n+      train_data,\\n+      shuffle=True,\\n+      num_epochs=None,\\n+      pack_examples=True,\\n+      batch_size=batch_size,\\n+      max_length=config.max_target_length)\\n+\\n+  eval_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_eval_target_length)\\n+\\n+  predict_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_predict_length,\\n+      drop_remainder=False)\\n+\\n+  return train_ds, eval_ds, predict_ds, sp_tokenizer\\n   \n",
              "\n",
              "  file_type Discrepancy  \n",
              "0   license         Yes  \n",
              "1    source         Yes  \n",
              "2    source         Yes  \n",
              "3    source         Yes  \n",
              "4    source         Yes  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba5f82c8-bc04-49da-be75-626ee85f9ca6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo_name</th>\n",
              "      <th>old_file_path</th>\n",
              "      <th>new_file_path</th>\n",
              "      <th>commit_sha</th>\n",
              "      <th>parent_commit_sha</th>\n",
              "      <th>commit_message</th>\n",
              "      <th>diff_myers</th>\n",
              "      <th>diff_hist</th>\n",
              "      <th>file_type</th>\n",
              "      <th>Discrepancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>maxtext</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LICENSE</td>\n",
              "      <td>696b089f888e57a468184d382e56b862985640f2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initial commit</td>\n",
              "      <td>@@ -0,0 +1,201 @@\\n+                                 Apache License\\n+                           Version 2.0, January 2004\\n+                        http://www.apache.org/licenses/\\n+\\n+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n+\\n+   1. Definitions.\\n+\\n+      \"License\" shall mean the terms and conditions for use, reproduction,\\n+      and distribution as defined by Sections 1 through 9 of this document.\\n+\\n+      \"Licensor\" shall mean the copyright owner or entity authorized by\\n+      the copyright owner that is granting the License.\\n+\\n+      \"Legal Entity\" shall mean the union of the acting entity and all\\n+      other entities that control, are controlled by, or are under common\\n+      control with that entity. For the purposes of this definition,\\n+      \"control\" means (i) the power, direct or indirect, to cause the\\n+      direction or management of such entity, whether by contract or\\n+      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n+      outstanding shares, or (iii) beneficial ownership of such entity.\\n+\\n+      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n+      exercising permissions granted by this License.\\n+\\n+      \"Source\" form shall mean the preferred form for making modifications,\\n+      including but not limited to software source code, documentation\\n+      source, and configuration files.\\n+\\n+      \"Object\" form shall mean any form resulting from mechanical\\n+      transformation or translation of a Source form, including but\\n+      not limited to compiled object code, generated documentation,\\n+      and conversions to other media types.\\n+\\n+      \"Work\" shall mean the work of authorship, whether in Source or\\n+      Object form, made available under the License, as indicated by a\\n+      copyright notice that is included in or attached to the work\\n+      (an example is provided in the Appendix below).\\n+\\n+      \"Derivative Works\" shall mean any work, whether in Source or Object\\n+      form, that is based on (or derived from) the Work and for which the\\n+      editorial revisions, annotations, elaborations, or other modifications\\n+      represent, as a whole, an original work of authorship. For the purposes\\n+      of this License, Derivative Works shall not include works that remain\\n+      separable from, or merely link (or bind by name) to the interfaces of,\\n+      the Work and Derivative Works thereof.\\n+\\n+      \"Contribution\" shall mean any work of authorship, including\\n+      the original version of the Work and any modifications or additions\\n+      to that Work or Derivative Works thereof, that is intentionally\\n+      submitted to Licensor for inclusion in the Work by the copyright owner\\n+      or by an individual or Legal Entity authorized to submit on behalf of\\n+      the copyright owner. For the purposes of this definition, \"submitted\"\\n+      means any form of electronic, verbal, or written communication sent\\n+      to the Licensor or its representatives, including but not limited to\\n+      communication on electronic mailing lists, source code control systems,\\n+      and issue tracking systems that are managed by, or on behalf of, the\\n+      Licensor for the purpose of discussing and improving the Work, but\\n+      excluding communication that is conspicuously marked or otherwise\\n+      designated in writing by the copyright owner as \"Not a Contribution.\"\\n+\\n+      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n+      on behalf of whom a Contribution has been received by Licensor and\\n+      subsequently incorporated within the Work.\\n+\\n+   2. Grant of Copyright License. Subject to the terms and conditions of\\n+      this License, each Contributor hereby grants to You a perpetual,\\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n+      copyright license to reproduce, prepare Derivative Works of,\\n+      publicly display, publicly perform, sublicense, and distribute the\\n+      Work and such Derivative Works in Source or Object form.\\n+\\n+   3. Grant of Patent License. Subject to the terms and conditions of\\n+      this License, each Contributor hereby grants to You a perpetual,\\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n+      (except as stated in this section) patent license to make, have made,\\n+      use, offer to sell, sell, import, and otherwise transfer the Work,\\n+      where such license applies only to those patent claims licensable\\n+      by such Contributor that are necessarily infringed by their\\n+      Contribution(s) alone or by combination of their Contribution(s)\\n+      with the Work to which such Contribution(s) was submitted. If You\\n+      institute patent litigation against any entity (including a\\n+      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n+      or a Contribution incorporated within the Work constitutes direct\\n+      or contributory patent infringement, then any patent licenses\\n+      granted to You under this License for that Work shall terminate\\n+      as of the date such litigation is filed.\\n+\\n+   4. Redistribution. You may reproduce and distribute copies of the\\n+      Work or Derivative Works thereof in any medium, with or without\\n+      modifications, and in Source or Object form, provided that You\\n+      meet the following conditions:\\n+\\n+      (a) You must give any other recipients of the Work or\\n+          Derivative Works a copy of this License; and\\n+\\n+      (b) You must cause any modified files to carry prominent notices\\n+          stating that You changed the files; and\\n+\\n+      (c) You must retain, in the Source form of any Derivative Works\\n+          that You distribute, all copyright, patent, trademark, and\\n+          attribution notices from the Source form of the Work,\\n+          excluding those notices that do not pertain to any part of\\n+          the Derivative Works; and\\n+\\n+      (d) If the Work includes a \"NOTICE\" text file as part of its\\n+          distribution, then any Derivative Works that You distribute must\\n+          include a readable copy of the attribution notices contained\\n+          within such NOTICE file, excluding those notices that do not\\n+          pertain to any part of the Derivative Works, in at least one\\n+          of the following places: within a NOTICE text file distributed\\n+          as part of the Derivative Works; within the Source form or\\n+          documentation, if provided along with the Derivative Works; or,\\n+          within a display generated by the Derivative Works, if and\\n+          wherever such third-party notices normally appear. The contents\\n+          of the NOTICE file are for informational purposes only and\\n+          do not modify the License. You may add Your own attribution\\n+          notices within Derivative Works that You distribute, alongside\\n+          or as an addendum to the NOTICE text from the Work, provided\\n+          that such additional attribution notices cannot be construed\\n+          as modifying the License.\\n+\\n+      You may add Your own copyright statement to Your modifications and\\n+      may provide additional or different license terms and conditions\\n+      for use, reproduction, or distribution of Your modifications, or\\n+      for any such Derivative Works as a whole, provided Your use,\\n+      reproduction, and distribution of the Work otherwise complies with\\n+      the conditions stated in this License.\\n+\\n+   5. Submission of Contributions. Unless You explicitly state otherwise,\\n+      any Contribution intentionally submitted for inclusion in the Work\\n+      by You to the Licensor shall be under the terms and conditions of\\n+      this License, without any additional terms or conditions.\\n+      Notwithstanding the above, nothing herein shall supersede or modify\\n+      the terms of any separate license agreement you may have executed\\n+      with Licensor regarding such Contributions.\\n+\\n+   6. Trademarks. This License does not grant permission to use the trade\\n+      names, trademarks, service marks, or product names of the Licensor,\\n+      except as required for reasonable and customary use in describing the\\n+      origin of the Work and reproducing the content of the NOTICE file.\\n+\\n+   7. Disclaimer of Warranty. Unless required by applicable law or\\n+      agreed to in writing, Licensor provides the Work (and each\\n+      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n+      implied, including, without limitation, any warranties or conditions\\n+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n+      PARTICULAR PURPOSE. You are solely responsible for determining the\\n+      appropriateness of using or redistributing the Work and assume any\\n+      risks associated with Your exercise of permissions under this License.\\n+\\n+   8. Limitation of Liability. In no event and under no legal theory,\\n+      whether in tort (including negligence), contract, or otherwise,\\n+      unless required by applicable law (such as deliberate and grossly\\n+      negligent acts) or agreed to in writing, shall any Contributor be\\n+      liable to You for damages, including any direct, indirect, special,\\n+      incidental, or consequential damages of any character arising as a\\n+      result of this License or out of the use or inability to use the\\n+      Work (including but not limited to damages for loss of goodwill,\\n+      work stoppage, computer failure or malfunction, or any and all\\n+      other commercial damages or losses), even if such Contributor\\n+      has been advised of the possibility of such damages.\\n+\\n+   9. Accepting Warranty or Additional Liability. While redistributing\\n+      the Work or Derivative Works thereof, You may choose to offer,\\n+      and charge a fee for, acceptance of support, warranty, indemnity,\\n+      or other liability obligations and/or rights consistent with this\\n+      License. However, in accepting such obligations, You may act only\\n+      on Your own behalf and on Your sole responsibility, not on behalf\\n+      of any other Contributor, and only if You agree to indemnify,\\n+      defend, and hold each Contributor harmless for any liability\\n+      incurred by, or claims asserted against, such Contributor by reason\\n+      of your accepting any such warranty or additional liability.\\n+\\n+   END OF TERMS AND CONDITIONS\\n+\\n+   APPENDIX: How to apply the Apache License to your work.\\n+\\n+      To apply the Apache License to your work, attach the following\\n+      boilerplate notice, with the fields enclosed by brackets \"[]\"\\n+      replaced with your own identifying information. (Don't include\\n+      the brackets!)  The text should be enclosed in the appropriate\\n+      comment syntax for the file format. We also recommend that a\\n+      file or class name and description of purpose be included on the\\n+      same \"printed page\" as the copyright notice for easier\\n+      identification within third-party archives.\\n+\\n+   Copyright [yyyy] [name of copyright owner]\\n+\\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\\n+   you may not use this file except in compliance with the License.\\n+   You may obtain a copy of the License at\\n+\\n+       http://www.apache.org/licenses/LICENSE-2.0\\n+\\n+   Unless required by applicable law or agreed to in writing, software\\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n+   See the License for the specific language governing permissions and\\n+   limitations under the License.\\n</td>\n",
              "      <td>Command '['git', '-C', 'maxtext', 'diff', '--histogram', '696b089f888e57a468184d382e56b862985640f2^', '696b089f888e57a468184d382e56b862985640f2', '--', 'LICENSE']' returned non-zero exit status 128.</td>\n",
              "      <td>license</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>maxtext</td>\n",
              "      <td>NaN</td>\n",
              "      <td>.gitignore</td>\n",
              "      <td>ef558122cde2877c82671fe23fa2ab408552c522</td>\n",
              "      <td>696b089f888e57a468184d382e56b862985640f2</td>\n",
              "      <td>Hard-forking a codebase generously shared by Anselm/JET</td>\n",
              "      <td>@@ -0,0 +1 @@\\n+*__pycache__*\\n</td>\n",
              "      <td>diff --git a/.gitignore b/.gitignore\\nnew file mode 100644\\nindex 00000000..cd4c22c4\\n--- /dev/null\\n+++ b/.gitignore\\n@@ -0,0 +1 @@\\n+*__pycache__*\\n</td>\n",
              "      <td>source</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>maxtext</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MaxText/__init__.py</td>\n",
              "      <td>ef558122cde2877c82671fe23fa2ab408552c522</td>\n",
              "      <td>696b089f888e57a468184d382e56b862985640f2</td>\n",
              "      <td>Hard-forking a codebase generously shared by Anselm/JET</td>\n",
              "      <td>@@ -0,0 +1 @@\\n+# adhd\\n</td>\n",
              "      <td>diff --git a/MaxText/__init__.py b/MaxText/__init__.py\\nnew file mode 100644\\nindex 00000000..f424dbec\\n--- /dev/null\\n+++ b/MaxText/__init__.py\\n@@ -0,0 +1 @@\\n+# adhd\\n</td>\n",
              "      <td>source</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>maxtext</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MaxText/config.py</td>\n",
              "      <td>ef558122cde2877c82671fe23fa2ab408552c522</td>\n",
              "      <td>696b089f888e57a468184d382e56b862985640f2</td>\n",
              "      <td>Hard-forking a codebase generously shared by Anselm/JET</td>\n",
              "      <td>@@ -0,0 +1,66 @@\\n+\"\"\"Config for training.\"\"\"\\n+\\n+from typing import Any, Sequence, Tuple\\n+from flax import struct\\n+import jax.numpy as jnp\\n+\\n+\\n+@struct.dataclass\\n+class T5Config:\\n+  \"\"\"Global hyperparameters used to minimize obnoxious kwarg plumbing.\"\"\"\\n+\\n+  # Activation dtypes.\\n+  dtype: Any = jnp.float32\\n+  emb_dim: int = 128\\n+  num_heads: int = 8\\n+  head_dim: int = 16\\n+  mlp_dim: int = 512\\n+  num_decoder_layers: int = 6\\n+  # activation functions are .\\n+  mlp_activations: Sequence[str] = ('relu',)\\n+  dropout_rate: float = 0\\n+  # If `True`, the embedding weights are used in the decoder output layer.\\n+  logits_via_embedding: bool = True  # NOTE: this is True just for testing.\\n+  # minimal, full, or none\\n+  remat_policy: str = 'none'\\n+  scan_layers: bool = False\\n+  param_scan_axis: int = 1\\n+\\n+  # Parallelism\\n+  mesh_shape: Tuple[int] = (4,)\\n+  mesh_axes: Tuple[str] = ('data',)\\n+  logical_axis_rules: Sequence = ( ('batch', 'data'), )\\n+\\n+  # Dataset\\n+  vocab_size: int = 30000\\n+  dataset_name: str = 'lm1b'\\n+  eval_dataset_name: str = 'lm1b'\\n+  eval_split: str = 'test'\\n+  per_device_batch_size: int = 32\\n+  eval_per_device_batch_size: int = 0\\n+  max_corpus_chars: int = 10**7  # for tokenization\\n+\\n+  # Training loop\\n+  steps: int = 20_000_000\\n+  log_period: int = 500\\n+  save_period: int = 2000\\n+  learning_rate: float = 1e-3\\n+  warmup_steps: int = 1000\\n+  save_checkpoints: bool = False\\n+  restore_checkpoints: bool = False\\n+\\n+  # Maximum length cutoff for training examples.\\n+  max_target_length: int = 128\\n+  # Maximum length cutoff for held-out evaluation examples.\\n+  max_eval_target_length: int = 512\\n+\\n+  # Maximum length cutoff for predicted tokens.\\n+  max_predict_length: int = 50\\n+  # Sampling temperature for language model inference.\\n+  sampling_temperature: float = 0.6\\n+  # Top k cutoff for logit sampling. If 0 then no top-k cutoff is used.\\n+  sampling_top_k: int = 20\\n+  eos_id: int = 2  # sentencepiece default\\n+  # Prompt for language model sampling.\\n+  prompt: str = \"I love to \"\\n+\\n</td>\n",
              "      <td>diff --git a/MaxText/config.py b/MaxText/config.py\\nnew file mode 100644\\nindex 00000000..71317091\\n--- /dev/null\\n+++ b/MaxText/config.py\\n@@ -0,0 +1,66 @@\\n+\"\"\"Config for training.\"\"\"\\n+\\n+from typing import Any, Sequence, Tuple\\n+from flax import struct\\n+import jax.numpy as jnp\\n+\\n+\\n+@struct.dataclass\\n+class T5Config:\\n+  \"\"\"Global hyperparameters used to minimize obnoxious kwarg plumbing.\"\"\"\\n+\\n+  # Activation dtypes.\\n+  dtype: Any = jnp.float32\\n+  emb_dim: int = 128\\n+  num_heads: int = 8\\n+  head_dim: int = 16\\n+  mlp_dim: int = 512\\n+  num_decoder_layers: int = 6\\n+  # activation functions are .\\n+  mlp_activations: Sequence[str] = ('relu',)\\n+  dropout_rate: float = 0\\n+  # If `True`, the embedding weights are used in the decoder output layer.\\n+  logits_via_embedding: bool = True  # NOTE: this is True just for testing.\\n+  # minimal, full, or none\\n+  remat_policy: str = 'none'\\n+  scan_layers: bool = False\\n+  param_scan_axis: int = 1\\n+\\n+  # Parallelism\\n+  mesh_shape: Tuple[int] = (4,)\\n+  mesh_axes: Tuple[str] = ('data',)\\n+  logical_axis_rules: Sequence = ( ('batch', 'data'), )\\n+\\n+  # Dataset\\n+  vocab_size: int = 30000\\n+  dataset_name: str = 'lm1b'\\n+  eval_dataset_name: str = 'lm1b'\\n+  eval_split: str = 'test'\\n+  per_device_batch_size: int = 32\\n+  eval_per_device_batch_size: int = 0\\n+  max_corpus_chars: int = 10**7  # for tokenization\\n+\\n+  # Training loop\\n+  steps: int = 20_000_000\\n+  log_period: int = 500\\n+  save_period: int = 2000\\n+  learning_rate: float = 1e-3\\n+  warmup_steps: int = 1000\\n+  save_checkpoints: bool = False\\n+  restore_checkpoints: bool = False\\n+\\n+  # Maximum length cutoff for training examples.\\n+  max_target_length: int = 128\\n+  # Maximum length cutoff for held-out evaluation examples.\\n+  max_eval_target_length: int = 512\\n+\\n+  # Maximum length cutoff for predicted tokens.\\n+  max_predict_length: int = 50\\n+  # Sampling temperature for language model inference.\\n+  sampling_temperature: float = 0.6\\n+  # Top k cutoff for logit sampling. If 0 then no top-k cutoff is used.\\n+  sampling_top_k: int = 20\\n+  eos_id: int = 2  # sentencepiece default\\n+  # Prompt for language model sampling.\\n+  prompt: str = \"I love to \"\\n+\\n</td>\n",
              "      <td>source</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>maxtext</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MaxText/input_pipeline.py</td>\n",
              "      <td>ef558122cde2877c82671fe23fa2ab408552c522</td>\n",
              "      <td>696b089f888e57a468184d382e56b862985640f2</td>\n",
              "      <td>Hard-forking a codebase generously shared by Anselm/JET</td>\n",
              "      <td>@@ -0,0 +1,340 @@\\n+\"\"\"Input pipeline for a LM1B dataset.\"\"\"\\n+\\n+import os\\n+from typing import Dict, Optional, List, Union\\n+\\n+from clu import deterministic_data\\n+import ml_collections\\n+import tensorflow as tf\\n+import tensorflow_datasets as tfds\\n+\\n+from adhd import tokenizer\\n+\\n+AUTOTUNE = tf.data.experimental.AUTOTUNE\\n+Features = Dict[str, tf.Tensor]\\n+\\n+\\n+class NormalizeFeatureNamesOp:\\n+  \"\"\"Normalizes feature names to 'inputs' and 'targets'.\"\"\"\\n+\\n+  def __init__(self, ds_info: tfds.core.DatasetInfo):\\n+    self.ds_info = ds_info\\n+\\n+  def __call__(self, features: Features) -&gt; Features:\\n+    features['inputs'] = features.pop('text')\\n+    # Unnecessary step used for uniformizing with examples/wmt.\\n+    features['targets'] = features['inputs']\\n+    return features\\n+\\n+\\n+def get_raw_dataset(dataset_builder: tfds.core.DatasetBuilder,\\n+                    split: str) -&gt; tf.data.Dataset:\\n+  \"\"\"Loads a raw text dataset and normalizes feature keys.\\n+  Args:\\n+    dataset_builder: TFDS dataset builder that can build `split`.\\n+    split: Split to use. This must be the full split. We shard the split across\\n+      multiple hosts and currently don't support sharding subsplits.\\n+  Returns:\\n+    Dataset with source and target language features mapped to 'inputs' and\\n+    'targets'.\\n+  \"\"\"\\n+  per_host_split = tfds.split_for_jax_process(split, drop_remainder=False)\\n+  ds = dataset_builder.as_dataset(split=per_host_split, shuffle_files=False)\\n+  ds = ds.map(\\n+      NormalizeFeatureNamesOp(dataset_builder.info),\\n+      num_parallel_calls=AUTOTUNE)\\n+  return ds\\n+\\n+\\n+def pack_dataset(dataset: tf.data.Dataset,\\n+                 key2length: Union[int, Dict[str, int]],\\n+                 keys: Optional[List[str]] = None) -&gt; tf.data.Dataset:\\n+  \"\"\"Creates a 'packed' version of a dataset on-the-fly.\\n+  Adapted from the mesh-tf implementation.\\n+  This is meant to replace the irritation of having to create a separate\\n+  \"packed\" version of a dataset to train efficiently on TPU.\\n+  Each example in the output dataset represents several examples in the\\n+  input dataset.\\n+  For each key in the input dataset, two additional keys are created:\\n+  &lt;key&gt;_segmentation: an int32 tensor identifying the parts\\n+     representing the original example.\\n+  &lt;key&gt;_position: an int32 tensor identifying the position within the original\\n+     example.\\n+  Example:\\n+  Two input examples get combined to form an output example.\\n+  The input examples are:\\n+  {\"inputs\": [8, 7, 1, 0], \"targets\":[4, 1, 0]}\\n+  {\"inputs\": [2, 3, 4, 1], \"targets\":[5, 6, 1]}\\n+  The output example is:\\n+  {\\n+                 \"inputs\": [8, 7, 1, 2, 3, 4, 1, 0, 0, 0]\\n+    \"inputs_segmentation\": [1, 1, 1, 2, 2, 2, 2, 0, 0, 0]\\n+        \"inputs_position\": [0, 1, 2, 0, 1, 2, 3, 0, 0, 0]\\n+                \"targets\": [4, 1, 5, 6, 1, 0, 0, 0, 0, 0]\\n+   \"targets_segmentation\": [1, 1, 2, 2, 2, 0, 0, 0, 0, 0]\\n+       \"targets_position\": [0, 1, 0, 1, 2, 0, 0, 0, 0, 0]\\n+  }\\n+  0 represents padding in both the inputs and the outputs.\\n+  Sequences in the incoming examples are truncated to length \"length\", and the\\n+  sequences in the output examples all have fixed (padded) length \"length\".\\n+  Args:\\n+    dataset: a tf.data.Dataset\\n+    key2length: an integer, or a dict from feature-key to integer\\n+    keys: a list of strings (e.g. [\"inputs\", \"targets\"])\\n+  Returns:\\n+    a tf.data.Dataset\\n+  \"\"\"\\n+  shapes = tf.nest.map_structure(lambda spec: spec.shape, dataset.element_spec)\\n+  if keys is None:\\n+    keys = list(shapes.keys())\\n+  for k in keys:\\n+    if k not in shapes:\\n+      raise ValueError('Key %s not found in dataset.  Available keys are %s' %\\n+                       (k, shapes.keys()))\\n+    if not shapes[k].is_compatible_with(tf.TensorShape([None])):\\n+      raise ValueError('Tensors to be packed must be one-dimensional.')\\n+  # make sure that the length dictionary contains all keys as well as the\\n+  # keys suffixed by \"_segmentation\" and \"_position\"\\n+  if isinstance(key2length, int):\\n+    key2length = {k: key2length for k in keys}\\n+  for k in keys:\\n+    for suffix in ['_segmentation', '_position']:\\n+      key2length[k + suffix] = key2length[k]\\n+\\n+  # trim to length\\n+  dataset = dataset.map(\\n+      lambda x: {k: x[k][:key2length[k]] for k in keys},\\n+      num_parallel_calls=AUTOTUNE)\\n+  # Setting batch_size=length ensures that the concatenated sequences (if they\\n+  # have length &gt;=1) are sufficient to fill at least one packed example.\\n+  batch_size = max(key2length.values())\\n+  dataset = dataset.padded_batch(\\n+      batch_size, padded_shapes={k: [-1] for k in keys})\\n+  dataset = _pack_with_tf_ops(dataset, keys, key2length)\\n+\\n+  # Set the Tensor shapes correctly since they get lost in the process.\\n+  def my_fn(x):\\n+    return {k: tf.reshape(v, [key2length[k]]) for k, v in x.items()}\\n+\\n+  return dataset.map(my_fn, num_parallel_calls=AUTOTUNE)\\n+\\n+\\n+def _pack_with_tf_ops(dataset: tf.data.Dataset, keys: List[str],\\n+                      key2length: Dict[str, int]) -&gt; tf.data.Dataset:\\n+  \"\"\"Helper-function for packing a dataset which has already been batched.\\n+  Helper for pack_dataset()  Uses tf.while_loop.\\n+  Args:\\n+    dataset: a dataset containing padded batches of examples.\\n+    keys: a list of strings\\n+    key2length: an dict from feature-key to integer\\n+  Returns:\\n+    a dataset.\\n+  \"\"\"\\n+  empty_example = {}\\n+  for k in keys:\\n+    empty_example[k] = tf.zeros([0], dtype=tf.int32)\\n+    empty_example[k + '_position'] = tf.zeros([0], dtype=tf.int32)\\n+  keys_etc = empty_example.keys()\\n+\\n+  def write_packed_example(partial, outputs):\\n+    new_partial = empty_example.copy()\\n+    new_outputs = {}\\n+    for k in keys_etc:\\n+      new_outputs[k] = outputs[k].write(\\n+          outputs[k].size(),\\n+          tf.pad(partial[k], [[0, key2length[k] - tf.size(partial[k])]]))\\n+    return new_partial, new_outputs\\n+\\n+  def map_fn(x):\\n+    \"\"\"Internal function to flat_map over.\\n+    Consumes a batch of input examples and produces a variable number of output\\n+    examples.\\n+    Args:\\n+      x: a single example\\n+    Returns:\\n+      a tf.data.Dataset\\n+    \"\"\"\\n+    partial = empty_example.copy()\\n+    i = tf.zeros([], dtype=tf.int32)\\n+    dynamic_batch_size = tf.shape(x[keys[0]])[0]\\n+    outputs = {}\\n+    for k in keys:\\n+      outputs[k] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+      outputs[k + '_position'] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+\\n+    def body_fn(i, partial, outputs):\\n+      \"\"\"Body function for while_loop.\\n+      Args:\\n+        i: integer scalar\\n+        partial: dictionary of Tensor (partially-constructed example)\\n+        outputs: dictionary of TensorArray\\n+      Returns:\\n+        A triple containing the new values of the inputs.\\n+      \"\"\"\\n+      can_append = True\\n+      one_example = {}\\n+      for k in keys:\\n+        val = tf.cast(x[k][i], tf.int32)\\n+        val = val[:tf.reduce_sum(tf.cast(tf.not_equal(val, 0), tf.int32))]\\n+        one_example[k] = val\\n+      for k in keys:\\n+        can_append = tf.logical_and(\\n+            can_append,\\n+            tf.less_equal(\\n+                tf.size(partial[k]) + tf.size(one_example[k]), key2length[k]))\\n+\\n+      def false_fn():\\n+        return write_packed_example(partial, outputs)\\n+\\n+      def true_fn():\\n+        return partial, outputs\\n+\\n+      partial, outputs = tf.cond(can_append, true_fn, false_fn)\\n+      new_partial = {}\\n+      for k in keys:\\n+        new_seq = one_example[k][:key2length[k]]\\n+        new_seq_len = tf.size(new_seq)\\n+        new_partial[k] = tf.concat([partial[k], new_seq], 0)\\n+        new_partial[k + '_position'] = tf.concat(\\n+            [partial[k + '_position'],\\n+             tf.range(new_seq_len)], 0)\\n+      partial = new_partial\\n+      return i + 1, partial, outputs\\n+\\n+    # For loop over all examples in the batch.\\n+    i, partial, outputs = tf.while_loop(\\n+        cond=lambda *_: True,\\n+        body=body_fn,\\n+        loop_vars=(i, partial, outputs),\\n+        shape_invariants=(\\n+            tf.TensorShape([]),\\n+            {k: tf.TensorShape([None]) for k in keys_etc},\\n+            {k: tf.TensorShape(None) for k in keys_etc},\\n+        ),\\n+        maximum_iterations=dynamic_batch_size)\\n+    _, outputs = write_packed_example(partial, outputs)\\n+    packed = {k: outputs[k].stack() for k in keys_etc}\\n+    for k in keys:\\n+      packed[k + '_segmentation'] = (\\n+          tf.cumsum(\\n+              tf.cast(tf.equal(packed[k + '_position'], 0), tf.int32), axis=1) *\\n+          tf.cast(tf.not_equal(packed[k], 0), tf.int32))\\n+    return packed\\n+\\n+  dataset = dataset.map(map_fn, num_parallel_calls=AUTOTUNE)\\n+  return dataset.unbatch()\\n+\\n+\\n+# -----------------------------------------------------------------------------\\n+# Main dataset prep routines.\\n+# -----------------------------------------------------------------------------\\n+def preprocess_data(dataset,\\n+                    shuffle: bool,\\n+                    num_epochs: Optional[int] = 1,\\n+                    pack_examples: bool = True,\\n+                    shuffle_buffer_size: int = 1024,\\n+                    max_length: int = 512,\\n+                    batch_size: int = 256,\\n+                    drop_remainder: bool = True,\\n+                    prefetch_size: int = AUTOTUNE):\\n+  \"\"\"Shuffle and batch/pack the given dataset.\"\"\"\\n+\\n+  def length_filter(max_len):\\n+\\n+    def filter_fn(x):\\n+      source, target = x['inputs'], x['targets']\\n+      l = tf.maximum(tf.shape(source)[0], tf.shape(target)[0])\\n+      return tf.less(l, max_len + 1)\\n+\\n+    return filter_fn\\n+\\n+  if max_length &gt; 0:\\n+    dataset = dataset.filter(length_filter(max_length))\\n+\\n+  if shuffle:\\n+    dataset = dataset.shuffle(shuffle_buffer_size)\\n+  dataset = dataset.repeat(num_epochs)\\n+\\n+  if pack_examples:\\n+    dataset = pack_dataset(dataset, max_length)\\n+    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\\n+  else:  # simple (static-shape) padded batching\\n+    dataset = dataset.padded_batch(\\n+        batch_size,\\n+        padded_shapes={\\n+            'inputs': max_length,\\n+            'targets': max_length\\n+        },\\n+        padding_values={\\n+            'inputs': 0,\\n+            'targets': 0\\n+        },\\n+        drop_remainder=drop_remainder)\\n+\\n+  if prefetch_size:\\n+    dataset = dataset.prefetch(prefetch_size)\\n+\\n+  return dataset\\n+\\n+\\n+def get_datasets(config: ml_collections.ConfigDict,\\n+                 *,\\n+                 n_devices: int,\\n+                 vocab_path: Optional[str] = None):\\n+  \"\"\"Load and return dataset of batched examples for use during training.\"\"\"\\n+  if vocab_path is None:\\n+    vocab_path = os.path.expanduser('~/lm1b_sentencepiece_model')\\n+\\n+  train_ds_builder = tfds.builder(config.dataset_name)\\n+  train_ds_builder.download_and_prepare()\\n+  train_data = get_raw_dataset(train_ds_builder, 'train')\\n+\\n+  if config.eval_dataset_name:\\n+    eval_ds_builder = tfds.builder(config.eval_dataset_name)\\n+  else:\\n+    eval_ds_builder = train_ds_builder\\n+  eval_data = get_raw_dataset(eval_ds_builder, config.eval_split)\\n+\\n+  # Tokenize data.\\n+  sp_tokenizer = tokenizer.load_or_train_tokenizer(\\n+      train_data,\\n+      vocab_path=vocab_path,\\n+      vocab_size=config.vocab_size,\\n+      max_corpus_chars=config.max_corpus_chars)\\n+  train_data = train_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+  eval_data = eval_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+\\n+  batch_size = config.per_device_batch_size * n_devices\\n+  if config.eval_per_device_batch_size &gt; 0:\\n+    eval_batch_size = config.eval_per_device_batch_size * n_devices\\n+  else:\\n+    eval_batch_size = batch_size\\n+\\n+  train_ds = preprocess_data(\\n+      train_data,\\n+      shuffle=True,\\n+      num_epochs=None,\\n+      pack_examples=True,\\n+      batch_size=batch_size,\\n+      max_length=config.max_target_length)\\n+\\n+  eval_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_eval_target_length)\\n+\\n+  predict_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_predict_length,\\n+      drop_remainder=False)\\n+\\n+  return train_ds, eval_ds, predict_ds, sp_tokenizer\\n</td>\n",
              "      <td>diff --git a/MaxText/input_pipeline.py b/MaxText/input_pipeline.py\\nnew file mode 100644\\nindex 00000000..8328ccad\\n--- /dev/null\\n+++ b/MaxText/input_pipeline.py\\n@@ -0,0 +1,340 @@\\n+\"\"\"Input pipeline for a LM1B dataset.\"\"\"\\n+\\n+import os\\n+from typing import Dict, Optional, List, Union\\n+\\n+from clu import deterministic_data\\n+import ml_collections\\n+import tensorflow as tf\\n+import tensorflow_datasets as tfds\\n+\\n+from adhd import tokenizer\\n+\\n+AUTOTUNE = tf.data.experimental.AUTOTUNE\\n+Features = Dict[str, tf.Tensor]\\n+\\n+\\n+class NormalizeFeatureNamesOp:\\n+  \"\"\"Normalizes feature names to 'inputs' and 'targets'.\"\"\"\\n+\\n+  def __init__(self, ds_info: tfds.core.DatasetInfo):\\n+    self.ds_info = ds_info\\n+\\n+  def __call__(self, features: Features) -&gt; Features:\\n+    features['inputs'] = features.pop('text')\\n+    # Unnecessary step used for uniformizing with examples/wmt.\\n+    features['targets'] = features['inputs']\\n+    return features\\n+\\n+\\n+def get_raw_dataset(dataset_builder: tfds.core.DatasetBuilder,\\n+                    split: str) -&gt; tf.data.Dataset:\\n+  \"\"\"Loads a raw text dataset and normalizes feature keys.\\n+  Args:\\n+    dataset_builder: TFDS dataset builder that can build `split`.\\n+    split: Split to use. This must be the full split. We shard the split across\\n+      multiple hosts and currently don't support sharding subsplits.\\n+  Returns:\\n+    Dataset with source and target language features mapped to 'inputs' and\\n+    'targets'.\\n+  \"\"\"\\n+  per_host_split = tfds.split_for_jax_process(split, drop_remainder=False)\\n+  ds = dataset_builder.as_dataset(split=per_host_split, shuffle_files=False)\\n+  ds = ds.map(\\n+      NormalizeFeatureNamesOp(dataset_builder.info),\\n+      num_parallel_calls=AUTOTUNE)\\n+  return ds\\n+\\n+\\n+def pack_dataset(dataset: tf.data.Dataset,\\n+                 key2length: Union[int, Dict[str, int]],\\n+                 keys: Optional[List[str]] = None) -&gt; tf.data.Dataset:\\n+  \"\"\"Creates a 'packed' version of a dataset on-the-fly.\\n+  Adapted from the mesh-tf implementation.\\n+  This is meant to replace the irritation of having to create a separate\\n+  \"packed\" version of a dataset to train efficiently on TPU.\\n+  Each example in the output dataset represents several examples in the\\n+  input dataset.\\n+  For each key in the input dataset, two additional keys are created:\\n+  &lt;key&gt;_segmentation: an int32 tensor identifying the parts\\n+     representing the original example.\\n+  &lt;key&gt;_position: an int32 tensor identifying the position within the original\\n+     example.\\n+  Example:\\n+  Two input examples get combined to form an output example.\\n+  The input examples are:\\n+  {\"inputs\": [8, 7, 1, 0], \"targets\":[4, 1, 0]}\\n+  {\"inputs\": [2, 3, 4, 1], \"targets\":[5, 6, 1]}\\n+  The output example is:\\n+  {\\n+                 \"inputs\": [8, 7, 1, 2, 3, 4, 1, 0, 0, 0]\\n+    \"inputs_segmentation\": [1, 1, 1, 2, 2, 2, 2, 0, 0, 0]\\n+        \"inputs_position\": [0, 1, 2, 0, 1, 2, 3, 0, 0, 0]\\n+                \"targets\": [4, 1, 5, 6, 1, 0, 0, 0, 0, 0]\\n+   \"targets_segmentation\": [1, 1, 2, 2, 2, 0, 0, 0, 0, 0]\\n+       \"targets_position\": [0, 1, 0, 1, 2, 0, 0, 0, 0, 0]\\n+  }\\n+  0 represents padding in both the inputs and the outputs.\\n+  Sequences in the incoming examples are truncated to length \"length\", and the\\n+  sequences in the output examples all have fixed (padded) length \"length\".\\n+  Args:\\n+    dataset: a tf.data.Dataset\\n+    key2length: an integer, or a dict from feature-key to integer\\n+    keys: a list of strings (e.g. [\"inputs\", \"targets\"])\\n+  Returns:\\n+    a tf.data.Dataset\\n+  \"\"\"\\n+  shapes = tf.nest.map_structure(lambda spec: spec.shape, dataset.element_spec)\\n+  if keys is None:\\n+    keys = list(shapes.keys())\\n+  for k in keys:\\n+    if k not in shapes:\\n+      raise ValueError('Key %s not found in dataset.  Available keys are %s' %\\n+                       (k, shapes.keys()))\\n+    if not shapes[k].is_compatible_with(tf.TensorShape([None])):\\n+      raise ValueError('Tensors to be packed must be one-dimensional.')\\n+  # make sure that the length dictionary contains all keys as well as the\\n+  # keys suffixed by \"_segmentation\" and \"_position\"\\n+  if isinstance(key2length, int):\\n+    key2length = {k: key2length for k in keys}\\n+  for k in keys:\\n+    for suffix in ['_segmentation', '_position']:\\n+      key2length[k + suffix] = key2length[k]\\n+\\n+  # trim to length\\n+  dataset = dataset.map(\\n+      lambda x: {k: x[k][:key2length[k]] for k in keys},\\n+      num_parallel_calls=AUTOTUNE)\\n+  # Setting batch_size=length ensures that the concatenated sequences (if they\\n+  # have length &gt;=1) are sufficient to fill at least one packed example.\\n+  batch_size = max(key2length.values())\\n+  dataset = dataset.padded_batch(\\n+      batch_size, padded_shapes={k: [-1] for k in keys})\\n+  dataset = _pack_with_tf_ops(dataset, keys, key2length)\\n+\\n+  # Set the Tensor shapes correctly since they get lost in the process.\\n+  def my_fn(x):\\n+    return {k: tf.reshape(v, [key2length[k]]) for k, v in x.items()}\\n+\\n+  return dataset.map(my_fn, num_parallel_calls=AUTOTUNE)\\n+\\n+\\n+def _pack_with_tf_ops(dataset: tf.data.Dataset, keys: List[str],\\n+                      key2length: Dict[str, int]) -&gt; tf.data.Dataset:\\n+  \"\"\"Helper-function for packing a dataset which has already been batched.\\n+  Helper for pack_dataset()  Uses tf.while_loop.\\n+  Args:\\n+    dataset: a dataset containing padded batches of examples.\\n+    keys: a list of strings\\n+    key2length: an dict from feature-key to integer\\n+  Returns:\\n+    a dataset.\\n+  \"\"\"\\n+  empty_example = {}\\n+  for k in keys:\\n+    empty_example[k] = tf.zeros([0], dtype=tf.int32)\\n+    empty_example[k + '_position'] = tf.zeros([0], dtype=tf.int32)\\n+  keys_etc = empty_example.keys()\\n+\\n+  def write_packed_example(partial, outputs):\\n+    new_partial = empty_example.copy()\\n+    new_outputs = {}\\n+    for k in keys_etc:\\n+      new_outputs[k] = outputs[k].write(\\n+          outputs[k].size(),\\n+          tf.pad(partial[k], [[0, key2length[k] - tf.size(partial[k])]]))\\n+    return new_partial, new_outputs\\n+\\n+  def map_fn(x):\\n+    \"\"\"Internal function to flat_map over.\\n+    Consumes a batch of input examples and produces a variable number of output\\n+    examples.\\n+    Args:\\n+      x: a single example\\n+    Returns:\\n+      a tf.data.Dataset\\n+    \"\"\"\\n+    partial = empty_example.copy()\\n+    i = tf.zeros([], dtype=tf.int32)\\n+    dynamic_batch_size = tf.shape(x[keys[0]])[0]\\n+    outputs = {}\\n+    for k in keys:\\n+      outputs[k] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+      outputs[k + '_position'] = tf.TensorArray(\\n+          tf.int32, size=0, dynamic_size=True, element_shape=[key2length[k]])\\n+\\n+    def body_fn(i, partial, outputs):\\n+      \"\"\"Body function for while_loop.\\n+      Args:\\n+        i: integer scalar\\n+        partial: dictionary of Tensor (partially-constructed example)\\n+        outputs: dictionary of TensorArray\\n+      Returns:\\n+        A triple containing the new values of the inputs.\\n+      \"\"\"\\n+      can_append = True\\n+      one_example = {}\\n+      for k in keys:\\n+        val = tf.cast(x[k][i], tf.int32)\\n+        val = val[:tf.reduce_sum(tf.cast(tf.not_equal(val, 0), tf.int32))]\\n+        one_example[k] = val\\n+      for k in keys:\\n+        can_append = tf.logical_and(\\n+            can_append,\\n+            tf.less_equal(\\n+                tf.size(partial[k]) + tf.size(one_example[k]), key2length[k]))\\n+\\n+      def false_fn():\\n+        return write_packed_example(partial, outputs)\\n+\\n+      def true_fn():\\n+        return partial, outputs\\n+\\n+      partial, outputs = tf.cond(can_append, true_fn, false_fn)\\n+      new_partial = {}\\n+      for k in keys:\\n+        new_seq = one_example[k][:key2length[k]]\\n+        new_seq_len = tf.size(new_seq)\\n+        new_partial[k] = tf.concat([partial[k], new_seq], 0)\\n+        new_partial[k + '_position'] = tf.concat(\\n+            [partial[k + '_position'],\\n+             tf.range(new_seq_len)], 0)\\n+      partial = new_partial\\n+      return i + 1, partial, outputs\\n+\\n+    # For loop over all examples in the batch.\\n+    i, partial, outputs = tf.while_loop(\\n+        cond=lambda *_: True,\\n+        body=body_fn,\\n+        loop_vars=(i, partial, outputs),\\n+        shape_invariants=(\\n+            tf.TensorShape([]),\\n+            {k: tf.TensorShape([None]) for k in keys_etc},\\n+            {k: tf.TensorShape(None) for k in keys_etc},\\n+        ),\\n+        maximum_iterations=dynamic_batch_size)\\n+    _, outputs = write_packed_example(partial, outputs)\\n+    packed = {k: outputs[k].stack() for k in keys_etc}\\n+    for k in keys:\\n+      packed[k + '_segmentation'] = (\\n+          tf.cumsum(\\n+              tf.cast(tf.equal(packed[k + '_position'], 0), tf.int32), axis=1) *\\n+          tf.cast(tf.not_equal(packed[k], 0), tf.int32))\\n+    return packed\\n+\\n+  dataset = dataset.map(map_fn, num_parallel_calls=AUTOTUNE)\\n+  return dataset.unbatch()\\n+\\n+\\n+# -----------------------------------------------------------------------------\\n+# Main dataset prep routines.\\n+# -----------------------------------------------------------------------------\\n+def preprocess_data(dataset,\\n+                    shuffle: bool,\\n+                    num_epochs: Optional[int] = 1,\\n+                    pack_examples: bool = True,\\n+                    shuffle_buffer_size: int = 1024,\\n+                    max_length: int = 512,\\n+                    batch_size: int = 256,\\n+                    drop_remainder: bool = True,\\n+                    prefetch_size: int = AUTOTUNE):\\n+  \"\"\"Shuffle and batch/pack the given dataset.\"\"\"\\n+\\n+  def length_filter(max_len):\\n+\\n+    def filter_fn(x):\\n+      source, target = x['inputs'], x['targets']\\n+      l = tf.maximum(tf.shape(source)[0], tf.shape(target)[0])\\n+      return tf.less(l, max_len + 1)\\n+\\n+    return filter_fn\\n+\\n+  if max_length &gt; 0:\\n+    dataset = dataset.filter(length_filter(max_length))\\n+\\n+  if shuffle:\\n+    dataset = dataset.shuffle(shuffle_buffer_size)\\n+  dataset = dataset.repeat(num_epochs)\\n+\\n+  if pack_examples:\\n+    dataset = pack_dataset(dataset, max_length)\\n+    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\\n+  else:  # simple (static-shape) padded batching\\n+    dataset = dataset.padded_batch(\\n+        batch_size,\\n+        padded_shapes={\\n+            'inputs': max_length,\\n+            'targets': max_length\\n+        },\\n+        padding_values={\\n+            'inputs': 0,\\n+            'targets': 0\\n+        },\\n+        drop_remainder=drop_remainder)\\n+\\n+  if prefetch_size:\\n+    dataset = dataset.prefetch(prefetch_size)\\n+\\n+  return dataset\\n+\\n+\\n+def get_datasets(config: ml_collections.ConfigDict,\\n+                 *,\\n+                 n_devices: int,\\n+                 vocab_path: Optional[str] = None):\\n+  \"\"\"Load and return dataset of batched examples for use during training.\"\"\"\\n+  if vocab_path is None:\\n+    vocab_path = os.path.expanduser('~/lm1b_sentencepiece_model')\\n+\\n+  train_ds_builder = tfds.builder(config.dataset_name)\\n+  train_ds_builder.download_and_prepare()\\n+  train_data = get_raw_dataset(train_ds_builder, 'train')\\n+\\n+  if config.eval_dataset_name:\\n+    eval_ds_builder = tfds.builder(config.eval_dataset_name)\\n+  else:\\n+    eval_ds_builder = train_ds_builder\\n+  eval_data = get_raw_dataset(eval_ds_builder, config.eval_split)\\n+\\n+  # Tokenize data.\\n+  sp_tokenizer = tokenizer.load_or_train_tokenizer(\\n+      train_data,\\n+      vocab_path=vocab_path,\\n+      vocab_size=config.vocab_size,\\n+      max_corpus_chars=config.max_corpus_chars)\\n+  train_data = train_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+  eval_data = eval_data.map(\\n+      tokenizer.TokenizeOp(sp_tokenizer), num_parallel_calls=AUTOTUNE)\\n+\\n+  batch_size = config.per_device_batch_size * n_devices\\n+  if config.eval_per_device_batch_size &gt; 0:\\n+    eval_batch_size = config.eval_per_device_batch_size * n_devices\\n+  else:\\n+    eval_batch_size = batch_size\\n+\\n+  train_ds = preprocess_data(\\n+      train_data,\\n+      shuffle=True,\\n+      num_epochs=None,\\n+      pack_examples=True,\\n+      batch_size=batch_size,\\n+      max_length=config.max_target_length)\\n+\\n+  eval_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_eval_target_length)\\n+\\n+  predict_ds = preprocess_data(\\n+      eval_data,\\n+      shuffle=False,\\n+      pack_examples=False,\\n+      batch_size=eval_batch_size,\\n+      max_length=config.max_predict_length,\\n+      drop_remainder=False)\\n+\\n+  return train_ds, eval_ds, predict_ds, sp_tokenizer\\n</td>\n",
              "      <td>source</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba5f82c8-bc04-49da-be75-626ee85f9ca6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba5f82c8-bc04-49da-be75-626ee85f9ca6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba5f82c8-bc04-49da-be75-626ee85f9ca6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-16e38d6c-02fd-48f4-a304-40f7ef7c7e68\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16e38d6c-02fd-48f4-a304-40f7ef7c7e68')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-16e38d6c-02fd-48f4-a304-40f7ef7c7e68 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/elegantrl_diffs.csv\")\n",
        "pd.set_option(\"display.max_colwidth\", None)  # Show full commit messages and diffs\n",
        "display(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RyD3bdstg9LX",
        "outputId": "10bacab9-ea67-4e01-99e9-c14a9103aa89"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   repo_name old_file_path                        new_file_path  \\\n",
              "0  elegantrl           NaN                            README.md   \n",
              "1  elegantrl           NaN                             agent.py   \n",
              "2  elegantrl           NaN                    train_and_eval.py   \n",
              "3  elegantrl           NaN  History/DelayDDPG_origin_version.py   \n",
              "4  elegantrl           NaN                      History/LICENSE   \n",
              "\n",
              "                                 commit_sha  \\\n",
              "0  142cab2ef5e705ea6064b28c32d6b2f7d00f0590   \n",
              "1  6094ed779eead413f7e059bc19e3a0f5ce313468   \n",
              "2  6094ed779eead413f7e059bc19e3a0f5ce313468   \n",
              "3  a3f494dd7cc0d2af234957a92240ae8ea70c6dec   \n",
              "4  a3f494dd7cc0d2af234957a92240ae8ea70c6dec   \n",
              "\n",
              "                          parent_commit_sha  \\\n",
              "0                                       NaN   \n",
              "1  142cab2ef5e705ea6064b28c32d6b2f7d00f0590   \n",
              "2  142cab2ef5e705ea6064b28c32d6b2f7d00f0590   \n",
              "3  6094ed779eead413f7e059bc19e3a0f5ce313468   \n",
              "4  6094ed779eead413f7e059bc19e3a0f5ce313468   \n",
              "\n",
              "                               commit_message  \\\n",
              "0                              Initial commit   \n",
              "1                    DelayDDPG for OpenAI Gym   \n",
              "2                    DelayDDPG for OpenAI Gym   \n",
              "3  LICENSE  Apache 2.0\\n\\nand origin  version   \n",
              "4  LICENSE  Apache 2.0\\n\\nand origin  version   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                diff_myers  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              @@ -0,0 +1,2 @@\\n+# LightWeight_Stable_ReinfLearning\\n+Lightweight, stable, efficient implement of reinforcement learning\\n   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   @@ -0,0 +1,203 @@\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\\n+# import torch.utils.data as data\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir):\\n+        torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+        torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+\\n+        torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+        torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+        print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        print(\"Loading:\", mod_dir)\\n+        self.act.load_state_dict(\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        self.act_target.load_state_dict(\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+        if load_actor_only:\\n+            print(\"load_actor_only!\")\\n+        else:\\n+            self.cri.load_state_dict(\\n+                torch.load('%s/critic.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+            self.cri_target.load_state_dict(\\n+                torch.load('%s/critic_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s >= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         @@ -0,0 +1,359 @@\\n+import os\\n+import sys\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+from agent import Memories\\n+from agent import AgentDelayDDPG\\n+\\n+\"\"\"\\n+beta2\\n+ Epoch (112, 143) TimeUsed: (823, 1200)sec\\n+dropout, break adjust, f_hswish, 2425s(68, 99)!!!!!\\n+beta2: DelayDDPG_stable \\n+explore_noise; policy_noise; TimeUsed; Epoch; \\n+926s E51,1048s E73\\n+dropout 0.50, E92, 1531s, stable\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+dropout 0.50: 1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]  # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward > target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch > max_epoch' or 'epoch_reward > target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num > max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    if 'LunarLanderContinuous-v2':\\n+        env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time > print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward > target_reward and epoch_reward > target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward > target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) < temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) > target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, save_name):\\n+    # np.save('%s/recorders.npy'% mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n   \n",
              "3  @@ -0,0 +1,557 @@\\n+import os\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\"\"\"\\n+GitHub: https://github.com/Yonv1943/LightWeight_Stable_ReinfLearning \\n+Origin: Zen4 Jia1Hao2(Yonv1943), 2019-07-07\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172, 1840s E178\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]      # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward > target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch > max_epoch' or 'epoch_reward > target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num > max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    # if 'LunarLanderContinuous-v2':\\n+    #     env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir, save_actor_only=False):\\n+        if save_actor_only:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            print(\"Saved: (actor_only)\", mod_dir)\\n+        else:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+            torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+            torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+\\n+            torch.save(self.act_optimizer.state_dict(), '%s/actor_optimizer.pth' % (mod_dir,))\\n+            torch.save(self.cri_optimizer.state_dict(), '%s/critic_optimizer.pth' % (mod_dir,))\\n+\\n+            print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        if load_actor_only:\\n+            print(\"Loading: (actor_only)\", mod_dir)\\n+            self.act_target.load_state_dict(\\n+                torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        else:\\n+            def map_location(storage, loc):  # ignore storage location (device id)\\n+                return storage\\n+\\n+            print(\"Loading:\", mod_dir)\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_target.pth' % (mod_dir,), map_location)\\n+\\n+            torch.load('%s/actor_optimizer.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_optimizer.pth' % (mod_dir,), map_location)\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s >= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time > print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward > target_reward and epoch_reward > target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward > target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) < temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) > target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                img_save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, img_save_name):\\n+    np.save('%s/recorders.npy' % mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", img_save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(img_save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, img_save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     @@ -0,0 +1,27 @@\\n+Copyright [2019] [֣Ѻ Zen4 Jia1Hao2 Yonv1943]\\r\\n+\\r\\n+עԴʱֻ򵥵עд Yonv1943 ⼸ԷǳߵַɣҲϸдݴַһGitHub\\r\\n+You simply need to write 'Yonv1943' in the comment, when annotating the source of this code. 'Yonv1943' is special and only few results can be obtained when you search it on the Internet(Before 2019 year). Or you can mark the corresponding website of this code in detail. (Generally GitHub)\\r\\n+\\r\\n+ʵApache License 2.0Դ֤ѡģֻΪ:Ȼʹ˵Ĵ룬ôҪԴдϡ\\r\\n+Actully, I chose Apache License 2.0 as an open source license at random. In my opinion: Since we use other people's code, we need to write the source of the reference.\\r\\n+\\r\\n+\\r\\n+\\r\\n+Yonv1943\\r\\n+About 'Yonv1943'\\r\\n+\\r\\n+Yonv (YonV), YonȡԳաBeYondֶӣYon: YonderǣV (Victory)ȡVơʵһʼҪȡYoY֣·Ѿ̫YoYˣֻȡˣ\\r\\n+1943˼ǹ㶫ͷѧһŰ43ţҵõѧźĲãҿʼķҿʼ֪Ҫʲôˣ߶ʱҵʦѧʦҵ۲ſʼΡ1943һȽҪʱ㣬ֵüͨʱȻ1943Ϊݣô˵޺ܵͣ\\r\\n+\\r\\n+Licensed under the Apache License, Version 2.0 (the \"License\");\\r\\n+you may not use this file except in compliance with the License.\\r\\n+You may obtain a copy of the License at\\r\\n+\\r\\n+    http://www.apache.org/licenses/LICENSE-2.0\\r\\n+\\r\\n+Unless required by applicable law or agreed to in writing, software\\r\\n+distributed under the License is distributed on an \"AS IS\" BASIS,\\r\\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\r\\n+See the License for the specific language governing permissions and\\r\\n+limitations under the License.\\n\\ No newline at end of file\\n   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   diff_hist  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Command '['git', '-C', 'elegantrl', 'diff', '--histogram', '142cab2ef5e705ea6064b28c32d6b2f7d00f0590^', '142cab2ef5e705ea6064b28c32d6b2f7d00f0590', '--', 'README.md']' returned non-zero exit status 128.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    diff --git a/agent.py b/agent.py\\nnew file mode 100644\\nindex 00000000..aafeaab1\\n--- /dev/null\\n+++ b/agent.py\\n@@ -0,0 +1,203 @@\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\\n+# import torch.utils.data as data\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir):\\n+        torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+        torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+\\n+        torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+        torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+        print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        print(\"Loading:\", mod_dir)\\n+        self.act.load_state_dict(\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        self.act_target.load_state_dict(\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+        if load_actor_only:\\n+            print(\"load_actor_only!\")\\n+        else:\\n+            self.cri.load_state_dict(\\n+                torch.load('%s/critic.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+            self.cri_target.load_state_dict(\\n+                torch.load('%s/critic_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s >= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               diff --git a/train_and_eval.py b/train_and_eval.py\\nnew file mode 100644\\nindex 00000000..b6574891\\n--- /dev/null\\n+++ b/train_and_eval.py\\n@@ -0,0 +1,359 @@\\n+import os\\n+import sys\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+from agent import Memories\\n+from agent import AgentDelayDDPG\\n+\\n+\"\"\"\\n+beta2\\n+ Epoch (112, 143) TimeUsed: (823, 1200)sec\\n+dropout, break adjust, f_hswish, 2425s(68, 99)!!!!!\\n+beta2: DelayDDPG_stable \\n+explore_noise; policy_noise; TimeUsed; Epoch; \\n+926s E51,1048s E73\\n+dropout 0.50, E92, 1531s, stable\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+dropout 0.50: 1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]  # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward > target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch > max_epoch' or 'epoch_reward > target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num > max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    if 'LunarLanderContinuous-v2':\\n+        env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time > print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward > target_reward and epoch_reward > target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward > target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) < temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) > target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, save_name):\\n+    # np.save('%s/recorders.npy'% mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n   \n",
              "3  diff --git a/History/DelayDDPG_origin_version.py b/History/DelayDDPG_origin_version.py\\nnew file mode 100644\\nindex 00000000..0dea1702\\n--- /dev/null\\n+++ b/History/DelayDDPG_origin_version.py\\n@@ -0,0 +1,557 @@\\n+import os\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\"\"\"\\n+GitHub: https://github.com/Yonv1943/LightWeight_Stable_ReinfLearning \\n+Origin: Zen4 Jia1Hao2(Yonv1943), 2019-07-07\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172, 1840s E178\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]      # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward > target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch > max_epoch' or 'epoch_reward > target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num > max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    # if 'LunarLanderContinuous-v2':\\n+    #     env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir, save_actor_only=False):\\n+        if save_actor_only:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            print(\"Saved: (actor_only)\", mod_dir)\\n+        else:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+            torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+            torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+\\n+            torch.save(self.act_optimizer.state_dict(), '%s/actor_optimizer.pth' % (mod_dir,))\\n+            torch.save(self.cri_optimizer.state_dict(), '%s/critic_optimizer.pth' % (mod_dir,))\\n+\\n+            print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        if load_actor_only:\\n+            print(\"Loading: (actor_only)\", mod_dir)\\n+            self.act_target.load_state_dict(\\n+                torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        else:\\n+            def map_location(storage, loc):  # ignore storage location (device id)\\n+                return storage\\n+\\n+            print(\"Loading:\", mod_dir)\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_target.pth' % (mod_dir,), map_location)\\n+\\n+            torch.load('%s/actor_optimizer.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_optimizer.pth' % (mod_dir,), map_location)\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s >= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time > print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward > target_reward and epoch_reward > target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward > target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) < temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) > target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                img_save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, img_save_name):\\n+    np.save('%s/recorders.npy' % mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", img_save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(img_save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, img_save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   'utf-8' codec can't decode byte 0xbc in position 167: invalid start byte   \n",
              "\n",
              "  file_type  \n",
              "0    readme  \n",
              "1    source  \n",
              "2    source  \n",
              "3    source  \n",
              "4   license  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d1c178a-a592-4b8c-98de-514d972f4c55\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo_name</th>\n",
              "      <th>old_file_path</th>\n",
              "      <th>new_file_path</th>\n",
              "      <th>commit_sha</th>\n",
              "      <th>parent_commit_sha</th>\n",
              "      <th>commit_message</th>\n",
              "      <th>diff_myers</th>\n",
              "      <th>diff_hist</th>\n",
              "      <th>file_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>elegantrl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>README.md</td>\n",
              "      <td>142cab2ef5e705ea6064b28c32d6b2f7d00f0590</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initial commit</td>\n",
              "      <td>@@ -0,0 +1,2 @@\\n+# LightWeight_Stable_ReinfLearning\\n+Lightweight, stable, efficient implement of reinforcement learning\\n</td>\n",
              "      <td>Command '['git', '-C', 'elegantrl', 'diff', '--histogram', '142cab2ef5e705ea6064b28c32d6b2f7d00f0590^', '142cab2ef5e705ea6064b28c32d6b2f7d00f0590', '--', 'README.md']' returned non-zero exit status 128.</td>\n",
              "      <td>readme</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>elegantrl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>agent.py</td>\n",
              "      <td>6094ed779eead413f7e059bc19e3a0f5ce313468</td>\n",
              "      <td>142cab2ef5e705ea6064b28c32d6b2f7d00f0590</td>\n",
              "      <td>DelayDDPG for OpenAI Gym</td>\n",
              "      <td>@@ -0,0 +1,203 @@\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\\n+# import torch.utils.data as data\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir):\\n+        torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+        torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+\\n+        torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+        torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+        print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        print(\"Loading:\", mod_dir)\\n+        self.act.load_state_dict(\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        self.act_target.load_state_dict(\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+        if load_actor_only:\\n+            print(\"load_actor_only!\")\\n+        else:\\n+            self.cri.load_state_dict(\\n+                torch.load('%s/critic.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+            self.cri_target.load_state_dict(\\n+                torch.load('%s/critic_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s &gt;= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n</td>\n",
              "      <td>diff --git a/agent.py b/agent.py\\nnew file mode 100644\\nindex 00000000..aafeaab1\\n--- /dev/null\\n+++ b/agent.py\\n@@ -0,0 +1,203 @@\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\\n+# import torch.utils.data as data\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir):\\n+        torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+        torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+\\n+        torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+        torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+        print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        print(\"Loading:\", mod_dir)\\n+        self.act.load_state_dict(\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        self.act_target.load_state_dict(\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+        if load_actor_only:\\n+            print(\"load_actor_only!\")\\n+        else:\\n+            self.cri.load_state_dict(\\n+                torch.load('%s/critic.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+            self.cri_target.load_state_dict(\\n+                torch.load('%s/critic_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s &gt;= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>elegantrl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>train_and_eval.py</td>\n",
              "      <td>6094ed779eead413f7e059bc19e3a0f5ce313468</td>\n",
              "      <td>142cab2ef5e705ea6064b28c32d6b2f7d00f0590</td>\n",
              "      <td>DelayDDPG for OpenAI Gym</td>\n",
              "      <td>@@ -0,0 +1,359 @@\\n+import os\\n+import sys\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+from agent import Memories\\n+from agent import AgentDelayDDPG\\n+\\n+\"\"\"\\n+beta2\\n+ Epoch (112, 143) TimeUsed: (823, 1200)sec\\n+dropout, break adjust, f_hswish, 2425s(68, 99)!!!!!\\n+beta2: DelayDDPG_stable \\n+explore_noise; policy_noise; TimeUsed; Epoch; \\n+926s E51,1048s E73\\n+dropout 0.50, E92, 1531s, stable\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+dropout 0.50: 1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]  # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward &gt; target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch &gt; max_epoch' or 'epoch_reward &gt; target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num &gt; max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    if 'LunarLanderContinuous-v2':\\n+        env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time &gt; print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward &gt; target_reward and epoch_reward &gt; target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward &gt; target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) &lt; temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) &gt; target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, save_name):\\n+    # np.save('%s/recorders.npy'% mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n</td>\n",
              "      <td>diff --git a/train_and_eval.py b/train_and_eval.py\\nnew file mode 100644\\nindex 00000000..b6574891\\n--- /dev/null\\n+++ b/train_and_eval.py\\n@@ -0,0 +1,359 @@\\n+import os\\n+import sys\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+from agent import Memories\\n+from agent import AgentDelayDDPG\\n+\\n+\"\"\"\\n+beta2\\n+ Epoch (112, 143) TimeUsed: (823, 1200)sec\\n+dropout, break adjust, f_hswish, 2425s(68, 99)!!!!!\\n+beta2: DelayDDPG_stable \\n+explore_noise; policy_noise; TimeUsed; Epoch; \\n+926s E51,1048s E73\\n+dropout 0.50, E92, 1531s, stable\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+dropout 0.50: 1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]  # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward &gt; target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch &gt; max_epoch' or 'epoch_reward &gt; target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num &gt; max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    if 'LunarLanderContinuous-v2':\\n+        env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time &gt; print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward &gt; target_reward and epoch_reward &gt; target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward &gt; target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) &lt; temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) &gt; target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, save_name):\\n+    # np.save('%s/recorders.npy'% mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>elegantrl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History/DelayDDPG_origin_version.py</td>\n",
              "      <td>a3f494dd7cc0d2af234957a92240ae8ea70c6dec</td>\n",
              "      <td>6094ed779eead413f7e059bc19e3a0f5ce313468</td>\n",
              "      <td>LICENSE  Apache 2.0\\n\\nand origin  version</td>\n",
              "      <td>@@ -0,0 +1,557 @@\\n+import os\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\"\"\"\\n+GitHub: https://github.com/Yonv1943/LightWeight_Stable_ReinfLearning \\n+Origin: Zen4 Jia1Hao2(Yonv1943), 2019-07-07\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172, 1840s E178\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]      # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward &gt; target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch &gt; max_epoch' or 'epoch_reward &gt; target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num &gt; max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    # if 'LunarLanderContinuous-v2':\\n+    #     env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir, save_actor_only=False):\\n+        if save_actor_only:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            print(\"Saved: (actor_only)\", mod_dir)\\n+        else:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+            torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+            torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+\\n+            torch.save(self.act_optimizer.state_dict(), '%s/actor_optimizer.pth' % (mod_dir,))\\n+            torch.save(self.cri_optimizer.state_dict(), '%s/critic_optimizer.pth' % (mod_dir,))\\n+\\n+            print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        if load_actor_only:\\n+            print(\"Loading: (actor_only)\", mod_dir)\\n+            self.act_target.load_state_dict(\\n+                torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        else:\\n+            def map_location(storage, loc):  # ignore storage location (device id)\\n+                return storage\\n+\\n+            print(\"Loading:\", mod_dir)\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_target.pth' % (mod_dir,), map_location)\\n+\\n+            torch.load('%s/actor_optimizer.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_optimizer.pth' % (mod_dir,), map_location)\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s &gt;= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time &gt; print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward &gt; target_reward and epoch_reward &gt; target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward &gt; target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) &lt; temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) &gt; target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                img_save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, img_save_name):\\n+    np.save('%s/recorders.npy' % mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", img_save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(img_save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, img_save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n</td>\n",
              "      <td>diff --git a/History/DelayDDPG_origin_version.py b/History/DelayDDPG_origin_version.py\\nnew file mode 100644\\nindex 00000000..0dea1702\\n--- /dev/null\\n+++ b/History/DelayDDPG_origin_version.py\\n@@ -0,0 +1,557 @@\\n+import os\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\"\"\"\\n+GitHub: https://github.com/Yonv1943/LightWeight_Stable_ReinfLearning \\n+Origin: Zen4 Jia1Hao2(Yonv1943), 2019-07-07\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172, 1840s E178\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]      # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward &gt; target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch &gt; max_epoch' or 'epoch_reward &gt; target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num &gt; max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    # if 'LunarLanderContinuous-v2':\\n+    #     env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir, save_actor_only=False):\\n+        if save_actor_only:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            print(\"Saved: (actor_only)\", mod_dir)\\n+        else:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+            torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+            torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+\\n+            torch.save(self.act_optimizer.state_dict(), '%s/actor_optimizer.pth' % (mod_dir,))\\n+            torch.save(self.cri_optimizer.state_dict(), '%s/critic_optimizer.pth' % (mod_dir,))\\n+\\n+            print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        if load_actor_only:\\n+            print(\"Loading: (actor_only)\", mod_dir)\\n+            self.act_target.load_state_dict(\\n+                torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        else:\\n+            def map_location(storage, loc):  # ignore storage location (device id)\\n+                return storage\\n+\\n+            print(\"Loading:\", mod_dir)\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_target.pth' % (mod_dir,), map_location)\\n+\\n+            torch.load('%s/actor_optimizer.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_optimizer.pth' % (mod_dir,), map_location)\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s &gt;= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time &gt; print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward &gt; target_reward and epoch_reward &gt; target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward &gt; target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) &lt; temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) &gt; target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                img_save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, img_save_name):\\n+    np.save('%s/recorders.npy' % mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", img_save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(img_save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, img_save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>elegantrl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History/LICENSE</td>\n",
              "      <td>a3f494dd7cc0d2af234957a92240ae8ea70c6dec</td>\n",
              "      <td>6094ed779eead413f7e059bc19e3a0f5ce313468</td>\n",
              "      <td>LICENSE  Apache 2.0\\n\\nand origin  version</td>\n",
              "      <td>@@ -0,0 +1,27 @@\\n+Copyright [2019] [֣Ѻ Zen4 Jia1Hao2 Yonv1943]\\r\\n+\\r\\n+עԴʱֻ򵥵עд Yonv1943 ⼸ԷǳߵַɣҲϸдݴַһGitHub\\r\\n+You simply need to write 'Yonv1943' in the comment, when annotating the source of this code. 'Yonv1943' is special and only few results can be obtained when you search it on the Internet(Before 2019 year). Or you can mark the corresponding website of this code in detail. (Generally GitHub)\\r\\n+\\r\\n+ʵApache License 2.0Դ֤ѡģֻΪ:Ȼʹ˵Ĵ룬ôҪԴдϡ\\r\\n+Actully, I chose Apache License 2.0 as an open source license at random. In my opinion: Since we use other people's code, we need to write the source of the reference.\\r\\n+\\r\\n+\\r\\n+\\r\\n+Yonv1943\\r\\n+About 'Yonv1943'\\r\\n+\\r\\n+Yonv (YonV), YonȡԳաBeYondֶӣYon: YonderǣV (Victory)ȡVơʵһʼҪȡYoY֣·Ѿ̫YoYˣֻȡˣ\\r\\n+1943˼ǹ㶫ͷѧһŰ43ţҵõѧźĲãҿʼķҿʼ֪Ҫʲôˣ߶ʱҵʦѧʦҵ۲ſʼΡ1943һȽҪʱ㣬ֵüͨʱȻ1943Ϊݣô˵޺ܵͣ\\r\\n+\\r\\n+Licensed under the Apache License, Version 2.0 (the \"License\");\\r\\n+you may not use this file except in compliance with the License.\\r\\n+You may obtain a copy of the License at\\r\\n+\\r\\n+    http://www.apache.org/licenses/LICENSE-2.0\\r\\n+\\r\\n+Unless required by applicable law or agreed to in writing, software\\r\\n+distributed under the License is distributed on an \"AS IS\" BASIS,\\r\\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\r\\n+See the License for the specific language governing permissions and\\r\\n+limitations under the License.\\n\\ No newline at end of file\\n</td>\n",
              "      <td>'utf-8' codec can't decode byte 0xbc in position 167: invalid start byte</td>\n",
              "      <td>license</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d1c178a-a592-4b8c-98de-514d972f4c55')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d1c178a-a592-4b8c-98de-514d972f4c55 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d1c178a-a592-4b8c-98de-514d972f4c55');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-83deb44b-b169-49b4-92b2-7f8d81f14b0b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83deb44b-b169-49b4-92b2-7f8d81f14b0b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-83deb44b-b169-49b4-92b2-7f8d81f14b0b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/elegantrl_final.csv\")\n",
        "pd.set_option(\"display.max_colwidth\", None)  # Show full commit messages and diffs\n",
        "display(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RTRihXNHg9Pd",
        "outputId": "dfd72ecd-75e6-4033-84c5-d522f88b0fb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   repo_name old_file_path                        new_file_path  \\\n",
              "0  elegantrl           NaN                            README.md   \n",
              "1  elegantrl           NaN                             agent.py   \n",
              "2  elegantrl           NaN                    train_and_eval.py   \n",
              "3  elegantrl           NaN  History/DelayDDPG_origin_version.py   \n",
              "4  elegantrl           NaN                      History/LICENSE   \n",
              "\n",
              "                                 commit_sha  \\\n",
              "0  142cab2ef5e705ea6064b28c32d6b2f7d00f0590   \n",
              "1  6094ed779eead413f7e059bc19e3a0f5ce313468   \n",
              "2  6094ed779eead413f7e059bc19e3a0f5ce313468   \n",
              "3  a3f494dd7cc0d2af234957a92240ae8ea70c6dec   \n",
              "4  a3f494dd7cc0d2af234957a92240ae8ea70c6dec   \n",
              "\n",
              "                          parent_commit_sha  \\\n",
              "0                                       NaN   \n",
              "1  142cab2ef5e705ea6064b28c32d6b2f7d00f0590   \n",
              "2  142cab2ef5e705ea6064b28c32d6b2f7d00f0590   \n",
              "3  6094ed779eead413f7e059bc19e3a0f5ce313468   \n",
              "4  6094ed779eead413f7e059bc19e3a0f5ce313468   \n",
              "\n",
              "                               commit_message  \\\n",
              "0                              Initial commit   \n",
              "1                    DelayDDPG for OpenAI Gym   \n",
              "2                    DelayDDPG for OpenAI Gym   \n",
              "3  LICENSE  Apache 2.0\\n\\nand origin  version   \n",
              "4  LICENSE  Apache 2.0\\n\\nand origin  version   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                diff_myers  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              @@ -0,0 +1,2 @@\\n+# LightWeight_Stable_ReinfLearning\\n+Lightweight, stable, efficient implement of reinforcement learning\\n   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   @@ -0,0 +1,203 @@\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\\n+# import torch.utils.data as data\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir):\\n+        torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+        torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+\\n+        torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+        torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+        print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        print(\"Loading:\", mod_dir)\\n+        self.act.load_state_dict(\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        self.act_target.load_state_dict(\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+        if load_actor_only:\\n+            print(\"load_actor_only!\")\\n+        else:\\n+            self.cri.load_state_dict(\\n+                torch.load('%s/critic.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+            self.cri_target.load_state_dict(\\n+                torch.load('%s/critic_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s >= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         @@ -0,0 +1,359 @@\\n+import os\\n+import sys\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+from agent import Memories\\n+from agent import AgentDelayDDPG\\n+\\n+\"\"\"\\n+beta2\\n+ Epoch (112, 143) TimeUsed: (823, 1200)sec\\n+dropout, break adjust, f_hswish, 2425s(68, 99)!!!!!\\n+beta2: DelayDDPG_stable \\n+explore_noise; policy_noise; TimeUsed; Epoch; \\n+926s E51,1048s E73\\n+dropout 0.50, E92, 1531s, stable\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+dropout 0.50: 1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]  # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward > target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch > max_epoch' or 'epoch_reward > target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num > max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    if 'LunarLanderContinuous-v2':\\n+        env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time > print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward > target_reward and epoch_reward > target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward > target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) < temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) > target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, save_name):\\n+    # np.save('%s/recorders.npy'% mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n   \n",
              "3  @@ -0,0 +1,557 @@\\n+import os\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\"\"\"\\n+GitHub: https://github.com/Yonv1943/LightWeight_Stable_ReinfLearning \\n+Origin: Zen4 Jia1Hao2(Yonv1943), 2019-07-07\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172, 1840s E178\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]      # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward > target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch > max_epoch' or 'epoch_reward > target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num > max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    # if 'LunarLanderContinuous-v2':\\n+    #     env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir, save_actor_only=False):\\n+        if save_actor_only:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            print(\"Saved: (actor_only)\", mod_dir)\\n+        else:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+            torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+            torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+\\n+            torch.save(self.act_optimizer.state_dict(), '%s/actor_optimizer.pth' % (mod_dir,))\\n+            torch.save(self.cri_optimizer.state_dict(), '%s/critic_optimizer.pth' % (mod_dir,))\\n+\\n+            print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        if load_actor_only:\\n+            print(\"Loading: (actor_only)\", mod_dir)\\n+            self.act_target.load_state_dict(\\n+                torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        else:\\n+            def map_location(storage, loc):  # ignore storage location (device id)\\n+                return storage\\n+\\n+            print(\"Loading:\", mod_dir)\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_target.pth' % (mod_dir,), map_location)\\n+\\n+            torch.load('%s/actor_optimizer.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_optimizer.pth' % (mod_dir,), map_location)\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s >= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time > print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward > target_reward and epoch_reward > target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward > target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) < temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) > target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                img_save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, img_save_name):\\n+    np.save('%s/recorders.npy' % mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", img_save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(img_save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, img_save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     @@ -0,0 +1,27 @@\\n+Copyright [2019] [֣Ѻ Zen4 Jia1Hao2 Yonv1943]\\r\\n+\\r\\n+עԴʱֻ򵥵עд Yonv1943 ⼸ԷǳߵַɣҲϸдݴַһGitHub\\r\\n+You simply need to write 'Yonv1943' in the comment, when annotating the source of this code. 'Yonv1943' is special and only few results can be obtained when you search it on the Internet(Before 2019 year). Or you can mark the corresponding website of this code in detail. (Generally GitHub)\\r\\n+\\r\\n+ʵApache License 2.0Դ֤ѡģֻΪ:Ȼʹ˵Ĵ룬ôҪԴдϡ\\r\\n+Actully, I chose Apache License 2.0 as an open source license at random. In my opinion: Since we use other people's code, we need to write the source of the reference.\\r\\n+\\r\\n+\\r\\n+\\r\\n+Yonv1943\\r\\n+About 'Yonv1943'\\r\\n+\\r\\n+Yonv (YonV), YonȡԳաBeYondֶӣYon: YonderǣV (Victory)ȡVơʵһʼҪȡYoY֣·Ѿ̫YoYˣֻȡˣ\\r\\n+1943˼ǹ㶫ͷѧһŰ43ţҵõѧźĲãҿʼķҿʼ֪Ҫʲôˣ߶ʱҵʦѧʦҵ۲ſʼΡ1943һȽҪʱ㣬ֵüͨʱȻ1943Ϊݣô˵޺ܵͣ\\r\\n+\\r\\n+Licensed under the Apache License, Version 2.0 (the \"License\");\\r\\n+you may not use this file except in compliance with the License.\\r\\n+You may obtain a copy of the License at\\r\\n+\\r\\n+    http://www.apache.org/licenses/LICENSE-2.0\\r\\n+\\r\\n+Unless required by applicable law or agreed to in writing, software\\r\\n+distributed under the License is distributed on an \"AS IS\" BASIS,\\r\\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\r\\n+See the License for the specific language governing permissions and\\r\\n+limitations under the License.\\n\\ No newline at end of file\\n   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   diff_hist  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Command '['git', '-C', 'elegantrl', 'diff', '--histogram', '142cab2ef5e705ea6064b28c32d6b2f7d00f0590^', '142cab2ef5e705ea6064b28c32d6b2f7d00f0590', '--', 'README.md']' returned non-zero exit status 128.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    diff --git a/agent.py b/agent.py\\nnew file mode 100644\\nindex 00000000..aafeaab1\\n--- /dev/null\\n+++ b/agent.py\\n@@ -0,0 +1,203 @@\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\\n+# import torch.utils.data as data\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir):\\n+        torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+        torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+\\n+        torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+        torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+        print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        print(\"Loading:\", mod_dir)\\n+        self.act.load_state_dict(\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        self.act_target.load_state_dict(\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+        if load_actor_only:\\n+            print(\"load_actor_only!\")\\n+        else:\\n+            self.cri.load_state_dict(\\n+                torch.load('%s/critic.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+            self.cri_target.load_state_dict(\\n+                torch.load('%s/critic_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s >= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               diff --git a/train_and_eval.py b/train_and_eval.py\\nnew file mode 100644\\nindex 00000000..b6574891\\n--- /dev/null\\n+++ b/train_and_eval.py\\n@@ -0,0 +1,359 @@\\n+import os\\n+import sys\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+from agent import Memories\\n+from agent import AgentDelayDDPG\\n+\\n+\"\"\"\\n+beta2\\n+ Epoch (112, 143) TimeUsed: (823, 1200)sec\\n+dropout, break adjust, f_hswish, 2425s(68, 99)!!!!!\\n+beta2: DelayDDPG_stable \\n+explore_noise; policy_noise; TimeUsed; Epoch; \\n+926s E51,1048s E73\\n+dropout 0.50, E92, 1531s, stable\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+dropout 0.50: 1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]  # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward > target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch > max_epoch' or 'epoch_reward > target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num > max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    if 'LunarLanderContinuous-v2':\\n+        env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time > print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward > target_reward and epoch_reward > target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward > target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) < temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) > target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, save_name):\\n+    # np.save('%s/recorders.npy'% mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n   \n",
              "3  diff --git a/History/DelayDDPG_origin_version.py b/History/DelayDDPG_origin_version.py\\nnew file mode 100644\\nindex 00000000..0dea1702\\n--- /dev/null\\n+++ b/History/DelayDDPG_origin_version.py\\n@@ -0,0 +1,557 @@\\n+import os\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\"\"\"\\n+GitHub: https://github.com/Yonv1943/LightWeight_Stable_ReinfLearning \\n+Origin: Zen4 Jia1Hao2(Yonv1943), 2019-07-07\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172, 1840s E178\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]      # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward > target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch > max_epoch' or 'epoch_reward > target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num > max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    # if 'LunarLanderContinuous-v2':\\n+    #     env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir, save_actor_only=False):\\n+        if save_actor_only:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            print(\"Saved: (actor_only)\", mod_dir)\\n+        else:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+            torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+            torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+\\n+            torch.save(self.act_optimizer.state_dict(), '%s/actor_optimizer.pth' % (mod_dir,))\\n+            torch.save(self.cri_optimizer.state_dict(), '%s/critic_optimizer.pth' % (mod_dir,))\\n+\\n+            print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        if load_actor_only:\\n+            print(\"Loading: (actor_only)\", mod_dir)\\n+            self.act_target.load_state_dict(\\n+                torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        else:\\n+            def map_location(storage, loc):  # ignore storage location (device id)\\n+                return storage\\n+\\n+            print(\"Loading:\", mod_dir)\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_target.pth' % (mod_dir,), map_location)\\n+\\n+            torch.load('%s/actor_optimizer.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_optimizer.pth' % (mod_dir,), map_location)\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s >= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time > print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward > target_reward and epoch_reward > target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward > target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) < temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) > target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                img_save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, img_save_name):\\n+    np.save('%s/recorders.npy' % mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", img_save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(img_save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, img_save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   'utf-8' codec can't decode byte 0xbc in position 167: invalid start byte   \n",
              "\n",
              "  file_type Discrepancy  \n",
              "0    readme         Yes  \n",
              "1    source         Yes  \n",
              "2    source         Yes  \n",
              "3    source         Yes  \n",
              "4   license         Yes  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-438d9432-c6ed-44ac-a20d-4740f4858654\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo_name</th>\n",
              "      <th>old_file_path</th>\n",
              "      <th>new_file_path</th>\n",
              "      <th>commit_sha</th>\n",
              "      <th>parent_commit_sha</th>\n",
              "      <th>commit_message</th>\n",
              "      <th>diff_myers</th>\n",
              "      <th>diff_hist</th>\n",
              "      <th>file_type</th>\n",
              "      <th>Discrepancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>elegantrl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>README.md</td>\n",
              "      <td>142cab2ef5e705ea6064b28c32d6b2f7d00f0590</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initial commit</td>\n",
              "      <td>@@ -0,0 +1,2 @@\\n+# LightWeight_Stable_ReinfLearning\\n+Lightweight, stable, efficient implement of reinforcement learning\\n</td>\n",
              "      <td>Command '['git', '-C', 'elegantrl', 'diff', '--histogram', '142cab2ef5e705ea6064b28c32d6b2f7d00f0590^', '142cab2ef5e705ea6064b28c32d6b2f7d00f0590', '--', 'README.md']' returned non-zero exit status 128.</td>\n",
              "      <td>readme</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>elegantrl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>agent.py</td>\n",
              "      <td>6094ed779eead413f7e059bc19e3a0f5ce313468</td>\n",
              "      <td>142cab2ef5e705ea6064b28c32d6b2f7d00f0590</td>\n",
              "      <td>DelayDDPG for OpenAI Gym</td>\n",
              "      <td>@@ -0,0 +1,203 @@\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\\n+# import torch.utils.data as data\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir):\\n+        torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+        torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+\\n+        torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+        torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+        print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        print(\"Loading:\", mod_dir)\\n+        self.act.load_state_dict(\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        self.act_target.load_state_dict(\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+        if load_actor_only:\\n+            print(\"load_actor_only!\")\\n+        else:\\n+            self.cri.load_state_dict(\\n+                torch.load('%s/critic.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+            self.cri_target.load_state_dict(\\n+                torch.load('%s/critic_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s &gt;= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n</td>\n",
              "      <td>diff --git a/agent.py b/agent.py\\nnew file mode 100644\\nindex 00000000..aafeaab1\\n--- /dev/null\\n+++ b/agent.py\\n@@ -0,0 +1,203 @@\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\\n+# import torch.utils.data as data\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir):\\n+        torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+        torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+\\n+        torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+        torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+        print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        print(\"Loading:\", mod_dir)\\n+        self.act.load_state_dict(\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        self.act_target.load_state_dict(\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+        if load_actor_only:\\n+            print(\"load_actor_only!\")\\n+        else:\\n+            self.cri.load_state_dict(\\n+                torch.load('%s/critic.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+            self.cri_target.load_state_dict(\\n+                torch.load('%s/critic_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s &gt;= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n</td>\n",
              "      <td>source</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>elegantrl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>train_and_eval.py</td>\n",
              "      <td>6094ed779eead413f7e059bc19e3a0f5ce313468</td>\n",
              "      <td>142cab2ef5e705ea6064b28c32d6b2f7d00f0590</td>\n",
              "      <td>DelayDDPG for OpenAI Gym</td>\n",
              "      <td>@@ -0,0 +1,359 @@\\n+import os\\n+import sys\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+from agent import Memories\\n+from agent import AgentDelayDDPG\\n+\\n+\"\"\"\\n+beta2\\n+ Epoch (112, 143) TimeUsed: (823, 1200)sec\\n+dropout, break adjust, f_hswish, 2425s(68, 99)!!!!!\\n+beta2: DelayDDPG_stable \\n+explore_noise; policy_noise; TimeUsed; Epoch; \\n+926s E51,1048s E73\\n+dropout 0.50, E92, 1531s, stable\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+dropout 0.50: 1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]  # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward &gt; target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch &gt; max_epoch' or 'epoch_reward &gt; target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num &gt; max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    if 'LunarLanderContinuous-v2':\\n+        env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time &gt; print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward &gt; target_reward and epoch_reward &gt; target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward &gt; target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) &lt; temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) &gt; target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, save_name):\\n+    # np.save('%s/recorders.npy'% mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n</td>\n",
              "      <td>diff --git a/train_and_eval.py b/train_and_eval.py\\nnew file mode 100644\\nindex 00000000..b6574891\\n--- /dev/null\\n+++ b/train_and_eval.py\\n@@ -0,0 +1,359 @@\\n+import os\\n+import sys\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+from agent import Memories\\n+from agent import AgentDelayDDPG\\n+\\n+\"\"\"\\n+beta2\\n+ Epoch (112, 143) TimeUsed: (823, 1200)sec\\n+dropout, break adjust, f_hswish, 2425s(68, 99)!!!!!\\n+beta2: DelayDDPG_stable \\n+explore_noise; policy_noise; TimeUsed; Epoch; \\n+926s E51,1048s E73\\n+dropout 0.50, E92, 1531s, stable\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+dropout 0.50: 1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]  # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward &gt; target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch &gt; max_epoch' or 'epoch_reward &gt; target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num &gt; max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    if 'LunarLanderContinuous-v2':\\n+        env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time &gt; print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward &gt; target_reward and epoch_reward &gt; target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward &gt; target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) &lt; temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) &gt; target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, save_name):\\n+    # np.save('%s/recorders.npy'% mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n</td>\n",
              "      <td>source</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>elegantrl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History/DelayDDPG_origin_version.py</td>\n",
              "      <td>a3f494dd7cc0d2af234957a92240ae8ea70c6dec</td>\n",
              "      <td>6094ed779eead413f7e059bc19e3a0f5ce313468</td>\n",
              "      <td>LICENSE  Apache 2.0\\n\\nand origin  version</td>\n",
              "      <td>@@ -0,0 +1,557 @@\\n+import os\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\"\"\"\\n+GitHub: https://github.com/Yonv1943/LightWeight_Stable_ReinfLearning \\n+Origin: Zen4 Jia1Hao2(Yonv1943), 2019-07-07\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172, 1840s E178\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]      # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward &gt; target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch &gt; max_epoch' or 'epoch_reward &gt; target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num &gt; max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    # if 'LunarLanderContinuous-v2':\\n+    #     env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir, save_actor_only=False):\\n+        if save_actor_only:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            print(\"Saved: (actor_only)\", mod_dir)\\n+        else:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+            torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+            torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+\\n+            torch.save(self.act_optimizer.state_dict(), '%s/actor_optimizer.pth' % (mod_dir,))\\n+            torch.save(self.cri_optimizer.state_dict(), '%s/critic_optimizer.pth' % (mod_dir,))\\n+\\n+            print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        if load_actor_only:\\n+            print(\"Loading: (actor_only)\", mod_dir)\\n+            self.act_target.load_state_dict(\\n+                torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        else:\\n+            def map_location(storage, loc):  # ignore storage location (device id)\\n+                return storage\\n+\\n+            print(\"Loading:\", mod_dir)\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_target.pth' % (mod_dir,), map_location)\\n+\\n+            torch.load('%s/actor_optimizer.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_optimizer.pth' % (mod_dir,), map_location)\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s &gt;= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time &gt; print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward &gt; target_reward and epoch_reward &gt; target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward &gt; target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) &lt; temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) &gt; target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                img_save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, img_save_name):\\n+    np.save('%s/recorders.npy' % mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", img_save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(img_save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, img_save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n</td>\n",
              "      <td>diff --git a/History/DelayDDPG_origin_version.py b/History/DelayDDPG_origin_version.py\\nnew file mode 100644\\nindex 00000000..0dea1702\\n--- /dev/null\\n+++ b/History/DelayDDPG_origin_version.py\\n@@ -0,0 +1,557 @@\\n+import os\\n+from time import time as timer\\n+\\n+import gym\\n+import numpy as np\\n+import numpy.random as rd\\n+\\n+import torch\\n+import torch.nn as nn\\n+import torch.nn.functional as F\\n+\\n+\"\"\"\\n+GitHub: https://github.com/Yonv1943/LightWeight_Stable_ReinfLearning \\n+Origin: Zen4 Jia1Hao2(Yonv1943), 2019-07-07\\n+\\n+LunarLanderContinuous-v2\\n+1531s E92, 1455s E97\\n+\\n+LunarLander-v2 (Discrete)\\n+1530s E147, 3036s E277, \\n+\\n+BipedalWalker-v2\\n+1620s E172, 1840s E178\\n+\"\"\"\\n+\\n+\\n+class Arguments:\\n+    \"\"\"\\n+    All the hyper-parameter is here.\\n+\\n+    If you are not familiar with this algorithm,\\n+    then I do not recommend that you modify other parameters that are not listed here.\\n+    The comments below are all my subjective guesses for reference only!\\n+\\n+    If you wanna change this code, please keep READABILITY and ELEGANT! (read 'import this')\\n+    Write by GitHub: Yonv1943 Zen4 Jia1Hao2, 2019-07-07\\n+    \"\"\"\\n+\\n+    '''device'''\\n+    gpu_id = 1  # sys.argv[0][-4]      # ! !!!!!!!!! !!!! !!!\\n+    mod_dir = 'DelayDDPG_%s' % gpu_id  # ! !!!!!!!!! !!!! !!!\\n+    env_name = \"LunarLanderContinuous-v2\"\\n+    is_remove = True  # remove the pre-training data?\\n+    # is_remove = True,  yes, remove the directory of model\\n+    # is_remove = None,  ask me when the program is running\\n+    # is_remove = False, keep the pre-training data and load it when necessary\\n+    random_seed = 1943  # random_seed for py_torch and gym.env\\n+\\n+    '''training'''\\n+    mod_dim = 2 ** 8  # the network width of actor_net and critic_net\\n+    # low mod_dim should correspond to low dropout_rate\\n+    memories_size = int(2 ** 18)  # memories capacity (memories: replay buffer)\\n+    # low memories capacity leads to low reward in the later stage of training.\\n+    batch_size = 2 ** 8  # num of transitions sampled from replay buffer.\\n+    # big batch_size makes training more stable.\\n+    update_gap = 2 ** 8  # update the target_net, delay update\\n+    # big update_gap will lengthen the training time, but get a better policy network\\n+    eval_epoch = 2 ** 2  # eval this model after training. and render the env\\n+\\n+    '''break'''\\n+    target_reward = 200  # when 'epoch_reward &gt; target_reward', break the training loop\\n+    # \"LunarLanderContinuous-v2\" Recommended range(100, 200)\\n+    smooth_kernel = 16  # smooth the reward curve\\n+    # big smooth_kernel makes the curve more smooth. Recommended range(16, 64)\\n+    print_gap = 2 ** 5  # print the Reward, actor_loss, critic_loss\\n+    # print the information every 'print_gap'sec\\n+    max_epoch = 1000  # max num of train_epoch\\n+    # if 'epoch &gt; max_epoch' or 'epoch_reward &gt; target_reward', break the training loop\\n+    max_step = 2000  # max steps in one epoch\\n+    # if 'iter_num &gt; max_step' or 'done', break. Then reset the env and start a new round of training\\n+\\n+    '''algorithm'''\\n+    gamma = 0.99  # discount for future rewards\\n+    # big gamma leads to a long-term strategy\\n+    explore_noise = 0.4  # action = select_action(state) + noise, 'explore_noise': sigma of noise\\n+    # big explore_noise is suitable when the fault tolerant rate of ENV is high.\\n+    # low explore_noise delays the time when the model reaches high reward\\n+    policy_noise = 0.8  # actor_target(next_state) + noise,  'policy_noise': sigma of noise\\n+    # low policy_noise lead to a stable training, but a longer learning period and clumsy movements\\n+    # Epsilon-Greedy, the variance of noise don not decay here.\\n+    # 'explore_noise' and 'explore_noise' act on 'action' (in range(-1, 1)), before 'action*action_max'\\n+\\n+    # if 'LunarLanderContinuous-v2':\\n+    #     env_name = \"LunarLanderContinuous-v2\"\\n+    # if 'Pendulum-v0':\\n+    #     env_name = \"Pendulum-v0\"\\n+    #     max_step = 200\\n+    # if \"BipedalWalker-v2\":\\n+    #     env_name = \"BipedalWalker-v2\"\\n+    #     target_reward = 100  # 300\\n+    # if \"BipedalWalkerHardcore-v2\":\\n+    #     env_name = \"BipedalWalkerHardcore-v2\"\\n+    #     target_reward = 200  # 300\\n+    #     mod_dim = 2 ** 9  # the network width of actor_net and critic_net\\n+    #     memories_size = int(2 ** 19)  # memories capacity (memories: replay buffer)\\n+    #     max_step = 8000  # max steps in one epoch\\n+    #     is_remove = None  # remove the pre-training data?\\n+\\n+    # \"\"\"Discrete_Action\"\"\"\\n+    # if 'LunarLander-v2':\\n+    #     env_name = \"LunarLander-v2\"\\n+    # if 'CartPole-v0':\\n+    #     env_name = \"CartPole-v0\"\\n+    #     target_reward = 195\\n+    #     print_gap = 2 ** 2\\n+    #     explore_noise = 0.1\\n+    #     policy_noise = 0.8\\n+    #     memories_size = 2 ** 16\\n+    #     batch_size = 2 ** 7\\n+    #     mod_dim = 2 ** 7\\n+\\n+\\n+def f_hard_swish(x):\\n+    return F.relu6(x + 3) / 6 * x\\n+\\n+\\n+class Actor(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Actor, self).__init__()\\n+        inp_dim = state_dim\\n+        out_dim = action_dim\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim * 1)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, x0):\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = torch.tanh(self.dense3(x3))\\n+        return x4\\n+\\n+\\n+class Critic(nn.Module):\\n+    def __init__(self, state_dim, action_dim, mod_dim):\\n+        super(Critic, self).__init__()\\n+        inp_dim = state_dim + action_dim\\n+        out_dim = 1\\n+        self.dense0 = nn.Linear(inp_dim, mod_dim * 1)\\n+        self.dense1 = nn.Linear(mod_dim * 1, mod_dim)\\n+        self.dense2 = nn.Linear(mod_dim * 2, mod_dim * 2)\\n+        self.dense3 = nn.Linear(mod_dim * 4, out_dim)\\n+\\n+    def forward(self, s, a):\\n+        x0 = torch.cat((s, a), dim=1)\\n+        x1 = f_hard_swish(self.dense0(x0))\\n+        x2 = torch.cat((x1, f_hard_swish(self.dense1(x1))), dim=1)\\n+        x3 = torch.cat((x2, f_hard_swish(self.dense2(x2))), dim=1)\\n+        x3 = F.dropout(x3, p=rd.uniform(0.0, 0.5), training=self.training)\\n+        x4 = self.dense3(x3)\\n+        return x4\\n+\\n+\\n+class AgentDelayDDPG:\\n+    def __init__(self, state_dim, action_dim, mod_dim,\\n+                 gamma, policy_noise, update_gap):\\n+        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n+\\n+        ''''''\\n+        self.state_dim = state_dim\\n+        self.action_dim = action_dim\\n+        self.state_idx = 1 + 1 + state_dim  # reward_dim==1, done_dim==1, state_dim\\n+        self.action_idx = self.state_idx + action_dim\\n+\\n+        from torch import optim\\n+        self.act = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_optimizer = optim.Adam(self.act.parameters(), lr=4e-4)\\n+        self.act.train()\\n+\\n+        self.act_target = Actor(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.act_target.load_state_dict(self.act.state_dict())\\n+        self.act_target.eval()\\n+\\n+        self.cri = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_optimizer = optim.Adam(self.cri.parameters(), lr=1e-3)\\n+        self.cri.train()\\n+\\n+        self.cri_target = Critic(state_dim, action_dim, mod_dim).to(self.device)\\n+        self.cri_target.load_state_dict(self.cri.state_dict())\\n+        self.cri_target.eval()\\n+\\n+        self.criterion = nn.SmoothL1Loss()\\n+\\n+        self.update_counter = 0\\n+        self.update_gap = update_gap\\n+        self.policy_noise = policy_noise\\n+        self.gamma = gamma\\n+\\n+    def select_action(self, state):\\n+        state = torch.tensor((state,), dtype=torch.float32).to(self.device)\\n+        action = self.act(state).cpu().data.numpy()\\n+        return action[0]\\n+\\n+    def update(self, memories, iter_num, batch_size):\\n+        actor_loss_avg, critic_loss_avg = 0, 0\\n+\\n+        k = 1 + memories.size / memories.memories_num\\n+        iter_num = int(k * iter_num)\\n+        batch_size = int(k * batch_size)\\n+\\n+        for i in range(iter_num):\\n+            with torch.no_grad():\\n+                memory = memories.sample(batch_size)\\n+                memory = torch.tensor(memory, dtype=torch.float32).to(self.device)\\n+                reward = memory[:, 0:1]\\n+                undone = memory[:, 1:2]\\n+                state = memory[:, 2:self.state_idx]\\n+                action = memory[:, self.state_idx:self.action_idx]\\n+                next_state = memory[:, self.action_idx:]\\n+\\n+                noise = torch.randn(action.size(), dtype=torch.float32, device=self.device) * self.policy_noise\\n+\\n+            next_action = self.act_target(next_state) + noise\\n+            next_action = next_action.clamp(-1.0, 1.0)\\n+\\n+            with torch.no_grad():\\n+                q_target = self.cri_target(next_state, next_action)\\n+                q_target = reward + undone * self.gamma * q_target\\n+\\n+            q_eval = self.cri(state, action)\\n+            critic_loss = self.criterion(q_eval, q_target)\\n+            critic_loss_avg += critic_loss.item()\\n+            self.cri_optimizer.zero_grad()\\n+            critic_loss.backward()\\n+            self.cri_optimizer.step()\\n+\\n+            actor_loss = -self.cri(state, self.act(state)).mean()\\n+            actor_loss_avg += actor_loss.item()\\n+            self.act_optimizer.zero_grad()\\n+            actor_loss.backward()\\n+            self.act_optimizer.step()\\n+\\n+            self.update_counter += 1\\n+            if self.update_counter == self.update_gap:\\n+                self.update_counter = 0\\n+                self.act_target.load_state_dict(self.act.state_dict())\\n+                self.cri_target.load_state_dict(self.cri.state_dict())\\n+\\n+        actor_loss_avg /= iter_num\\n+        critic_loss_avg /= iter_num\\n+        return actor_loss_avg, critic_loss_avg\\n+\\n+    def save(self, mod_dir, save_actor_only=False):\\n+        if save_actor_only:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            print(\"Saved: (actor_only)\", mod_dir)\\n+        else:\\n+            torch.save(self.act.state_dict(), '%s/actor.pth' % (mod_dir,))\\n+            torch.save(self.cri.state_dict(), '%s/critic.pth' % (mod_dir,))\\n+            torch.save(self.act_target.state_dict(), '%s/actor_target.pth' % (mod_dir,))\\n+            torch.save(self.cri_target.state_dict(), '%s/critic_target.pth' % (mod_dir,))\\n+\\n+            torch.save(self.act_optimizer.state_dict(), '%s/actor_optimizer.pth' % (mod_dir,))\\n+            torch.save(self.cri_optimizer.state_dict(), '%s/critic_optimizer.pth' % (mod_dir,))\\n+\\n+            print(\"Saved:\", mod_dir)\\n+\\n+    def load(self, mod_dir, load_actor_only=False):\\n+        if load_actor_only:\\n+            print(\"Loading: (actor_only)\", mod_dir)\\n+            self.act_target.load_state_dict(\\n+                torch.load('%s/actor_target.pth' % (mod_dir,), map_location=lambda storage, loc: storage))\\n+        else:\\n+            def map_location(storage, loc):  # ignore storage location (device id)\\n+                return storage\\n+\\n+            print(\"Loading:\", mod_dir)\\n+            torch.load('%s/actor.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/actor_target.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_target.pth' % (mod_dir,), map_location)\\n+\\n+            torch.load('%s/actor_optimizer.pth' % (mod_dir,), map_location)\\n+            torch.load('%s/critic_optimizer.pth' % (mod_dir,), map_location)\\n+\\n+\\n+class Memories:\\n+    ptr_u = 0  # pointer_for_update\\n+    ptr_s = 0  # pointer_for_sample\\n+    is_full = False\\n+\\n+    def __init__(self, memories_num, state_dim, action_dim, ):\\n+        self.size = 0\\n+\\n+        memories_num = int(memories_num)\\n+        self.memories_num = memories_num\\n+\\n+        reward_dim = 1\\n+        done_dim = 1\\n+        memories_dim = reward_dim + done_dim + state_dim + action_dim + state_dim\\n+        self.memories = np.empty((memories_num, memories_dim), dtype=np.float32)\\n+        self.indices = np.arange(memories_num)\\n+\\n+    def add(self, memory):\\n+        self.memories[self.ptr_u, :] = memory\\n+\\n+        self.ptr_u += 1\\n+        if self.ptr_u == self.memories_num:\\n+            self.ptr_u = 0\\n+            if not self.is_full:\\n+                self.is_full = True\\n+                print('Memories is_full!')\\n+        self.size = self.memories_num if self.is_full else self.ptr_u\\n+\\n+    def sample(self, batch_size):\\n+        self.ptr_s += batch_size\\n+        if self.ptr_s &gt;= self.size:\\n+            self.ptr_s = batch_size\\n+            rd.shuffle(self.indices[:self.size])\\n+\\n+        batch_memory = self.memories[self.indices[self.ptr_s - batch_size:self.ptr_s]]\\n+        return batch_memory\\n+\\n+\\n+def train():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    env_name = args.env_name\\n+    mod_dir = args.mod_dir\\n+\\n+    memories_size = args.memories_size\\n+    batch_size = args.batch_size\\n+    update_gap = args.update_gap\\n+    mod_dim = args.mod_dim\\n+\\n+    target_reward = args.target_reward\\n+    smooth_kernel = args.smooth_kernel\\n+    print_gap = args.print_gap\\n+    max_step = args.max_step\\n+    max_epoch = args.max_epoch\\n+\\n+    gamma = args.gamma\\n+    explore_noise = args.explore_noise\\n+    policy_noise = args.policy_noise\\n+    random_seed = args.random_seed\\n+\\n+    def whether_remove_history(remove=None):\\n+        print('  GPUid: %s' % gpu_id)\\n+        print('  Model: %s' % mod_dir)\\n+        if remove is None:\\n+            remove = bool(input(\"  'y' to REMOVE: %s? \" % mod_dir) == 'y')\\n+        if remove:\\n+            import shutil\\n+            shutil.rmtree(mod_dir, ignore_errors=True)\\n+            print(\"| Remove\")\\n+            del shutil\\n+\\n+        if not os.path.exists(mod_dir):\\n+            os.mkdir(mod_dir)\\n+\\n+    whether_remove_history(remove=args.is_remove)\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    env.seed(random_seed)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma, policy_noise, update_gap)\\n+\\n+    memories = Memories(memories_size, state_dim, action_dim)\\n+    torch.set_num_threads(8)\\n+    torch.manual_seed(random_seed)\\n+    np.random.seed(random_seed)\\n+\\n+    '''train loop'''\\n+    rd_normal = np.random.normal\\n+    recorders = list()\\n+    rewards = list()\\n+\\n+    start_time = show_time = timer()\\n+    try:\\n+        for epoch in range(max_epoch):\\n+            state = env.reset()\\n+            epoch_reward = 0\\n+            iter_num = 0\\n+            for iter_num in range(max_step):\\n+                action = policy.select_action(state)\\n+\\n+                action += rd_normal(0, explore_noise, size=action_dim)  # add explore noise\\n+                action = action.clip(-1.0, 1.0)\\n+\\n+                next_state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim))\\n+                memories.add(np.hstack(((reward, 1 - float(done)), state, action, next_state)))\\n+                state = next_state\\n+\\n+                epoch_reward += reward\\n+\\n+                if done:\\n+                    break\\n+\\n+            al, cl = policy.update(memories, iter_num, batch_size)\\n+\\n+            recorders.append((epoch, al, cl))\\n+            rewards.append(epoch_reward)\\n+            smooth_reward = np.average(rewards[-smooth_kernel:])\\n+\\n+            if timer() - show_time &gt; print_gap:\\n+                show_time = timer()\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+            if smooth_reward &gt; target_reward and epoch_reward &gt; target_reward:\\n+                print(\"########## Solved! ###########\")\\n+                print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                      % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                break\\n+\\n+            if epoch_reward &gt; target_reward:  # eval and break\\n+                print(\"Eval: %.2f\" % epoch_reward)\\n+                policy.act.eval()\\n+\\n+                eva_rewards = list()\\n+                eva_epoch = 100\\n+                for eval_epoch in range(eva_epoch):\\n+                    state = env.reset()\\n+                    eva_reward = 0\\n+                    for _ in range(max_step):\\n+                        action = policy.select_action(state)\\n+                        state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+\\n+                        eva_reward += reward\\n+                        # env.render()\\n+                        if done:\\n+                            break\\n+                    eva_rewards.append(eva_reward)\\n+\\n+                    temp_target_reward = target_reward * (len(eva_rewards) / eva_epoch)\\n+                    if np.average(eva_rewards) &lt; temp_target_reward:\\n+                        break  # break the evaluating loop ahead of time.\\n+\\n+                if np.average(eva_rewards) &gt; target_reward:\\n+                    print(\"########## Solved! ###########\")\\n+                    print(\"%3i\\tSmoR: %3i\\tEpiR %3i\\t|A %.3f, C %.3f\"\\n+                          % (epoch, smooth_reward, epoch_reward, al, cl))\\n+                    break\\n+\\n+                policy.act.train()\\n+    except KeyboardInterrupt:\\n+        print(\"KeyboardInterrupt\")\\n+    finally:\\n+        print('TimeUsed:', int(timer() - start_time))\\n+        policy.save(mod_dir)\\n+\\n+    recorders = np.concatenate((np.array(rewards)[:, np.newaxis],\\n+                                recorders), axis=1)\\n+    report_plot(recorders, smooth_kernel, mod_dir,\\n+                img_save_name=\"%s_plot.png\" % (mod_dir,))\\n+\\n+\\n+def evals():\\n+    args = Arguments()\\n+\\n+    gpu_id = args.gpu_id\\n+    mod_dir = args.mod_dir\\n+    env_name = args.env_name\\n+    eval_epoch = args.eval_epoch\\n+    max_step = args.max_step\\n+    mod_dim = args.mod_dim\\n+\\n+    '''env init'''\\n+    env = gym.make(env_name)\\n+    state_dim = env.observation_space.shape[0]\\n+    try:\\n+        action_dim = env.action_space.shape[0]\\n+        action_max = float(env.action_space.high[0])\\n+    except IndexError:\\n+        action_dim = env.action_space.n  # Discrete\\n+        action_max = None\\n+        print('action_space: Discrete:', action_dim)\\n+\\n+    '''mod init'''\\n+    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\\n+    policy = AgentDelayDDPG(state_dim, action_dim, mod_dim,\\n+                            gamma=0, policy_noise=0, update_gap=0)\\n+    # (gamma=0, policy_noise=0, update_gap=0) are not required for evaluating\\n+    policy.load(mod_dir, load_actor_only=True)\\n+    policy.act.eval()\\n+    policy.cri.eval()\\n+\\n+    for epoch in range(eval_epoch):\\n+        epoch_reward = 0\\n+        state = env.reset()\\n+        for iter_num in range(max_step):\\n+            action = policy.select_action(state)\\n+            state, reward, done, _ = env.step(adapt_action(action, action_max, action_dim=False))\\n+            epoch_reward += reward\\n+            env.render()\\n+            # Image.fromarray(env.render(mode='rgb_array')).save('%s/img_%4i.png'%(mod_dir, iter_num))\\n+            if done:\\n+                break\\n+\\n+        print(\"%3i\\tEpiR %3i\" % (epoch, epoch_reward))\\n+    env.close()\\n+\\n+\\n+def adapt_action(action, action_max, action_dim):\\n+    \"\"\"\\n+    :param action: belongs to range(-1, 1), makes it suit for env.step(action)\\n+    :param action_max: if it is False, means DISCRETE action_space\\n+    :param action_dim: if it is False, means DISCRETE action_space and not train.\\n+    :return: a compatible action for env\\n+    \"\"\"\\n+    if action_max:  # action_space: Continuous\\n+        return action * action_max\\n+    elif action_dim:  # action_space: Discrete and is_train\\n+        action_prob = action + 1.00001\\n+        action_prob /= sum(action_prob)\\n+        return rd.choice(action_dim, p=action_prob)\\n+    else:  # action_space: Discrete and is_eval\\n+        return np.argmax(action)\\n+\\n+\\n+def report_plot(recorders, smooth_kernel, mod_dir, img_save_name):\\n+    np.save('%s/recorders.npy' % mod_dir, recorders)\\n+    # recorders = np.load('%s/recorders.npy'% mod_dir)\\n+    # report_plot(recorders=np.load('recorders.npy', ), smooth_kernel=32, mod_dir=0, save_name='TD.png')\\n+    if recorders is list():\\n+        return print('Record is empty')\\n+    else:\\n+        print(\"Matplotlib Plot:\", img_save_name)\\n+    import matplotlib.pyplot as plt\\n+\\n+    y_reward = np.array(recorders[:, 0]).clip(-500, 500)\\n+    y_reward_smooth = np.pad(y_reward, (smooth_kernel - 1, 0), mode='reflect')\\n+    y_reward_smooth = np.convolve(y_reward_smooth, np.ones(smooth_kernel) / smooth_kernel, mode='valid')\\n+\\n+    x_epoch = np.array(recorders[:, 1])\\n+\\n+    fig, axs = plt.subplots(3)\\n+    plt.title(img_save_name, y=3.5)\\n+\\n+    axs[0].plot(x_epoch, y_reward, label='Reward', linestyle=':')\\n+    axs[0].plot(x_epoch, y_reward_smooth, label='Smooth R')\\n+    axs[0].legend()\\n+\\n+    axs[1].plot(x_epoch, recorders[:, 2], label='loss_A')\\n+    axs[2].plot(x_epoch, recorders[:, 3], label='loss_C')\\n+\\n+    plt.savefig(\"%s/%s\" % (mod_dir, img_save_name))\\n+    plt.show()\\n+\\n+\\n+if __name__ == '__main__':\\n+    train()\\n+    evals()\\n</td>\n",
              "      <td>source</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>elegantrl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>History/LICENSE</td>\n",
              "      <td>a3f494dd7cc0d2af234957a92240ae8ea70c6dec</td>\n",
              "      <td>6094ed779eead413f7e059bc19e3a0f5ce313468</td>\n",
              "      <td>LICENSE  Apache 2.0\\n\\nand origin  version</td>\n",
              "      <td>@@ -0,0 +1,27 @@\\n+Copyright [2019] [֣Ѻ Zen4 Jia1Hao2 Yonv1943]\\r\\n+\\r\\n+עԴʱֻ򵥵עд Yonv1943 ⼸ԷǳߵַɣҲϸдݴַһGitHub\\r\\n+You simply need to write 'Yonv1943' in the comment, when annotating the source of this code. 'Yonv1943' is special and only few results can be obtained when you search it on the Internet(Before 2019 year). Or you can mark the corresponding website of this code in detail. (Generally GitHub)\\r\\n+\\r\\n+ʵApache License 2.0Դ֤ѡģֻΪ:Ȼʹ˵Ĵ룬ôҪԴдϡ\\r\\n+Actully, I chose Apache License 2.0 as an open source license at random. In my opinion: Since we use other people's code, we need to write the source of the reference.\\r\\n+\\r\\n+\\r\\n+\\r\\n+Yonv1943\\r\\n+About 'Yonv1943'\\r\\n+\\r\\n+Yonv (YonV), YonȡԳաBeYondֶӣYon: YonderǣV (Victory)ȡVơʵһʼҪȡYoY֣·Ѿ̫YoYˣֻȡˣ\\r\\n+1943˼ǹ㶫ͷѧһŰ43ţҵõѧźĲãҿʼķҿʼ֪Ҫʲôˣ߶ʱҵʦѧʦҵ۲ſʼΡ1943һȽҪʱ㣬ֵüͨʱȻ1943Ϊݣô˵޺ܵͣ\\r\\n+\\r\\n+Licensed under the Apache License, Version 2.0 (the \"License\");\\r\\n+you may not use this file except in compliance with the License.\\r\\n+You may obtain a copy of the License at\\r\\n+\\r\\n+    http://www.apache.org/licenses/LICENSE-2.0\\r\\n+\\r\\n+Unless required by applicable law or agreed to in writing, software\\r\\n+distributed under the License is distributed on an \"AS IS\" BASIS,\\r\\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\r\\n+See the License for the specific language governing permissions and\\r\\n+limitations under the License.\\n\\ No newline at end of file\\n</td>\n",
              "      <td>'utf-8' codec can't decode byte 0xbc in position 167: invalid start byte</td>\n",
              "      <td>license</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-438d9432-c6ed-44ac-a20d-4740f4858654')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-438d9432-c6ed-44ac-a20d-4740f4858654 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-438d9432-c6ed-44ac-a20d-4740f4858654');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-834bb9be-0cd2-40f3-a7f4-46dcb9bd2d92\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-834bb9be-0cd2-40f3-a7f4-46dcb9bd2d92')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-834bb9be-0cd2-40f3-a7f4-46dcb9bd2d92 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/flask_diffs.csv\")\n",
        "pd.set_option(\"display.max_colwidth\", None)  # Show full commit messages and diffs\n",
        "display(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TUa8LYCqg9Sw",
        "outputId": "66479899-982b-4166-8abb-1f39b553ac04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  repo_name old_file_path                new_file_path  \\\n",
              "0     flask           NaN                      LICENSE   \n",
              "1     flask           NaN        actions/web_scrape.py   \n",
              "2     flask           NaN        actions/web_search.py   \n",
              "3     flask           NaN             agent/prompts.py   \n",
              "4     flask           NaN  agent/research_assistant.py   \n",
              "\n",
              "                                 commit_sha  \\\n",
              "0  e983f3a0d3e45ced42c0d309244a17cebfba32f4   \n",
              "1  653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d   \n",
              "2  653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d   \n",
              "3  653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d   \n",
              "4  653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d   \n",
              "\n",
              "                          parent_commit_sha        commit_message  \\\n",
              "0                                       NaN        Initial commit   \n",
              "1  e983f3a0d3e45ced42c0d309244a17cebfba32f4  added all base files   \n",
              "2  e983f3a0d3e45ced42c0d309244a17cebfba32f4  added all base files   \n",
              "3  e983f3a0d3e45ced42c0d309244a17cebfba32f4  added all base files   \n",
              "4  e983f3a0d3e45ced42c0d309244a17cebfba32f4  added all base files   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          diff_myers  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          @@ -0,0 +1,21 @@\\n+MIT License\\n+\\n+Copyright (c) 2023 Assaf Elovic\\n+\\n+Permission is hereby granted, free of charge, to any person obtaining a copy\\n+of this software and associated documentation files (the \"Software\"), to deal\\n+in the Software without restriction, including without limitation the rights\\n+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\n+copies of the Software, and to permit persons to whom the Software is\\n+furnished to do so, subject to the following conditions:\\n+\\n+The above copyright notice and this permission notice shall be included in all\\n+copies or substantial portions of the Software.\\n+\\n+THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\n+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\n+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\n+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\n+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\n+SOFTWARE.\\n   \n",
              "1  @@ -0,0 +1,181 @@\\n+\"\"\"Selenium web scraping module.\"\"\"\\n+from __future__ import annotations\\n+\\n+import logging\\n+import asyncio\\n+from pathlib import Path\\n+from sys import platform\\n+\\n+from bs4 import BeautifulSoup\\n+from selenium import webdriver\\n+from selenium.webdriver.chrome.options import Options as ChromeOptions\\n+from selenium.webdriver.common.by import By\\n+from selenium.webdriver.firefox.options import Options as FirefoxOptions\\n+from selenium.webdriver.remote.webdriver import WebDriver\\n+from selenium.webdriver.safari.options import Options as SafariOptions\\n+from selenium.webdriver.support import expected_conditions as EC\\n+from selenium.webdriver.support.wait import WebDriverWait\\n+from webdriver_manager.chrome import ChromeDriverManager\\n+from webdriver_manager.firefox import GeckoDriverManager\\n+\\n+import processing.text as summary\\n+\\n+from config import Config\\n+from processing.html import extract_hyperlinks, format_hyperlinks\\n+\\n+from concurrent.futures import ThreadPoolExecutor\\n+executor = ThreadPoolExecutor()\\n+\\n+FILE_DIR = Path(__file__).parent.parent\\n+CFG = Config()\\n+\\n+async def async_browse(url: str, question: str) -> str:\\n+    loop = asyncio.get_event_loop()\\n+\\n+    driver, text = await loop.run_in_executor(executor, scrape_text_with_selenium, url)\\n+    await loop.run_in_executor(executor, add_header, driver)\\n+    summary_text = await loop.run_in_executor(executor, summary.summarize_text, url, text, question, driver)\\n+\\n+    await loop.run_in_executor(executor, close_browser, driver)\\n+    return f\"Information gathered from url {url}: {summary_text}\"\\n+\\n+def browse_website(url: str, question: str) -> tuple[str, WebDriver]:\\n+    \"\"\"Browse a website and return the answer and links to the user\\n+\\n+    Args:\\n+        url (str): The url of the website to browse\\n+        question (str): The question asked by the user\\n+\\n+    Returns:\\n+        Tuple[str, WebDriver]: The answer and links to the user and the webdriver\\n+    \"\"\"\\n+\\n+    if not url:\\n+        return \"A URL was not specified, cancelling request to browse website.\", None\\n+\\n+    driver, text = scrape_text_with_selenium(url)\\n+    add_header(driver)\\n+    summary_text = summary.summarize_text(url, text, question, driver)\\n+\\n+    links = scrape_links_with_selenium(driver, url)\\n+\\n+    # Limit links to 5\\n+    if len(links) > 5:\\n+        links = links[:5]\\n+\\n+    # write_to_file('research-{0}.txt'.format(url), summary_text + \"\\nSource Links: {0}\\n\\n\".format(links))\\n+\\n+    close_browser(driver)\\n+    return f\"Answer gathered from website: {summary_text} \\n \\n Links: {links}\", driver\\n+\\n+\\n+def scrape_text_with_selenium(url: str) -> tuple[WebDriver, str]:\\n+    \"\"\"Scrape text from a website using selenium\\n+\\n+    Args:\\n+        url (str): The url of the website to scrape\\n+\\n+    Returns:\\n+        Tuple[WebDriver, str]: The webdriver and the text scraped from the website\\n+    \"\"\"\\n+    print(\"Scraping text from website {0}...\".format(url))\\n+    logging.getLogger(\"selenium\").setLevel(logging.CRITICAL)\\n+\\n+    options_available = {\\n+        \"chrome\": ChromeOptions,\\n+        \"safari\": SafariOptions,\\n+        \"firefox\": FirefoxOptions,\\n+    }\\n+\\n+    options = options_available[CFG.selenium_web_browser]()\\n+    options.add_argument(\\n+        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.49 Safari/537.36\"\\n+    )\\n+    options.add_argument('--headless')\\n+\\n+    if CFG.selenium_web_browser == \"firefox\":\\n+        driver = webdriver.Firefox(\\n+            executable_path=GeckoDriverManager().install(), options=options\\n+        )\\n+    elif CFG.selenium_web_browser == \"safari\":\\n+        # Requires a bit more setup on the users end\\n+        # See https://developer.apple.com/documentation/webkit/testing_with_webdriver_in_safari\\n+        driver = webdriver.Safari(options=options)\\n+    else:\\n+        if platform == \"linux\" or platform == \"linux2\":\\n+            options.add_argument(\"--disable-dev-shm-usage\")\\n+            options.add_argument(\"--remote-debugging-port=9222\")\\n+        options.add_argument(\"--no-sandbox\")\\n+        driver = webdriver.Chrome(\\n+            executable_path=ChromeDriverManager().install(), options=options\\n+        )\\n+    driver.get(url)\\n+\\n+    WebDriverWait(driver, 10).until(\\n+        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\\n+    )\\n+\\n+    # Get the HTML content directly from the browser's DOM\\n+    page_source = driver.execute_script(\"return document.body.outerHTML;\")\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    #text = soup.get_text()\\n+    text = get_text(soup)\\n+\\n+    lines = (line.strip() for line in text.splitlines())\\n+    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\\n+    text = \"\\n\".join(chunk for chunk in chunks if chunk)\\n+    return driver, text\\n+\\n+def get_text(soup):\\n+    text = \"\"\\n+    tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'p']\\n+    for element in soup.find_all(tags):  # Find all the <p> elements\\n+        text += element.text + \"\\n\\n\"\\n+    return text\\n+\\n+def scrape_links_with_selenium(driver: WebDriver, url: str) -> list[str]:\\n+    \"\"\"Scrape links from a website using selenium\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to scrape the links\\n+\\n+    Returns:\\n+        List[str]: The links scraped from the website\\n+    \"\"\"\\n+    page_source = driver.page_source\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    hyperlinks = extract_hyperlinks(soup, url)\\n+\\n+    return format_hyperlinks(hyperlinks)\\n+\\n+\\n+def close_browser(driver: WebDriver) -> None:\\n+    \"\"\"Close the browser\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to close\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.quit()\\n+\\n+\\n+def add_header(driver: WebDriver) -> None:\\n+    \"\"\"Add a header to the website\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to add the header\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.execute_script(open(f\"{FILE_DIR}/js/overlay.js\", \"r\").read())\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  @@ -0,0 +1,25 @@\\n+from __future__ import annotations\\n+import json\\n+from duckduckgo_search import DDGS\\n+\\n+ddgs = DDGS()\\n+\\n+def web_search(query: str, num_results: int = 5) -> str:\\n+    \"\"\"Useful for general internet search queries.\"\"\"\\n+    print(\"Searching with query {0}...\".format(query))\\n+    search_results = []\\n+    if not query:\\n+        return json.dumps(search_results)\\n+\\n+    results = ddgs.text(query)\\n+    if not results:\\n+        return json.dumps(search_results)\\n+\\n+    total_added = 0\\n+    for j in results:\\n+        search_results.append(j)\\n+        total_added += 1\\n+        if total_added >= num_results:\\n+            break\\n+\\n+    return json.dumps(search_results, ensure_ascii=False, indent=4)\\n   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              @@ -0,0 +1,16 @@\\n+AGENT_ROLE_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"\\n+\\n+def generate_agent_role_prompt():\\n+    return AGENT_ROLE_PROMPT\\n+\\n+def generate_report_prompt(question, research_summary):\\n+    return f'\"\"\"{research_summary}\"\"\" Using the above information, answer the following'\\\\n+           f' question or topic: \"{question}\" in a detailed report --'\\\\n+           \" The report should focus on the answer to the question, should be well structured, \" \\\\n+           \"informative, in depth, with facts and numbers if available, a minimum of 1,200 words and with markdown syntax. \"\\\\n+            \"Write all source urls at the end of the report, including urls that weren't used (explain why you didn't use them).\"\\n+\\n+def generate_search_queries_prompt(question):\\n+    return f'Write 4 google search queries to search online that form an objective opinion from the following: \"{question}\"'\\\\n+           f'You must respond with a list of strings in the following format: [\"query 1\", \"query 2\", \"query 3\", \"query 4\"]'\\n+\\n   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  @@ -0,0 +1,102 @@\\n+import asyncio\\n+import json\\n+from actions.web_search import web_search\\n+from actions.web_scrape import async_browse\\n+from processing.text import write_to_file, create_message, create_chat_completion, md_to_pdf, read_txt_files\\n+from config import Config\\n+from agent import prompts\\n+import os\\n+\\n+CFG = Config()\\n+\\n+\\n+class ResearchAssistant:\\n+    def __init__(self, question):\\n+        self.question = question\\n+        self.visited_urls = set()\\n+        self.research_summary = \"\"\\n+        self.directory_name = question[:100] if len(question) > 100 else question\\n+        self.dir_path = os.path.dirname(f\"./outputs/{self.directory_name}/\")\\n+\\n+    def summarize(self, text, topic):\\n+        messages = [create_message(text, topic)]\\n+        print(\"Summarizing text for query: \", text)\\n+        return create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+\\n+    def get_new_urls(self, url_set_input):\\n+        new_urls = []\\n+        for url in url_set_input:\\n+            if url not in self.visited_urls:\\n+                print(\"New url found: \", url)\\n+                self.visited_urls.add(url)\\n+                new_urls.append(url)\\n+        return new_urls\\n+\\n+    def create_search_queries(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_search_queries_prompt(self.question),\\n+        }]\\n+        result = create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+        print(f\"Search queries: {result}\")\\n+        return json.loads(result)\\n+\\n+    def write_report(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_report_prompt(self.question, self.research_summary),\\n+        }]\\n+        print(f\"Writing report for query: {self.question}...\")\\n+        answer = create_chat_completion(\\n+            model=\"gpt-4\",\\n+            messages=messages,\\n+            stream=True,\\n+        )\\n+        file_path = f\"./outputs/{self.directory_name}/report\"\\n+        write_to_file(f\"{file_path}.md\", answer)\\n+        md_to_pdf(f\"{file_path}.md\", f\"{file_path}.pdf\")\\n+        print(f\"Report written to {file_path}.pdf\")\\n+        return answer\\n+\\n+    async def async_search(self, query):\\n+        search_results = json.loads(web_search(query))\\n+        new_search_urls = self.get_new_urls([url.get(\"href\") for url in search_results])\\n+        tasks = [asyncio.create_task(async_browse(url, query)) for url in new_search_urls]\\n+        print(\"Visited urls: \", self.visited_urls)\\n+        return await asyncio.gather(*tasks)\\n+\\n+    def run_search_summary(self, query):\\n+        print(f\"Running research for {query}...\")\\n+        loop = asyncio.get_event_loop()\\n+        responses = loop.run_until_complete(self.async_search(query))\\n+\\n+        result = \"\\n\".join(responses)\\n+        os.makedirs(os.path.dirname(f\"./outputs/{self.directory_name}/research-{query}.txt\"), exist_ok=True)\\n+        write_to_file(f\"./outputs/{self.directory_name}/research-{query}.txt\", result)\\n+        return result\\n+\\n+    def conduct_research(self):\\n+        self.research_summary = read_txt_files(self.dir_path) if os.path.isdir(self.dir_path) else \"\"\\n+\\n+        if not self.research_summary:\\n+            search_queries = self.create_search_queries()  # + [self.question]\\n+            for query in search_queries:\\n+                research_result = self.run_search_summary(query)  # summarize(run_search_summary(query), query)\\n+                self.research_summary += f\"{research_result}\\n\\n\"  # f\"{query}\\n{research_result}\\n\\n\"\\n+                print(\"Research summary so far: \", self.research_summary)\\n+\\n+        print(self.research_summary)\\n+        print(\"Total research words: {0}\".format(len(self.research_summary.split(\" \"))))\\n+        return self.research_summary\\n\\ No newline at end of file\\n   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   diff_hist  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Command '['git', '-C', 'gpt_researcher', 'diff', '--histogram', 'e983f3a0d3e45ced42c0d309244a17cebfba32f4^', 'e983f3a0d3e45ced42c0d309244a17cebfba32f4', '--', 'LICENSE']' returned non-zero exit status 128.   \n",
              "1  diff --git a/actions/web_scrape.py b/actions/web_scrape.py\\nnew file mode 100644\\nindex 00000000..f768357b\\n--- /dev/null\\n+++ b/actions/web_scrape.py\\n@@ -0,0 +1,181 @@\\n+\"\"\"Selenium web scraping module.\"\"\"\\n+from __future__ import annotations\\n+\\n+import logging\\n+import asyncio\\n+from pathlib import Path\\n+from sys import platform\\n+\\n+from bs4 import BeautifulSoup\\n+from selenium import webdriver\\n+from selenium.webdriver.chrome.options import Options as ChromeOptions\\n+from selenium.webdriver.common.by import By\\n+from selenium.webdriver.firefox.options import Options as FirefoxOptions\\n+from selenium.webdriver.remote.webdriver import WebDriver\\n+from selenium.webdriver.safari.options import Options as SafariOptions\\n+from selenium.webdriver.support import expected_conditions as EC\\n+from selenium.webdriver.support.wait import WebDriverWait\\n+from webdriver_manager.chrome import ChromeDriverManager\\n+from webdriver_manager.firefox import GeckoDriverManager\\n+\\n+import processing.text as summary\\n+\\n+from config import Config\\n+from processing.html import extract_hyperlinks, format_hyperlinks\\n+\\n+from concurrent.futures import ThreadPoolExecutor\\n+executor = ThreadPoolExecutor()\\n+\\n+FILE_DIR = Path(__file__).parent.parent\\n+CFG = Config()\\n+\\n+async def async_browse(url: str, question: str) -> str:\\n+    loop = asyncio.get_event_loop()\\n+\\n+    driver, text = await loop.run_in_executor(executor, scrape_text_with_selenium, url)\\n+    await loop.run_in_executor(executor, add_header, driver)\\n+    summary_text = await loop.run_in_executor(executor, summary.summarize_text, url, text, question, driver)\\n+\\n+    await loop.run_in_executor(executor, close_browser, driver)\\n+    return f\"Information gathered from url {url}: {summary_text}\"\\n+\\n+def browse_website(url: str, question: str) -> tuple[str, WebDriver]:\\n+    \"\"\"Browse a website and return the answer and links to the user\\n+\\n+    Args:\\n+        url (str): The url of the website to browse\\n+        question (str): The question asked by the user\\n+\\n+    Returns:\\n+        Tuple[str, WebDriver]: The answer and links to the user and the webdriver\\n+    \"\"\"\\n+\\n+    if not url:\\n+        return \"A URL was not specified, cancelling request to browse website.\", None\\n+\\n+    driver, text = scrape_text_with_selenium(url)\\n+    add_header(driver)\\n+    summary_text = summary.summarize_text(url, text, question, driver)\\n+\\n+    links = scrape_links_with_selenium(driver, url)\\n+\\n+    # Limit links to 5\\n+    if len(links) > 5:\\n+        links = links[:5]\\n+\\n+    # write_to_file('research-{0}.txt'.format(url), summary_text + \"\\nSource Links: {0}\\n\\n\".format(links))\\n+\\n+    close_browser(driver)\\n+    return f\"Answer gathered from website: {summary_text} \\n \\n Links: {links}\", driver\\n+\\n+\\n+def scrape_text_with_selenium(url: str) -> tuple[WebDriver, str]:\\n+    \"\"\"Scrape text from a website using selenium\\n+\\n+    Args:\\n+        url (str): The url of the website to scrape\\n+\\n+    Returns:\\n+        Tuple[WebDriver, str]: The webdriver and the text scraped from the website\\n+    \"\"\"\\n+    print(\"Scraping text from website {0}...\".format(url))\\n+    logging.getLogger(\"selenium\").setLevel(logging.CRITICAL)\\n+\\n+    options_available = {\\n+        \"chrome\": ChromeOptions,\\n+        \"safari\": SafariOptions,\\n+        \"firefox\": FirefoxOptions,\\n+    }\\n+\\n+    options = options_available[CFG.selenium_web_browser]()\\n+    options.add_argument(\\n+        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.49 Safari/537.36\"\\n+    )\\n+    options.add_argument('--headless')\\n+\\n+    if CFG.selenium_web_browser == \"firefox\":\\n+        driver = webdriver.Firefox(\\n+            executable_path=GeckoDriverManager().install(), options=options\\n+        )\\n+    elif CFG.selenium_web_browser == \"safari\":\\n+        # Requires a bit more setup on the users end\\n+        # See https://developer.apple.com/documentation/webkit/testing_with_webdriver_in_safari\\n+        driver = webdriver.Safari(options=options)\\n+    else:\\n+        if platform == \"linux\" or platform == \"linux2\":\\n+            options.add_argument(\"--disable-dev-shm-usage\")\\n+            options.add_argument(\"--remote-debugging-port=9222\")\\n+        options.add_argument(\"--no-sandbox\")\\n+        driver = webdriver.Chrome(\\n+            executable_path=ChromeDriverManager().install(), options=options\\n+        )\\n+    driver.get(url)\\n+\\n+    WebDriverWait(driver, 10).until(\\n+        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\\n+    )\\n+\\n+    # Get the HTML content directly from the browser's DOM\\n+    page_source = driver.execute_script(\"return document.body.outerHTML;\")\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    #text = soup.get_text()\\n+    text = get_text(soup)\\n+\\n+    lines = (line.strip() for line in text.splitlines())\\n+    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\\n+    text = \"\\n\".join(chunk for chunk in chunks if chunk)\\n+    return driver, text\\n+\\n+def get_text(soup):\\n+    text = \"\"\\n+    tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'p']\\n+    for element in soup.find_all(tags):  # Find all the <p> elements\\n+        text += element.text + \"\\n\\n\"\\n+    return text\\n+\\n+def scrape_links_with_selenium(driver: WebDriver, url: str) -> list[str]:\\n+    \"\"\"Scrape links from a website using selenium\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to scrape the links\\n+\\n+    Returns:\\n+        List[str]: The links scraped from the website\\n+    \"\"\"\\n+    page_source = driver.page_source\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    hyperlinks = extract_hyperlinks(soup, url)\\n+\\n+    return format_hyperlinks(hyperlinks)\\n+\\n+\\n+def close_browser(driver: WebDriver) -> None:\\n+    \"\"\"Close the browser\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to close\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.quit()\\n+\\n+\\n+def add_header(driver: WebDriver) -> None:\\n+    \"\"\"Add a header to the website\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to add the header\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.execute_script(open(f\"{FILE_DIR}/js/overlay.js\", \"r\").read())\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  diff --git a/actions/web_search.py b/actions/web_search.py\\nnew file mode 100644\\nindex 00000000..7385c6ff\\n--- /dev/null\\n+++ b/actions/web_search.py\\n@@ -0,0 +1,25 @@\\n+from __future__ import annotations\\n+import json\\n+from duckduckgo_search import DDGS\\n+\\n+ddgs = DDGS()\\n+\\n+def web_search(query: str, num_results: int = 5) -> str:\\n+    \"\"\"Useful for general internet search queries.\"\"\"\\n+    print(\"Searching with query {0}...\".format(query))\\n+    search_results = []\\n+    if not query:\\n+        return json.dumps(search_results)\\n+\\n+    results = ddgs.text(query)\\n+    if not results:\\n+        return json.dumps(search_results)\\n+\\n+    total_added = 0\\n+    for j in results:\\n+        search_results.append(j)\\n+        total_added += 1\\n+        if total_added >= num_results:\\n+            break\\n+\\n+    return json.dumps(search_results, ensure_ascii=False, indent=4)\\n   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             diff --git a/agent/prompts.py b/agent/prompts.py\\nnew file mode 100644\\nindex 00000000..705c096e\\n--- /dev/null\\n+++ b/agent/prompts.py\\n@@ -0,0 +1,16 @@\\n+AGENT_ROLE_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"\\n+\\n+def generate_agent_role_prompt():\\n+    return AGENT_ROLE_PROMPT\\n+\\n+def generate_report_prompt(question, research_summary):\\n+    return f'\"\"\"{research_summary}\"\"\" Using the above information, answer the following'\\\\n+           f' question or topic: \"{question}\" in a detailed report --'\\\\n+           \" The report should focus on the answer to the question, should be well structured, \" \\\\n+           \"informative, in depth, with facts and numbers if available, a minimum of 1,200 words and with markdown syntax. \"\\\\n+            \"Write all source urls at the end of the report, including urls that weren't used (explain why you didn't use them).\"\\n+\\n+def generate_search_queries_prompt(question):\\n+    return f'Write 4 google search queries to search online that form an objective opinion from the following: \"{question}\"'\\\\n+           f'You must respond with a list of strings in the following format: [\"query 1\", \"query 2\", \"query 3\", \"query 4\"]'\\n+\\n   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                diff --git a/agent/research_assistant.py b/agent/research_assistant.py\\nnew file mode 100644\\nindex 00000000..32554db4\\n--- /dev/null\\n+++ b/agent/research_assistant.py\\n@@ -0,0 +1,102 @@\\n+import asyncio\\n+import json\\n+from actions.web_search import web_search\\n+from actions.web_scrape import async_browse\\n+from processing.text import write_to_file, create_message, create_chat_completion, md_to_pdf, read_txt_files\\n+from config import Config\\n+from agent import prompts\\n+import os\\n+\\n+CFG = Config()\\n+\\n+\\n+class ResearchAssistant:\\n+    def __init__(self, question):\\n+        self.question = question\\n+        self.visited_urls = set()\\n+        self.research_summary = \"\"\\n+        self.directory_name = question[:100] if len(question) > 100 else question\\n+        self.dir_path = os.path.dirname(f\"./outputs/{self.directory_name}/\")\\n+\\n+    def summarize(self, text, topic):\\n+        messages = [create_message(text, topic)]\\n+        print(\"Summarizing text for query: \", text)\\n+        return create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+\\n+    def get_new_urls(self, url_set_input):\\n+        new_urls = []\\n+        for url in url_set_input:\\n+            if url not in self.visited_urls:\\n+                print(\"New url found: \", url)\\n+                self.visited_urls.add(url)\\n+                new_urls.append(url)\\n+        return new_urls\\n+\\n+    def create_search_queries(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_search_queries_prompt(self.question),\\n+        }]\\n+        result = create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+        print(f\"Search queries: {result}\")\\n+        return json.loads(result)\\n+\\n+    def write_report(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_report_prompt(self.question, self.research_summary),\\n+        }]\\n+        print(f\"Writing report for query: {self.question}...\")\\n+        answer = create_chat_completion(\\n+            model=\"gpt-4\",\\n+            messages=messages,\\n+            stream=True,\\n+        )\\n+        file_path = f\"./outputs/{self.directory_name}/report\"\\n+        write_to_file(f\"{file_path}.md\", answer)\\n+        md_to_pdf(f\"{file_path}.md\", f\"{file_path}.pdf\")\\n+        print(f\"Report written to {file_path}.pdf\")\\n+        return answer\\n+\\n+    async def async_search(self, query):\\n+        search_results = json.loads(web_search(query))\\n+        new_search_urls = self.get_new_urls([url.get(\"href\") for url in search_results])\\n+        tasks = [asyncio.create_task(async_browse(url, query)) for url in new_search_urls]\\n+        print(\"Visited urls: \", self.visited_urls)\\n+        return await asyncio.gather(*tasks)\\n+\\n+    def run_search_summary(self, query):\\n+        print(f\"Running research for {query}...\")\\n+        loop = asyncio.get_event_loop()\\n+        responses = loop.run_until_complete(self.async_search(query))\\n+\\n+        result = \"\\n\".join(responses)\\n+        os.makedirs(os.path.dirname(f\"./outputs/{self.directory_name}/research-{query}.txt\"), exist_ok=True)\\n+        write_to_file(f\"./outputs/{self.directory_name}/research-{query}.txt\", result)\\n+        return result\\n+\\n+    def conduct_research(self):\\n+        self.research_summary = read_txt_files(self.dir_path) if os.path.isdir(self.dir_path) else \"\"\\n+\\n+        if not self.research_summary:\\n+            search_queries = self.create_search_queries()  # + [self.question]\\n+            for query in search_queries:\\n+                research_result = self.run_search_summary(query)  # summarize(run_search_summary(query), query)\\n+                self.research_summary += f\"{research_result}\\n\\n\"  # f\"{query}\\n{research_result}\\n\\n\"\\n+                print(\"Research summary so far: \", self.research_summary)\\n+\\n+        print(self.research_summary)\\n+        print(\"Total research words: {0}\".format(len(self.research_summary.split(\" \"))))\\n+        return self.research_summary\\n\\ No newline at end of file\\n   \n",
              "\n",
              "  file_type  \n",
              "0   license  \n",
              "1    source  \n",
              "2    source  \n",
              "3    source  \n",
              "4    source  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-682f96b8-6eef-480d-9458-4748d16cd8f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo_name</th>\n",
              "      <th>old_file_path</th>\n",
              "      <th>new_file_path</th>\n",
              "      <th>commit_sha</th>\n",
              "      <th>parent_commit_sha</th>\n",
              "      <th>commit_message</th>\n",
              "      <th>diff_myers</th>\n",
              "      <th>diff_hist</th>\n",
              "      <th>file_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>flask</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LICENSE</td>\n",
              "      <td>e983f3a0d3e45ced42c0d309244a17cebfba32f4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initial commit</td>\n",
              "      <td>@@ -0,0 +1,21 @@\\n+MIT License\\n+\\n+Copyright (c) 2023 Assaf Elovic\\n+\\n+Permission is hereby granted, free of charge, to any person obtaining a copy\\n+of this software and associated documentation files (the \"Software\"), to deal\\n+in the Software without restriction, including without limitation the rights\\n+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\n+copies of the Software, and to permit persons to whom the Software is\\n+furnished to do so, subject to the following conditions:\\n+\\n+The above copyright notice and this permission notice shall be included in all\\n+copies or substantial portions of the Software.\\n+\\n+THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\n+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\n+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\n+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\n+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\n+SOFTWARE.\\n</td>\n",
              "      <td>Command '['git', '-C', 'gpt_researcher', 'diff', '--histogram', 'e983f3a0d3e45ced42c0d309244a17cebfba32f4^', 'e983f3a0d3e45ced42c0d309244a17cebfba32f4', '--', 'LICENSE']' returned non-zero exit status 128.</td>\n",
              "      <td>license</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>flask</td>\n",
              "      <td>NaN</td>\n",
              "      <td>actions/web_scrape.py</td>\n",
              "      <td>653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d</td>\n",
              "      <td>e983f3a0d3e45ced42c0d309244a17cebfba32f4</td>\n",
              "      <td>added all base files</td>\n",
              "      <td>@@ -0,0 +1,181 @@\\n+\"\"\"Selenium web scraping module.\"\"\"\\n+from __future__ import annotations\\n+\\n+import logging\\n+import asyncio\\n+from pathlib import Path\\n+from sys import platform\\n+\\n+from bs4 import BeautifulSoup\\n+from selenium import webdriver\\n+from selenium.webdriver.chrome.options import Options as ChromeOptions\\n+from selenium.webdriver.common.by import By\\n+from selenium.webdriver.firefox.options import Options as FirefoxOptions\\n+from selenium.webdriver.remote.webdriver import WebDriver\\n+from selenium.webdriver.safari.options import Options as SafariOptions\\n+from selenium.webdriver.support import expected_conditions as EC\\n+from selenium.webdriver.support.wait import WebDriverWait\\n+from webdriver_manager.chrome import ChromeDriverManager\\n+from webdriver_manager.firefox import GeckoDriverManager\\n+\\n+import processing.text as summary\\n+\\n+from config import Config\\n+from processing.html import extract_hyperlinks, format_hyperlinks\\n+\\n+from concurrent.futures import ThreadPoolExecutor\\n+executor = ThreadPoolExecutor()\\n+\\n+FILE_DIR = Path(__file__).parent.parent\\n+CFG = Config()\\n+\\n+async def async_browse(url: str, question: str) -&gt; str:\\n+    loop = asyncio.get_event_loop()\\n+\\n+    driver, text = await loop.run_in_executor(executor, scrape_text_with_selenium, url)\\n+    await loop.run_in_executor(executor, add_header, driver)\\n+    summary_text = await loop.run_in_executor(executor, summary.summarize_text, url, text, question, driver)\\n+\\n+    await loop.run_in_executor(executor, close_browser, driver)\\n+    return f\"Information gathered from url {url}: {summary_text}\"\\n+\\n+def browse_website(url: str, question: str) -&gt; tuple[str, WebDriver]:\\n+    \"\"\"Browse a website and return the answer and links to the user\\n+\\n+    Args:\\n+        url (str): The url of the website to browse\\n+        question (str): The question asked by the user\\n+\\n+    Returns:\\n+        Tuple[str, WebDriver]: The answer and links to the user and the webdriver\\n+    \"\"\"\\n+\\n+    if not url:\\n+        return \"A URL was not specified, cancelling request to browse website.\", None\\n+\\n+    driver, text = scrape_text_with_selenium(url)\\n+    add_header(driver)\\n+    summary_text = summary.summarize_text(url, text, question, driver)\\n+\\n+    links = scrape_links_with_selenium(driver, url)\\n+\\n+    # Limit links to 5\\n+    if len(links) &gt; 5:\\n+        links = links[:5]\\n+\\n+    # write_to_file('research-{0}.txt'.format(url), summary_text + \"\\nSource Links: {0}\\n\\n\".format(links))\\n+\\n+    close_browser(driver)\\n+    return f\"Answer gathered from website: {summary_text} \\n \\n Links: {links}\", driver\\n+\\n+\\n+def scrape_text_with_selenium(url: str) -&gt; tuple[WebDriver, str]:\\n+    \"\"\"Scrape text from a website using selenium\\n+\\n+    Args:\\n+        url (str): The url of the website to scrape\\n+\\n+    Returns:\\n+        Tuple[WebDriver, str]: The webdriver and the text scraped from the website\\n+    \"\"\"\\n+    print(\"Scraping text from website {0}...\".format(url))\\n+    logging.getLogger(\"selenium\").setLevel(logging.CRITICAL)\\n+\\n+    options_available = {\\n+        \"chrome\": ChromeOptions,\\n+        \"safari\": SafariOptions,\\n+        \"firefox\": FirefoxOptions,\\n+    }\\n+\\n+    options = options_available[CFG.selenium_web_browser]()\\n+    options.add_argument(\\n+        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.49 Safari/537.36\"\\n+    )\\n+    options.add_argument('--headless')\\n+\\n+    if CFG.selenium_web_browser == \"firefox\":\\n+        driver = webdriver.Firefox(\\n+            executable_path=GeckoDriverManager().install(), options=options\\n+        )\\n+    elif CFG.selenium_web_browser == \"safari\":\\n+        # Requires a bit more setup on the users end\\n+        # See https://developer.apple.com/documentation/webkit/testing_with_webdriver_in_safari\\n+        driver = webdriver.Safari(options=options)\\n+    else:\\n+        if platform == \"linux\" or platform == \"linux2\":\\n+            options.add_argument(\"--disable-dev-shm-usage\")\\n+            options.add_argument(\"--remote-debugging-port=9222\")\\n+        options.add_argument(\"--no-sandbox\")\\n+        driver = webdriver.Chrome(\\n+            executable_path=ChromeDriverManager().install(), options=options\\n+        )\\n+    driver.get(url)\\n+\\n+    WebDriverWait(driver, 10).until(\\n+        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\\n+    )\\n+\\n+    # Get the HTML content directly from the browser's DOM\\n+    page_source = driver.execute_script(\"return document.body.outerHTML;\")\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    #text = soup.get_text()\\n+    text = get_text(soup)\\n+\\n+    lines = (line.strip() for line in text.splitlines())\\n+    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\\n+    text = \"\\n\".join(chunk for chunk in chunks if chunk)\\n+    return driver, text\\n+\\n+def get_text(soup):\\n+    text = \"\"\\n+    tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'p']\\n+    for element in soup.find_all(tags):  # Find all the &lt;p&gt; elements\\n+        text += element.text + \"\\n\\n\"\\n+    return text\\n+\\n+def scrape_links_with_selenium(driver: WebDriver, url: str) -&gt; list[str]:\\n+    \"\"\"Scrape links from a website using selenium\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to scrape the links\\n+\\n+    Returns:\\n+        List[str]: The links scraped from the website\\n+    \"\"\"\\n+    page_source = driver.page_source\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    hyperlinks = extract_hyperlinks(soup, url)\\n+\\n+    return format_hyperlinks(hyperlinks)\\n+\\n+\\n+def close_browser(driver: WebDriver) -&gt; None:\\n+    \"\"\"Close the browser\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to close\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.quit()\\n+\\n+\\n+def add_header(driver: WebDriver) -&gt; None:\\n+    \"\"\"Add a header to the website\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to add the header\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.execute_script(open(f\"{FILE_DIR}/js/overlay.js\", \"r\").read())\\n</td>\n",
              "      <td>diff --git a/actions/web_scrape.py b/actions/web_scrape.py\\nnew file mode 100644\\nindex 00000000..f768357b\\n--- /dev/null\\n+++ b/actions/web_scrape.py\\n@@ -0,0 +1,181 @@\\n+\"\"\"Selenium web scraping module.\"\"\"\\n+from __future__ import annotations\\n+\\n+import logging\\n+import asyncio\\n+from pathlib import Path\\n+from sys import platform\\n+\\n+from bs4 import BeautifulSoup\\n+from selenium import webdriver\\n+from selenium.webdriver.chrome.options import Options as ChromeOptions\\n+from selenium.webdriver.common.by import By\\n+from selenium.webdriver.firefox.options import Options as FirefoxOptions\\n+from selenium.webdriver.remote.webdriver import WebDriver\\n+from selenium.webdriver.safari.options import Options as SafariOptions\\n+from selenium.webdriver.support import expected_conditions as EC\\n+from selenium.webdriver.support.wait import WebDriverWait\\n+from webdriver_manager.chrome import ChromeDriverManager\\n+from webdriver_manager.firefox import GeckoDriverManager\\n+\\n+import processing.text as summary\\n+\\n+from config import Config\\n+from processing.html import extract_hyperlinks, format_hyperlinks\\n+\\n+from concurrent.futures import ThreadPoolExecutor\\n+executor = ThreadPoolExecutor()\\n+\\n+FILE_DIR = Path(__file__).parent.parent\\n+CFG = Config()\\n+\\n+async def async_browse(url: str, question: str) -&gt; str:\\n+    loop = asyncio.get_event_loop()\\n+\\n+    driver, text = await loop.run_in_executor(executor, scrape_text_with_selenium, url)\\n+    await loop.run_in_executor(executor, add_header, driver)\\n+    summary_text = await loop.run_in_executor(executor, summary.summarize_text, url, text, question, driver)\\n+\\n+    await loop.run_in_executor(executor, close_browser, driver)\\n+    return f\"Information gathered from url {url}: {summary_text}\"\\n+\\n+def browse_website(url: str, question: str) -&gt; tuple[str, WebDriver]:\\n+    \"\"\"Browse a website and return the answer and links to the user\\n+\\n+    Args:\\n+        url (str): The url of the website to browse\\n+        question (str): The question asked by the user\\n+\\n+    Returns:\\n+        Tuple[str, WebDriver]: The answer and links to the user and the webdriver\\n+    \"\"\"\\n+\\n+    if not url:\\n+        return \"A URL was not specified, cancelling request to browse website.\", None\\n+\\n+    driver, text = scrape_text_with_selenium(url)\\n+    add_header(driver)\\n+    summary_text = summary.summarize_text(url, text, question, driver)\\n+\\n+    links = scrape_links_with_selenium(driver, url)\\n+\\n+    # Limit links to 5\\n+    if len(links) &gt; 5:\\n+        links = links[:5]\\n+\\n+    # write_to_file('research-{0}.txt'.format(url), summary_text + \"\\nSource Links: {0}\\n\\n\".format(links))\\n+\\n+    close_browser(driver)\\n+    return f\"Answer gathered from website: {summary_text} \\n \\n Links: {links}\", driver\\n+\\n+\\n+def scrape_text_with_selenium(url: str) -&gt; tuple[WebDriver, str]:\\n+    \"\"\"Scrape text from a website using selenium\\n+\\n+    Args:\\n+        url (str): The url of the website to scrape\\n+\\n+    Returns:\\n+        Tuple[WebDriver, str]: The webdriver and the text scraped from the website\\n+    \"\"\"\\n+    print(\"Scraping text from website {0}...\".format(url))\\n+    logging.getLogger(\"selenium\").setLevel(logging.CRITICAL)\\n+\\n+    options_available = {\\n+        \"chrome\": ChromeOptions,\\n+        \"safari\": SafariOptions,\\n+        \"firefox\": FirefoxOptions,\\n+    }\\n+\\n+    options = options_available[CFG.selenium_web_browser]()\\n+    options.add_argument(\\n+        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.49 Safari/537.36\"\\n+    )\\n+    options.add_argument('--headless')\\n+\\n+    if CFG.selenium_web_browser == \"firefox\":\\n+        driver = webdriver.Firefox(\\n+            executable_path=GeckoDriverManager().install(), options=options\\n+        )\\n+    elif CFG.selenium_web_browser == \"safari\":\\n+        # Requires a bit more setup on the users end\\n+        # See https://developer.apple.com/documentation/webkit/testing_with_webdriver_in_safari\\n+        driver = webdriver.Safari(options=options)\\n+    else:\\n+        if platform == \"linux\" or platform == \"linux2\":\\n+            options.add_argument(\"--disable-dev-shm-usage\")\\n+            options.add_argument(\"--remote-debugging-port=9222\")\\n+        options.add_argument(\"--no-sandbox\")\\n+        driver = webdriver.Chrome(\\n+            executable_path=ChromeDriverManager().install(), options=options\\n+        )\\n+    driver.get(url)\\n+\\n+    WebDriverWait(driver, 10).until(\\n+        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\\n+    )\\n+\\n+    # Get the HTML content directly from the browser's DOM\\n+    page_source = driver.execute_script(\"return document.body.outerHTML;\")\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    #text = soup.get_text()\\n+    text = get_text(soup)\\n+\\n+    lines = (line.strip() for line in text.splitlines())\\n+    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\\n+    text = \"\\n\".join(chunk for chunk in chunks if chunk)\\n+    return driver, text\\n+\\n+def get_text(soup):\\n+    text = \"\"\\n+    tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'p']\\n+    for element in soup.find_all(tags):  # Find all the &lt;p&gt; elements\\n+        text += element.text + \"\\n\\n\"\\n+    return text\\n+\\n+def scrape_links_with_selenium(driver: WebDriver, url: str) -&gt; list[str]:\\n+    \"\"\"Scrape links from a website using selenium\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to scrape the links\\n+\\n+    Returns:\\n+        List[str]: The links scraped from the website\\n+    \"\"\"\\n+    page_source = driver.page_source\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    hyperlinks = extract_hyperlinks(soup, url)\\n+\\n+    return format_hyperlinks(hyperlinks)\\n+\\n+\\n+def close_browser(driver: WebDriver) -&gt; None:\\n+    \"\"\"Close the browser\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to close\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.quit()\\n+\\n+\\n+def add_header(driver: WebDriver) -&gt; None:\\n+    \"\"\"Add a header to the website\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to add the header\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.execute_script(open(f\"{FILE_DIR}/js/overlay.js\", \"r\").read())\\n</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>flask</td>\n",
              "      <td>NaN</td>\n",
              "      <td>actions/web_search.py</td>\n",
              "      <td>653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d</td>\n",
              "      <td>e983f3a0d3e45ced42c0d309244a17cebfba32f4</td>\n",
              "      <td>added all base files</td>\n",
              "      <td>@@ -0,0 +1,25 @@\\n+from __future__ import annotations\\n+import json\\n+from duckduckgo_search import DDGS\\n+\\n+ddgs = DDGS()\\n+\\n+def web_search(query: str, num_results: int = 5) -&gt; str:\\n+    \"\"\"Useful for general internet search queries.\"\"\"\\n+    print(\"Searching with query {0}...\".format(query))\\n+    search_results = []\\n+    if not query:\\n+        return json.dumps(search_results)\\n+\\n+    results = ddgs.text(query)\\n+    if not results:\\n+        return json.dumps(search_results)\\n+\\n+    total_added = 0\\n+    for j in results:\\n+        search_results.append(j)\\n+        total_added += 1\\n+        if total_added &gt;= num_results:\\n+            break\\n+\\n+    return json.dumps(search_results, ensure_ascii=False, indent=4)\\n</td>\n",
              "      <td>diff --git a/actions/web_search.py b/actions/web_search.py\\nnew file mode 100644\\nindex 00000000..7385c6ff\\n--- /dev/null\\n+++ b/actions/web_search.py\\n@@ -0,0 +1,25 @@\\n+from __future__ import annotations\\n+import json\\n+from duckduckgo_search import DDGS\\n+\\n+ddgs = DDGS()\\n+\\n+def web_search(query: str, num_results: int = 5) -&gt; str:\\n+    \"\"\"Useful for general internet search queries.\"\"\"\\n+    print(\"Searching with query {0}...\".format(query))\\n+    search_results = []\\n+    if not query:\\n+        return json.dumps(search_results)\\n+\\n+    results = ddgs.text(query)\\n+    if not results:\\n+        return json.dumps(search_results)\\n+\\n+    total_added = 0\\n+    for j in results:\\n+        search_results.append(j)\\n+        total_added += 1\\n+        if total_added &gt;= num_results:\\n+            break\\n+\\n+    return json.dumps(search_results, ensure_ascii=False, indent=4)\\n</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>flask</td>\n",
              "      <td>NaN</td>\n",
              "      <td>agent/prompts.py</td>\n",
              "      <td>653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d</td>\n",
              "      <td>e983f3a0d3e45ced42c0d309244a17cebfba32f4</td>\n",
              "      <td>added all base files</td>\n",
              "      <td>@@ -0,0 +1,16 @@\\n+AGENT_ROLE_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"\\n+\\n+def generate_agent_role_prompt():\\n+    return AGENT_ROLE_PROMPT\\n+\\n+def generate_report_prompt(question, research_summary):\\n+    return f'\"\"\"{research_summary}\"\"\" Using the above information, answer the following'\\\\n+           f' question or topic: \"{question}\" in a detailed report --'\\\\n+           \" The report should focus on the answer to the question, should be well structured, \" \\\\n+           \"informative, in depth, with facts and numbers if available, a minimum of 1,200 words and with markdown syntax. \"\\\\n+            \"Write all source urls at the end of the report, including urls that weren't used (explain why you didn't use them).\"\\n+\\n+def generate_search_queries_prompt(question):\\n+    return f'Write 4 google search queries to search online that form an objective opinion from the following: \"{question}\"'\\\\n+           f'You must respond with a list of strings in the following format: [\"query 1\", \"query 2\", \"query 3\", \"query 4\"]'\\n+\\n</td>\n",
              "      <td>diff --git a/agent/prompts.py b/agent/prompts.py\\nnew file mode 100644\\nindex 00000000..705c096e\\n--- /dev/null\\n+++ b/agent/prompts.py\\n@@ -0,0 +1,16 @@\\n+AGENT_ROLE_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"\\n+\\n+def generate_agent_role_prompt():\\n+    return AGENT_ROLE_PROMPT\\n+\\n+def generate_report_prompt(question, research_summary):\\n+    return f'\"\"\"{research_summary}\"\"\" Using the above information, answer the following'\\\\n+           f' question or topic: \"{question}\" in a detailed report --'\\\\n+           \" The report should focus on the answer to the question, should be well structured, \" \\\\n+           \"informative, in depth, with facts and numbers if available, a minimum of 1,200 words and with markdown syntax. \"\\\\n+            \"Write all source urls at the end of the report, including urls that weren't used (explain why you didn't use them).\"\\n+\\n+def generate_search_queries_prompt(question):\\n+    return f'Write 4 google search queries to search online that form an objective opinion from the following: \"{question}\"'\\\\n+           f'You must respond with a list of strings in the following format: [\"query 1\", \"query 2\", \"query 3\", \"query 4\"]'\\n+\\n</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>flask</td>\n",
              "      <td>NaN</td>\n",
              "      <td>agent/research_assistant.py</td>\n",
              "      <td>653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d</td>\n",
              "      <td>e983f3a0d3e45ced42c0d309244a17cebfba32f4</td>\n",
              "      <td>added all base files</td>\n",
              "      <td>@@ -0,0 +1,102 @@\\n+import asyncio\\n+import json\\n+from actions.web_search import web_search\\n+from actions.web_scrape import async_browse\\n+from processing.text import write_to_file, create_message, create_chat_completion, md_to_pdf, read_txt_files\\n+from config import Config\\n+from agent import prompts\\n+import os\\n+\\n+CFG = Config()\\n+\\n+\\n+class ResearchAssistant:\\n+    def __init__(self, question):\\n+        self.question = question\\n+        self.visited_urls = set()\\n+        self.research_summary = \"\"\\n+        self.directory_name = question[:100] if len(question) &gt; 100 else question\\n+        self.dir_path = os.path.dirname(f\"./outputs/{self.directory_name}/\")\\n+\\n+    def summarize(self, text, topic):\\n+        messages = [create_message(text, topic)]\\n+        print(\"Summarizing text for query: \", text)\\n+        return create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+\\n+    def get_new_urls(self, url_set_input):\\n+        new_urls = []\\n+        for url in url_set_input:\\n+            if url not in self.visited_urls:\\n+                print(\"New url found: \", url)\\n+                self.visited_urls.add(url)\\n+                new_urls.append(url)\\n+        return new_urls\\n+\\n+    def create_search_queries(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_search_queries_prompt(self.question),\\n+        }]\\n+        result = create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+        print(f\"Search queries: {result}\")\\n+        return json.loads(result)\\n+\\n+    def write_report(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_report_prompt(self.question, self.research_summary),\\n+        }]\\n+        print(f\"Writing report for query: {self.question}...\")\\n+        answer = create_chat_completion(\\n+            model=\"gpt-4\",\\n+            messages=messages,\\n+            stream=True,\\n+        )\\n+        file_path = f\"./outputs/{self.directory_name}/report\"\\n+        write_to_file(f\"{file_path}.md\", answer)\\n+        md_to_pdf(f\"{file_path}.md\", f\"{file_path}.pdf\")\\n+        print(f\"Report written to {file_path}.pdf\")\\n+        return answer\\n+\\n+    async def async_search(self, query):\\n+        search_results = json.loads(web_search(query))\\n+        new_search_urls = self.get_new_urls([url.get(\"href\") for url in search_results])\\n+        tasks = [asyncio.create_task(async_browse(url, query)) for url in new_search_urls]\\n+        print(\"Visited urls: \", self.visited_urls)\\n+        return await asyncio.gather(*tasks)\\n+\\n+    def run_search_summary(self, query):\\n+        print(f\"Running research for {query}...\")\\n+        loop = asyncio.get_event_loop()\\n+        responses = loop.run_until_complete(self.async_search(query))\\n+\\n+        result = \"\\n\".join(responses)\\n+        os.makedirs(os.path.dirname(f\"./outputs/{self.directory_name}/research-{query}.txt\"), exist_ok=True)\\n+        write_to_file(f\"./outputs/{self.directory_name}/research-{query}.txt\", result)\\n+        return result\\n+\\n+    def conduct_research(self):\\n+        self.research_summary = read_txt_files(self.dir_path) if os.path.isdir(self.dir_path) else \"\"\\n+\\n+        if not self.research_summary:\\n+            search_queries = self.create_search_queries()  # + [self.question]\\n+            for query in search_queries:\\n+                research_result = self.run_search_summary(query)  # summarize(run_search_summary(query), query)\\n+                self.research_summary += f\"{research_result}\\n\\n\"  # f\"{query}\\n{research_result}\\n\\n\"\\n+                print(\"Research summary so far: \", self.research_summary)\\n+\\n+        print(self.research_summary)\\n+        print(\"Total research words: {0}\".format(len(self.research_summary.split(\" \"))))\\n+        return self.research_summary\\n\\ No newline at end of file\\n</td>\n",
              "      <td>diff --git a/agent/research_assistant.py b/agent/research_assistant.py\\nnew file mode 100644\\nindex 00000000..32554db4\\n--- /dev/null\\n+++ b/agent/research_assistant.py\\n@@ -0,0 +1,102 @@\\n+import asyncio\\n+import json\\n+from actions.web_search import web_search\\n+from actions.web_scrape import async_browse\\n+from processing.text import write_to_file, create_message, create_chat_completion, md_to_pdf, read_txt_files\\n+from config import Config\\n+from agent import prompts\\n+import os\\n+\\n+CFG = Config()\\n+\\n+\\n+class ResearchAssistant:\\n+    def __init__(self, question):\\n+        self.question = question\\n+        self.visited_urls = set()\\n+        self.research_summary = \"\"\\n+        self.directory_name = question[:100] if len(question) &gt; 100 else question\\n+        self.dir_path = os.path.dirname(f\"./outputs/{self.directory_name}/\")\\n+\\n+    def summarize(self, text, topic):\\n+        messages = [create_message(text, topic)]\\n+        print(\"Summarizing text for query: \", text)\\n+        return create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+\\n+    def get_new_urls(self, url_set_input):\\n+        new_urls = []\\n+        for url in url_set_input:\\n+            if url not in self.visited_urls:\\n+                print(\"New url found: \", url)\\n+                self.visited_urls.add(url)\\n+                new_urls.append(url)\\n+        return new_urls\\n+\\n+    def create_search_queries(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_search_queries_prompt(self.question),\\n+        }]\\n+        result = create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+        print(f\"Search queries: {result}\")\\n+        return json.loads(result)\\n+\\n+    def write_report(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_report_prompt(self.question, self.research_summary),\\n+        }]\\n+        print(f\"Writing report for query: {self.question}...\")\\n+        answer = create_chat_completion(\\n+            model=\"gpt-4\",\\n+            messages=messages,\\n+            stream=True,\\n+        )\\n+        file_path = f\"./outputs/{self.directory_name}/report\"\\n+        write_to_file(f\"{file_path}.md\", answer)\\n+        md_to_pdf(f\"{file_path}.md\", f\"{file_path}.pdf\")\\n+        print(f\"Report written to {file_path}.pdf\")\\n+        return answer\\n+\\n+    async def async_search(self, query):\\n+        search_results = json.loads(web_search(query))\\n+        new_search_urls = self.get_new_urls([url.get(\"href\") for url in search_results])\\n+        tasks = [asyncio.create_task(async_browse(url, query)) for url in new_search_urls]\\n+        print(\"Visited urls: \", self.visited_urls)\\n+        return await asyncio.gather(*tasks)\\n+\\n+    def run_search_summary(self, query):\\n+        print(f\"Running research for {query}...\")\\n+        loop = asyncio.get_event_loop()\\n+        responses = loop.run_until_complete(self.async_search(query))\\n+\\n+        result = \"\\n\".join(responses)\\n+        os.makedirs(os.path.dirname(f\"./outputs/{self.directory_name}/research-{query}.txt\"), exist_ok=True)\\n+        write_to_file(f\"./outputs/{self.directory_name}/research-{query}.txt\", result)\\n+        return result\\n+\\n+    def conduct_research(self):\\n+        self.research_summary = read_txt_files(self.dir_path) if os.path.isdir(self.dir_path) else \"\"\\n+\\n+        if not self.research_summary:\\n+            search_queries = self.create_search_queries()  # + [self.question]\\n+            for query in search_queries:\\n+                research_result = self.run_search_summary(query)  # summarize(run_search_summary(query), query)\\n+                self.research_summary += f\"{research_result}\\n\\n\"  # f\"{query}\\n{research_result}\\n\\n\"\\n+                print(\"Research summary so far: \", self.research_summary)\\n+\\n+        print(self.research_summary)\\n+        print(\"Total research words: {0}\".format(len(self.research_summary.split(\" \"))))\\n+        return self.research_summary\\n\\ No newline at end of file\\n</td>\n",
              "      <td>source</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-682f96b8-6eef-480d-9458-4748d16cd8f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-682f96b8-6eef-480d-9458-4748d16cd8f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-682f96b8-6eef-480d-9458-4748d16cd8f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fea9e22f-84d7-4f3d-886d-2b3e86f93b0d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fea9e22f-84d7-4f3d-886d-2b3e86f93b0d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fea9e22f-84d7-4f3d-886d-2b3e86f93b0d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/flask_final.csv\")\n",
        "pd.set_option(\"display.max_colwidth\", None)  # Show full commit messages and diffs\n",
        "display(df.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tOUOGYO7g9Vs",
        "outputId": "76aa1d17-6bc6-4ab0-b622-af7e3b40cab0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  repo_name old_file_path                new_file_path  \\\n",
              "0     flask           NaN                      LICENSE   \n",
              "1     flask           NaN        actions/web_scrape.py   \n",
              "2     flask           NaN        actions/web_search.py   \n",
              "3     flask           NaN             agent/prompts.py   \n",
              "4     flask           NaN  agent/research_assistant.py   \n",
              "\n",
              "                                 commit_sha  \\\n",
              "0  e983f3a0d3e45ced42c0d309244a17cebfba32f4   \n",
              "1  653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d   \n",
              "2  653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d   \n",
              "3  653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d   \n",
              "4  653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d   \n",
              "\n",
              "                          parent_commit_sha        commit_message  \\\n",
              "0                                       NaN        Initial commit   \n",
              "1  e983f3a0d3e45ced42c0d309244a17cebfba32f4  added all base files   \n",
              "2  e983f3a0d3e45ced42c0d309244a17cebfba32f4  added all base files   \n",
              "3  e983f3a0d3e45ced42c0d309244a17cebfba32f4  added all base files   \n",
              "4  e983f3a0d3e45ced42c0d309244a17cebfba32f4  added all base files   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          diff_myers  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          @@ -0,0 +1,21 @@\\n+MIT License\\n+\\n+Copyright (c) 2023 Assaf Elovic\\n+\\n+Permission is hereby granted, free of charge, to any person obtaining a copy\\n+of this software and associated documentation files (the \"Software\"), to deal\\n+in the Software without restriction, including without limitation the rights\\n+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\n+copies of the Software, and to permit persons to whom the Software is\\n+furnished to do so, subject to the following conditions:\\n+\\n+The above copyright notice and this permission notice shall be included in all\\n+copies or substantial portions of the Software.\\n+\\n+THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\n+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\n+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\n+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\n+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\n+SOFTWARE.\\n   \n",
              "1  @@ -0,0 +1,181 @@\\n+\"\"\"Selenium web scraping module.\"\"\"\\n+from __future__ import annotations\\n+\\n+import logging\\n+import asyncio\\n+from pathlib import Path\\n+from sys import platform\\n+\\n+from bs4 import BeautifulSoup\\n+from selenium import webdriver\\n+from selenium.webdriver.chrome.options import Options as ChromeOptions\\n+from selenium.webdriver.common.by import By\\n+from selenium.webdriver.firefox.options import Options as FirefoxOptions\\n+from selenium.webdriver.remote.webdriver import WebDriver\\n+from selenium.webdriver.safari.options import Options as SafariOptions\\n+from selenium.webdriver.support import expected_conditions as EC\\n+from selenium.webdriver.support.wait import WebDriverWait\\n+from webdriver_manager.chrome import ChromeDriverManager\\n+from webdriver_manager.firefox import GeckoDriverManager\\n+\\n+import processing.text as summary\\n+\\n+from config import Config\\n+from processing.html import extract_hyperlinks, format_hyperlinks\\n+\\n+from concurrent.futures import ThreadPoolExecutor\\n+executor = ThreadPoolExecutor()\\n+\\n+FILE_DIR = Path(__file__).parent.parent\\n+CFG = Config()\\n+\\n+async def async_browse(url: str, question: str) -> str:\\n+    loop = asyncio.get_event_loop()\\n+\\n+    driver, text = await loop.run_in_executor(executor, scrape_text_with_selenium, url)\\n+    await loop.run_in_executor(executor, add_header, driver)\\n+    summary_text = await loop.run_in_executor(executor, summary.summarize_text, url, text, question, driver)\\n+\\n+    await loop.run_in_executor(executor, close_browser, driver)\\n+    return f\"Information gathered from url {url}: {summary_text}\"\\n+\\n+def browse_website(url: str, question: str) -> tuple[str, WebDriver]:\\n+    \"\"\"Browse a website and return the answer and links to the user\\n+\\n+    Args:\\n+        url (str): The url of the website to browse\\n+        question (str): The question asked by the user\\n+\\n+    Returns:\\n+        Tuple[str, WebDriver]: The answer and links to the user and the webdriver\\n+    \"\"\"\\n+\\n+    if not url:\\n+        return \"A URL was not specified, cancelling request to browse website.\", None\\n+\\n+    driver, text = scrape_text_with_selenium(url)\\n+    add_header(driver)\\n+    summary_text = summary.summarize_text(url, text, question, driver)\\n+\\n+    links = scrape_links_with_selenium(driver, url)\\n+\\n+    # Limit links to 5\\n+    if len(links) > 5:\\n+        links = links[:5]\\n+\\n+    # write_to_file('research-{0}.txt'.format(url), summary_text + \"\\nSource Links: {0}\\n\\n\".format(links))\\n+\\n+    close_browser(driver)\\n+    return f\"Answer gathered from website: {summary_text} \\n \\n Links: {links}\", driver\\n+\\n+\\n+def scrape_text_with_selenium(url: str) -> tuple[WebDriver, str]:\\n+    \"\"\"Scrape text from a website using selenium\\n+\\n+    Args:\\n+        url (str): The url of the website to scrape\\n+\\n+    Returns:\\n+        Tuple[WebDriver, str]: The webdriver and the text scraped from the website\\n+    \"\"\"\\n+    print(\"Scraping text from website {0}...\".format(url))\\n+    logging.getLogger(\"selenium\").setLevel(logging.CRITICAL)\\n+\\n+    options_available = {\\n+        \"chrome\": ChromeOptions,\\n+        \"safari\": SafariOptions,\\n+        \"firefox\": FirefoxOptions,\\n+    }\\n+\\n+    options = options_available[CFG.selenium_web_browser]()\\n+    options.add_argument(\\n+        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.49 Safari/537.36\"\\n+    )\\n+    options.add_argument('--headless')\\n+\\n+    if CFG.selenium_web_browser == \"firefox\":\\n+        driver = webdriver.Firefox(\\n+            executable_path=GeckoDriverManager().install(), options=options\\n+        )\\n+    elif CFG.selenium_web_browser == \"safari\":\\n+        # Requires a bit more setup on the users end\\n+        # See https://developer.apple.com/documentation/webkit/testing_with_webdriver_in_safari\\n+        driver = webdriver.Safari(options=options)\\n+    else:\\n+        if platform == \"linux\" or platform == \"linux2\":\\n+            options.add_argument(\"--disable-dev-shm-usage\")\\n+            options.add_argument(\"--remote-debugging-port=9222\")\\n+        options.add_argument(\"--no-sandbox\")\\n+        driver = webdriver.Chrome(\\n+            executable_path=ChromeDriverManager().install(), options=options\\n+        )\\n+    driver.get(url)\\n+\\n+    WebDriverWait(driver, 10).until(\\n+        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\\n+    )\\n+\\n+    # Get the HTML content directly from the browser's DOM\\n+    page_source = driver.execute_script(\"return document.body.outerHTML;\")\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    #text = soup.get_text()\\n+    text = get_text(soup)\\n+\\n+    lines = (line.strip() for line in text.splitlines())\\n+    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\\n+    text = \"\\n\".join(chunk for chunk in chunks if chunk)\\n+    return driver, text\\n+\\n+def get_text(soup):\\n+    text = \"\"\\n+    tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'p']\\n+    for element in soup.find_all(tags):  # Find all the <p> elements\\n+        text += element.text + \"\\n\\n\"\\n+    return text\\n+\\n+def scrape_links_with_selenium(driver: WebDriver, url: str) -> list[str]:\\n+    \"\"\"Scrape links from a website using selenium\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to scrape the links\\n+\\n+    Returns:\\n+        List[str]: The links scraped from the website\\n+    \"\"\"\\n+    page_source = driver.page_source\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    hyperlinks = extract_hyperlinks(soup, url)\\n+\\n+    return format_hyperlinks(hyperlinks)\\n+\\n+\\n+def close_browser(driver: WebDriver) -> None:\\n+    \"\"\"Close the browser\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to close\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.quit()\\n+\\n+\\n+def add_header(driver: WebDriver) -> None:\\n+    \"\"\"Add a header to the website\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to add the header\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.execute_script(open(f\"{FILE_DIR}/js/overlay.js\", \"r\").read())\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  @@ -0,0 +1,25 @@\\n+from __future__ import annotations\\n+import json\\n+from duckduckgo_search import DDGS\\n+\\n+ddgs = DDGS()\\n+\\n+def web_search(query: str, num_results: int = 5) -> str:\\n+    \"\"\"Useful for general internet search queries.\"\"\"\\n+    print(\"Searching with query {0}...\".format(query))\\n+    search_results = []\\n+    if not query:\\n+        return json.dumps(search_results)\\n+\\n+    results = ddgs.text(query)\\n+    if not results:\\n+        return json.dumps(search_results)\\n+\\n+    total_added = 0\\n+    for j in results:\\n+        search_results.append(j)\\n+        total_added += 1\\n+        if total_added >= num_results:\\n+            break\\n+\\n+    return json.dumps(search_results, ensure_ascii=False, indent=4)\\n   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              @@ -0,0 +1,16 @@\\n+AGENT_ROLE_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"\\n+\\n+def generate_agent_role_prompt():\\n+    return AGENT_ROLE_PROMPT\\n+\\n+def generate_report_prompt(question, research_summary):\\n+    return f'\"\"\"{research_summary}\"\"\" Using the above information, answer the following'\\\\n+           f' question or topic: \"{question}\" in a detailed report --'\\\\n+           \" The report should focus on the answer to the question, should be well structured, \" \\\\n+           \"informative, in depth, with facts and numbers if available, a minimum of 1,200 words and with markdown syntax. \"\\\\n+            \"Write all source urls at the end of the report, including urls that weren't used (explain why you didn't use them).\"\\n+\\n+def generate_search_queries_prompt(question):\\n+    return f'Write 4 google search queries to search online that form an objective opinion from the following: \"{question}\"'\\\\n+           f'You must respond with a list of strings in the following format: [\"query 1\", \"query 2\", \"query 3\", \"query 4\"]'\\n+\\n   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  @@ -0,0 +1,102 @@\\n+import asyncio\\n+import json\\n+from actions.web_search import web_search\\n+from actions.web_scrape import async_browse\\n+from processing.text import write_to_file, create_message, create_chat_completion, md_to_pdf, read_txt_files\\n+from config import Config\\n+from agent import prompts\\n+import os\\n+\\n+CFG = Config()\\n+\\n+\\n+class ResearchAssistant:\\n+    def __init__(self, question):\\n+        self.question = question\\n+        self.visited_urls = set()\\n+        self.research_summary = \"\"\\n+        self.directory_name = question[:100] if len(question) > 100 else question\\n+        self.dir_path = os.path.dirname(f\"./outputs/{self.directory_name}/\")\\n+\\n+    def summarize(self, text, topic):\\n+        messages = [create_message(text, topic)]\\n+        print(\"Summarizing text for query: \", text)\\n+        return create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+\\n+    def get_new_urls(self, url_set_input):\\n+        new_urls = []\\n+        for url in url_set_input:\\n+            if url not in self.visited_urls:\\n+                print(\"New url found: \", url)\\n+                self.visited_urls.add(url)\\n+                new_urls.append(url)\\n+        return new_urls\\n+\\n+    def create_search_queries(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_search_queries_prompt(self.question),\\n+        }]\\n+        result = create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+        print(f\"Search queries: {result}\")\\n+        return json.loads(result)\\n+\\n+    def write_report(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_report_prompt(self.question, self.research_summary),\\n+        }]\\n+        print(f\"Writing report for query: {self.question}...\")\\n+        answer = create_chat_completion(\\n+            model=\"gpt-4\",\\n+            messages=messages,\\n+            stream=True,\\n+        )\\n+        file_path = f\"./outputs/{self.directory_name}/report\"\\n+        write_to_file(f\"{file_path}.md\", answer)\\n+        md_to_pdf(f\"{file_path}.md\", f\"{file_path}.pdf\")\\n+        print(f\"Report written to {file_path}.pdf\")\\n+        return answer\\n+\\n+    async def async_search(self, query):\\n+        search_results = json.loads(web_search(query))\\n+        new_search_urls = self.get_new_urls([url.get(\"href\") for url in search_results])\\n+        tasks = [asyncio.create_task(async_browse(url, query)) for url in new_search_urls]\\n+        print(\"Visited urls: \", self.visited_urls)\\n+        return await asyncio.gather(*tasks)\\n+\\n+    def run_search_summary(self, query):\\n+        print(f\"Running research for {query}...\")\\n+        loop = asyncio.get_event_loop()\\n+        responses = loop.run_until_complete(self.async_search(query))\\n+\\n+        result = \"\\n\".join(responses)\\n+        os.makedirs(os.path.dirname(f\"./outputs/{self.directory_name}/research-{query}.txt\"), exist_ok=True)\\n+        write_to_file(f\"./outputs/{self.directory_name}/research-{query}.txt\", result)\\n+        return result\\n+\\n+    def conduct_research(self):\\n+        self.research_summary = read_txt_files(self.dir_path) if os.path.isdir(self.dir_path) else \"\"\\n+\\n+        if not self.research_summary:\\n+            search_queries = self.create_search_queries()  # + [self.question]\\n+            for query in search_queries:\\n+                research_result = self.run_search_summary(query)  # summarize(run_search_summary(query), query)\\n+                self.research_summary += f\"{research_result}\\n\\n\"  # f\"{query}\\n{research_result}\\n\\n\"\\n+                print(\"Research summary so far: \", self.research_summary)\\n+\\n+        print(self.research_summary)\\n+        print(\"Total research words: {0}\".format(len(self.research_summary.split(\" \"))))\\n+        return self.research_summary\\n\\ No newline at end of file\\n   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   diff_hist  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Command '['git', '-C', 'gpt_researcher', 'diff', '--histogram', 'e983f3a0d3e45ced42c0d309244a17cebfba32f4^', 'e983f3a0d3e45ced42c0d309244a17cebfba32f4', '--', 'LICENSE']' returned non-zero exit status 128.   \n",
              "1  diff --git a/actions/web_scrape.py b/actions/web_scrape.py\\nnew file mode 100644\\nindex 00000000..f768357b\\n--- /dev/null\\n+++ b/actions/web_scrape.py\\n@@ -0,0 +1,181 @@\\n+\"\"\"Selenium web scraping module.\"\"\"\\n+from __future__ import annotations\\n+\\n+import logging\\n+import asyncio\\n+from pathlib import Path\\n+from sys import platform\\n+\\n+from bs4 import BeautifulSoup\\n+from selenium import webdriver\\n+from selenium.webdriver.chrome.options import Options as ChromeOptions\\n+from selenium.webdriver.common.by import By\\n+from selenium.webdriver.firefox.options import Options as FirefoxOptions\\n+from selenium.webdriver.remote.webdriver import WebDriver\\n+from selenium.webdriver.safari.options import Options as SafariOptions\\n+from selenium.webdriver.support import expected_conditions as EC\\n+from selenium.webdriver.support.wait import WebDriverWait\\n+from webdriver_manager.chrome import ChromeDriverManager\\n+from webdriver_manager.firefox import GeckoDriverManager\\n+\\n+import processing.text as summary\\n+\\n+from config import Config\\n+from processing.html import extract_hyperlinks, format_hyperlinks\\n+\\n+from concurrent.futures import ThreadPoolExecutor\\n+executor = ThreadPoolExecutor()\\n+\\n+FILE_DIR = Path(__file__).parent.parent\\n+CFG = Config()\\n+\\n+async def async_browse(url: str, question: str) -> str:\\n+    loop = asyncio.get_event_loop()\\n+\\n+    driver, text = await loop.run_in_executor(executor, scrape_text_with_selenium, url)\\n+    await loop.run_in_executor(executor, add_header, driver)\\n+    summary_text = await loop.run_in_executor(executor, summary.summarize_text, url, text, question, driver)\\n+\\n+    await loop.run_in_executor(executor, close_browser, driver)\\n+    return f\"Information gathered from url {url}: {summary_text}\"\\n+\\n+def browse_website(url: str, question: str) -> tuple[str, WebDriver]:\\n+    \"\"\"Browse a website and return the answer and links to the user\\n+\\n+    Args:\\n+        url (str): The url of the website to browse\\n+        question (str): The question asked by the user\\n+\\n+    Returns:\\n+        Tuple[str, WebDriver]: The answer and links to the user and the webdriver\\n+    \"\"\"\\n+\\n+    if not url:\\n+        return \"A URL was not specified, cancelling request to browse website.\", None\\n+\\n+    driver, text = scrape_text_with_selenium(url)\\n+    add_header(driver)\\n+    summary_text = summary.summarize_text(url, text, question, driver)\\n+\\n+    links = scrape_links_with_selenium(driver, url)\\n+\\n+    # Limit links to 5\\n+    if len(links) > 5:\\n+        links = links[:5]\\n+\\n+    # write_to_file('research-{0}.txt'.format(url), summary_text + \"\\nSource Links: {0}\\n\\n\".format(links))\\n+\\n+    close_browser(driver)\\n+    return f\"Answer gathered from website: {summary_text} \\n \\n Links: {links}\", driver\\n+\\n+\\n+def scrape_text_with_selenium(url: str) -> tuple[WebDriver, str]:\\n+    \"\"\"Scrape text from a website using selenium\\n+\\n+    Args:\\n+        url (str): The url of the website to scrape\\n+\\n+    Returns:\\n+        Tuple[WebDriver, str]: The webdriver and the text scraped from the website\\n+    \"\"\"\\n+    print(\"Scraping text from website {0}...\".format(url))\\n+    logging.getLogger(\"selenium\").setLevel(logging.CRITICAL)\\n+\\n+    options_available = {\\n+        \"chrome\": ChromeOptions,\\n+        \"safari\": SafariOptions,\\n+        \"firefox\": FirefoxOptions,\\n+    }\\n+\\n+    options = options_available[CFG.selenium_web_browser]()\\n+    options.add_argument(\\n+        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.49 Safari/537.36\"\\n+    )\\n+    options.add_argument('--headless')\\n+\\n+    if CFG.selenium_web_browser == \"firefox\":\\n+        driver = webdriver.Firefox(\\n+            executable_path=GeckoDriverManager().install(), options=options\\n+        )\\n+    elif CFG.selenium_web_browser == \"safari\":\\n+        # Requires a bit more setup on the users end\\n+        # See https://developer.apple.com/documentation/webkit/testing_with_webdriver_in_safari\\n+        driver = webdriver.Safari(options=options)\\n+    else:\\n+        if platform == \"linux\" or platform == \"linux2\":\\n+            options.add_argument(\"--disable-dev-shm-usage\")\\n+            options.add_argument(\"--remote-debugging-port=9222\")\\n+        options.add_argument(\"--no-sandbox\")\\n+        driver = webdriver.Chrome(\\n+            executable_path=ChromeDriverManager().install(), options=options\\n+        )\\n+    driver.get(url)\\n+\\n+    WebDriverWait(driver, 10).until(\\n+        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\\n+    )\\n+\\n+    # Get the HTML content directly from the browser's DOM\\n+    page_source = driver.execute_script(\"return document.body.outerHTML;\")\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    #text = soup.get_text()\\n+    text = get_text(soup)\\n+\\n+    lines = (line.strip() for line in text.splitlines())\\n+    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\\n+    text = \"\\n\".join(chunk for chunk in chunks if chunk)\\n+    return driver, text\\n+\\n+def get_text(soup):\\n+    text = \"\"\\n+    tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'p']\\n+    for element in soup.find_all(tags):  # Find all the <p> elements\\n+        text += element.text + \"\\n\\n\"\\n+    return text\\n+\\n+def scrape_links_with_selenium(driver: WebDriver, url: str) -> list[str]:\\n+    \"\"\"Scrape links from a website using selenium\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to scrape the links\\n+\\n+    Returns:\\n+        List[str]: The links scraped from the website\\n+    \"\"\"\\n+    page_source = driver.page_source\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    hyperlinks = extract_hyperlinks(soup, url)\\n+\\n+    return format_hyperlinks(hyperlinks)\\n+\\n+\\n+def close_browser(driver: WebDriver) -> None:\\n+    \"\"\"Close the browser\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to close\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.quit()\\n+\\n+\\n+def add_header(driver: WebDriver) -> None:\\n+    \"\"\"Add a header to the website\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to add the header\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.execute_script(open(f\"{FILE_DIR}/js/overlay.js\", \"r\").read())\\n   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  diff --git a/actions/web_search.py b/actions/web_search.py\\nnew file mode 100644\\nindex 00000000..7385c6ff\\n--- /dev/null\\n+++ b/actions/web_search.py\\n@@ -0,0 +1,25 @@\\n+from __future__ import annotations\\n+import json\\n+from duckduckgo_search import DDGS\\n+\\n+ddgs = DDGS()\\n+\\n+def web_search(query: str, num_results: int = 5) -> str:\\n+    \"\"\"Useful for general internet search queries.\"\"\"\\n+    print(\"Searching with query {0}...\".format(query))\\n+    search_results = []\\n+    if not query:\\n+        return json.dumps(search_results)\\n+\\n+    results = ddgs.text(query)\\n+    if not results:\\n+        return json.dumps(search_results)\\n+\\n+    total_added = 0\\n+    for j in results:\\n+        search_results.append(j)\\n+        total_added += 1\\n+        if total_added >= num_results:\\n+            break\\n+\\n+    return json.dumps(search_results, ensure_ascii=False, indent=4)\\n   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             diff --git a/agent/prompts.py b/agent/prompts.py\\nnew file mode 100644\\nindex 00000000..705c096e\\n--- /dev/null\\n+++ b/agent/prompts.py\\n@@ -0,0 +1,16 @@\\n+AGENT_ROLE_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"\\n+\\n+def generate_agent_role_prompt():\\n+    return AGENT_ROLE_PROMPT\\n+\\n+def generate_report_prompt(question, research_summary):\\n+    return f'\"\"\"{research_summary}\"\"\" Using the above information, answer the following'\\\\n+           f' question or topic: \"{question}\" in a detailed report --'\\\\n+           \" The report should focus on the answer to the question, should be well structured, \" \\\\n+           \"informative, in depth, with facts and numbers if available, a minimum of 1,200 words and with markdown syntax. \"\\\\n+            \"Write all source urls at the end of the report, including urls that weren't used (explain why you didn't use them).\"\\n+\\n+def generate_search_queries_prompt(question):\\n+    return f'Write 4 google search queries to search online that form an objective opinion from the following: \"{question}\"'\\\\n+           f'You must respond with a list of strings in the following format: [\"query 1\", \"query 2\", \"query 3\", \"query 4\"]'\\n+\\n   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                diff --git a/agent/research_assistant.py b/agent/research_assistant.py\\nnew file mode 100644\\nindex 00000000..32554db4\\n--- /dev/null\\n+++ b/agent/research_assistant.py\\n@@ -0,0 +1,102 @@\\n+import asyncio\\n+import json\\n+from actions.web_search import web_search\\n+from actions.web_scrape import async_browse\\n+from processing.text import write_to_file, create_message, create_chat_completion, md_to_pdf, read_txt_files\\n+from config import Config\\n+from agent import prompts\\n+import os\\n+\\n+CFG = Config()\\n+\\n+\\n+class ResearchAssistant:\\n+    def __init__(self, question):\\n+        self.question = question\\n+        self.visited_urls = set()\\n+        self.research_summary = \"\"\\n+        self.directory_name = question[:100] if len(question) > 100 else question\\n+        self.dir_path = os.path.dirname(f\"./outputs/{self.directory_name}/\")\\n+\\n+    def summarize(self, text, topic):\\n+        messages = [create_message(text, topic)]\\n+        print(\"Summarizing text for query: \", text)\\n+        return create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+\\n+    def get_new_urls(self, url_set_input):\\n+        new_urls = []\\n+        for url in url_set_input:\\n+            if url not in self.visited_urls:\\n+                print(\"New url found: \", url)\\n+                self.visited_urls.add(url)\\n+                new_urls.append(url)\\n+        return new_urls\\n+\\n+    def create_search_queries(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_search_queries_prompt(self.question),\\n+        }]\\n+        result = create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+        print(f\"Search queries: {result}\")\\n+        return json.loads(result)\\n+\\n+    def write_report(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_report_prompt(self.question, self.research_summary),\\n+        }]\\n+        print(f\"Writing report for query: {self.question}...\")\\n+        answer = create_chat_completion(\\n+            model=\"gpt-4\",\\n+            messages=messages,\\n+            stream=True,\\n+        )\\n+        file_path = f\"./outputs/{self.directory_name}/report\"\\n+        write_to_file(f\"{file_path}.md\", answer)\\n+        md_to_pdf(f\"{file_path}.md\", f\"{file_path}.pdf\")\\n+        print(f\"Report written to {file_path}.pdf\")\\n+        return answer\\n+\\n+    async def async_search(self, query):\\n+        search_results = json.loads(web_search(query))\\n+        new_search_urls = self.get_new_urls([url.get(\"href\") for url in search_results])\\n+        tasks = [asyncio.create_task(async_browse(url, query)) for url in new_search_urls]\\n+        print(\"Visited urls: \", self.visited_urls)\\n+        return await asyncio.gather(*tasks)\\n+\\n+    def run_search_summary(self, query):\\n+        print(f\"Running research for {query}...\")\\n+        loop = asyncio.get_event_loop()\\n+        responses = loop.run_until_complete(self.async_search(query))\\n+\\n+        result = \"\\n\".join(responses)\\n+        os.makedirs(os.path.dirname(f\"./outputs/{self.directory_name}/research-{query}.txt\"), exist_ok=True)\\n+        write_to_file(f\"./outputs/{self.directory_name}/research-{query}.txt\", result)\\n+        return result\\n+\\n+    def conduct_research(self):\\n+        self.research_summary = read_txt_files(self.dir_path) if os.path.isdir(self.dir_path) else \"\"\\n+\\n+        if not self.research_summary:\\n+            search_queries = self.create_search_queries()  # + [self.question]\\n+            for query in search_queries:\\n+                research_result = self.run_search_summary(query)  # summarize(run_search_summary(query), query)\\n+                self.research_summary += f\"{research_result}\\n\\n\"  # f\"{query}\\n{research_result}\\n\\n\"\\n+                print(\"Research summary so far: \", self.research_summary)\\n+\\n+        print(self.research_summary)\\n+        print(\"Total research words: {0}\".format(len(self.research_summary.split(\" \"))))\\n+        return self.research_summary\\n\\ No newline at end of file\\n   \n",
              "\n",
              "  file_type Discrepancy  \n",
              "0   license         Yes  \n",
              "1    source         Yes  \n",
              "2    source         Yes  \n",
              "3    source         Yes  \n",
              "4    source         Yes  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45c72861-2c07-44e8-9e35-213ef2452014\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo_name</th>\n",
              "      <th>old_file_path</th>\n",
              "      <th>new_file_path</th>\n",
              "      <th>commit_sha</th>\n",
              "      <th>parent_commit_sha</th>\n",
              "      <th>commit_message</th>\n",
              "      <th>diff_myers</th>\n",
              "      <th>diff_hist</th>\n",
              "      <th>file_type</th>\n",
              "      <th>Discrepancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>flask</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LICENSE</td>\n",
              "      <td>e983f3a0d3e45ced42c0d309244a17cebfba32f4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initial commit</td>\n",
              "      <td>@@ -0,0 +1,21 @@\\n+MIT License\\n+\\n+Copyright (c) 2023 Assaf Elovic\\n+\\n+Permission is hereby granted, free of charge, to any person obtaining a copy\\n+of this software and associated documentation files (the \"Software\"), to deal\\n+in the Software without restriction, including without limitation the rights\\n+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\n+copies of the Software, and to permit persons to whom the Software is\\n+furnished to do so, subject to the following conditions:\\n+\\n+The above copyright notice and this permission notice shall be included in all\\n+copies or substantial portions of the Software.\\n+\\n+THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\n+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\n+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\n+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\n+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\n+SOFTWARE.\\n</td>\n",
              "      <td>Command '['git', '-C', 'gpt_researcher', 'diff', '--histogram', 'e983f3a0d3e45ced42c0d309244a17cebfba32f4^', 'e983f3a0d3e45ced42c0d309244a17cebfba32f4', '--', 'LICENSE']' returned non-zero exit status 128.</td>\n",
              "      <td>license</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>flask</td>\n",
              "      <td>NaN</td>\n",
              "      <td>actions/web_scrape.py</td>\n",
              "      <td>653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d</td>\n",
              "      <td>e983f3a0d3e45ced42c0d309244a17cebfba32f4</td>\n",
              "      <td>added all base files</td>\n",
              "      <td>@@ -0,0 +1,181 @@\\n+\"\"\"Selenium web scraping module.\"\"\"\\n+from __future__ import annotations\\n+\\n+import logging\\n+import asyncio\\n+from pathlib import Path\\n+from sys import platform\\n+\\n+from bs4 import BeautifulSoup\\n+from selenium import webdriver\\n+from selenium.webdriver.chrome.options import Options as ChromeOptions\\n+from selenium.webdriver.common.by import By\\n+from selenium.webdriver.firefox.options import Options as FirefoxOptions\\n+from selenium.webdriver.remote.webdriver import WebDriver\\n+from selenium.webdriver.safari.options import Options as SafariOptions\\n+from selenium.webdriver.support import expected_conditions as EC\\n+from selenium.webdriver.support.wait import WebDriverWait\\n+from webdriver_manager.chrome import ChromeDriverManager\\n+from webdriver_manager.firefox import GeckoDriverManager\\n+\\n+import processing.text as summary\\n+\\n+from config import Config\\n+from processing.html import extract_hyperlinks, format_hyperlinks\\n+\\n+from concurrent.futures import ThreadPoolExecutor\\n+executor = ThreadPoolExecutor()\\n+\\n+FILE_DIR = Path(__file__).parent.parent\\n+CFG = Config()\\n+\\n+async def async_browse(url: str, question: str) -&gt; str:\\n+    loop = asyncio.get_event_loop()\\n+\\n+    driver, text = await loop.run_in_executor(executor, scrape_text_with_selenium, url)\\n+    await loop.run_in_executor(executor, add_header, driver)\\n+    summary_text = await loop.run_in_executor(executor, summary.summarize_text, url, text, question, driver)\\n+\\n+    await loop.run_in_executor(executor, close_browser, driver)\\n+    return f\"Information gathered from url {url}: {summary_text}\"\\n+\\n+def browse_website(url: str, question: str) -&gt; tuple[str, WebDriver]:\\n+    \"\"\"Browse a website and return the answer and links to the user\\n+\\n+    Args:\\n+        url (str): The url of the website to browse\\n+        question (str): The question asked by the user\\n+\\n+    Returns:\\n+        Tuple[str, WebDriver]: The answer and links to the user and the webdriver\\n+    \"\"\"\\n+\\n+    if not url:\\n+        return \"A URL was not specified, cancelling request to browse website.\", None\\n+\\n+    driver, text = scrape_text_with_selenium(url)\\n+    add_header(driver)\\n+    summary_text = summary.summarize_text(url, text, question, driver)\\n+\\n+    links = scrape_links_with_selenium(driver, url)\\n+\\n+    # Limit links to 5\\n+    if len(links) &gt; 5:\\n+        links = links[:5]\\n+\\n+    # write_to_file('research-{0}.txt'.format(url), summary_text + \"\\nSource Links: {0}\\n\\n\".format(links))\\n+\\n+    close_browser(driver)\\n+    return f\"Answer gathered from website: {summary_text} \\n \\n Links: {links}\", driver\\n+\\n+\\n+def scrape_text_with_selenium(url: str) -&gt; tuple[WebDriver, str]:\\n+    \"\"\"Scrape text from a website using selenium\\n+\\n+    Args:\\n+        url (str): The url of the website to scrape\\n+\\n+    Returns:\\n+        Tuple[WebDriver, str]: The webdriver and the text scraped from the website\\n+    \"\"\"\\n+    print(\"Scraping text from website {0}...\".format(url))\\n+    logging.getLogger(\"selenium\").setLevel(logging.CRITICAL)\\n+\\n+    options_available = {\\n+        \"chrome\": ChromeOptions,\\n+        \"safari\": SafariOptions,\\n+        \"firefox\": FirefoxOptions,\\n+    }\\n+\\n+    options = options_available[CFG.selenium_web_browser]()\\n+    options.add_argument(\\n+        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.49 Safari/537.36\"\\n+    )\\n+    options.add_argument('--headless')\\n+\\n+    if CFG.selenium_web_browser == \"firefox\":\\n+        driver = webdriver.Firefox(\\n+            executable_path=GeckoDriverManager().install(), options=options\\n+        )\\n+    elif CFG.selenium_web_browser == \"safari\":\\n+        # Requires a bit more setup on the users end\\n+        # See https://developer.apple.com/documentation/webkit/testing_with_webdriver_in_safari\\n+        driver = webdriver.Safari(options=options)\\n+    else:\\n+        if platform == \"linux\" or platform == \"linux2\":\\n+            options.add_argument(\"--disable-dev-shm-usage\")\\n+            options.add_argument(\"--remote-debugging-port=9222\")\\n+        options.add_argument(\"--no-sandbox\")\\n+        driver = webdriver.Chrome(\\n+            executable_path=ChromeDriverManager().install(), options=options\\n+        )\\n+    driver.get(url)\\n+\\n+    WebDriverWait(driver, 10).until(\\n+        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\\n+    )\\n+\\n+    # Get the HTML content directly from the browser's DOM\\n+    page_source = driver.execute_script(\"return document.body.outerHTML;\")\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    #text = soup.get_text()\\n+    text = get_text(soup)\\n+\\n+    lines = (line.strip() for line in text.splitlines())\\n+    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\\n+    text = \"\\n\".join(chunk for chunk in chunks if chunk)\\n+    return driver, text\\n+\\n+def get_text(soup):\\n+    text = \"\"\\n+    tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'p']\\n+    for element in soup.find_all(tags):  # Find all the &lt;p&gt; elements\\n+        text += element.text + \"\\n\\n\"\\n+    return text\\n+\\n+def scrape_links_with_selenium(driver: WebDriver, url: str) -&gt; list[str]:\\n+    \"\"\"Scrape links from a website using selenium\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to scrape the links\\n+\\n+    Returns:\\n+        List[str]: The links scraped from the website\\n+    \"\"\"\\n+    page_source = driver.page_source\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    hyperlinks = extract_hyperlinks(soup, url)\\n+\\n+    return format_hyperlinks(hyperlinks)\\n+\\n+\\n+def close_browser(driver: WebDriver) -&gt; None:\\n+    \"\"\"Close the browser\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to close\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.quit()\\n+\\n+\\n+def add_header(driver: WebDriver) -&gt; None:\\n+    \"\"\"Add a header to the website\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to add the header\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.execute_script(open(f\"{FILE_DIR}/js/overlay.js\", \"r\").read())\\n</td>\n",
              "      <td>diff --git a/actions/web_scrape.py b/actions/web_scrape.py\\nnew file mode 100644\\nindex 00000000..f768357b\\n--- /dev/null\\n+++ b/actions/web_scrape.py\\n@@ -0,0 +1,181 @@\\n+\"\"\"Selenium web scraping module.\"\"\"\\n+from __future__ import annotations\\n+\\n+import logging\\n+import asyncio\\n+from pathlib import Path\\n+from sys import platform\\n+\\n+from bs4 import BeautifulSoup\\n+from selenium import webdriver\\n+from selenium.webdriver.chrome.options import Options as ChromeOptions\\n+from selenium.webdriver.common.by import By\\n+from selenium.webdriver.firefox.options import Options as FirefoxOptions\\n+from selenium.webdriver.remote.webdriver import WebDriver\\n+from selenium.webdriver.safari.options import Options as SafariOptions\\n+from selenium.webdriver.support import expected_conditions as EC\\n+from selenium.webdriver.support.wait import WebDriverWait\\n+from webdriver_manager.chrome import ChromeDriverManager\\n+from webdriver_manager.firefox import GeckoDriverManager\\n+\\n+import processing.text as summary\\n+\\n+from config import Config\\n+from processing.html import extract_hyperlinks, format_hyperlinks\\n+\\n+from concurrent.futures import ThreadPoolExecutor\\n+executor = ThreadPoolExecutor()\\n+\\n+FILE_DIR = Path(__file__).parent.parent\\n+CFG = Config()\\n+\\n+async def async_browse(url: str, question: str) -&gt; str:\\n+    loop = asyncio.get_event_loop()\\n+\\n+    driver, text = await loop.run_in_executor(executor, scrape_text_with_selenium, url)\\n+    await loop.run_in_executor(executor, add_header, driver)\\n+    summary_text = await loop.run_in_executor(executor, summary.summarize_text, url, text, question, driver)\\n+\\n+    await loop.run_in_executor(executor, close_browser, driver)\\n+    return f\"Information gathered from url {url}: {summary_text}\"\\n+\\n+def browse_website(url: str, question: str) -&gt; tuple[str, WebDriver]:\\n+    \"\"\"Browse a website and return the answer and links to the user\\n+\\n+    Args:\\n+        url (str): The url of the website to browse\\n+        question (str): The question asked by the user\\n+\\n+    Returns:\\n+        Tuple[str, WebDriver]: The answer and links to the user and the webdriver\\n+    \"\"\"\\n+\\n+    if not url:\\n+        return \"A URL was not specified, cancelling request to browse website.\", None\\n+\\n+    driver, text = scrape_text_with_selenium(url)\\n+    add_header(driver)\\n+    summary_text = summary.summarize_text(url, text, question, driver)\\n+\\n+    links = scrape_links_with_selenium(driver, url)\\n+\\n+    # Limit links to 5\\n+    if len(links) &gt; 5:\\n+        links = links[:5]\\n+\\n+    # write_to_file('research-{0}.txt'.format(url), summary_text + \"\\nSource Links: {0}\\n\\n\".format(links))\\n+\\n+    close_browser(driver)\\n+    return f\"Answer gathered from website: {summary_text} \\n \\n Links: {links}\", driver\\n+\\n+\\n+def scrape_text_with_selenium(url: str) -&gt; tuple[WebDriver, str]:\\n+    \"\"\"Scrape text from a website using selenium\\n+\\n+    Args:\\n+        url (str): The url of the website to scrape\\n+\\n+    Returns:\\n+        Tuple[WebDriver, str]: The webdriver and the text scraped from the website\\n+    \"\"\"\\n+    print(\"Scraping text from website {0}...\".format(url))\\n+    logging.getLogger(\"selenium\").setLevel(logging.CRITICAL)\\n+\\n+    options_available = {\\n+        \"chrome\": ChromeOptions,\\n+        \"safari\": SafariOptions,\\n+        \"firefox\": FirefoxOptions,\\n+    }\\n+\\n+    options = options_available[CFG.selenium_web_browser]()\\n+    options.add_argument(\\n+        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.49 Safari/537.36\"\\n+    )\\n+    options.add_argument('--headless')\\n+\\n+    if CFG.selenium_web_browser == \"firefox\":\\n+        driver = webdriver.Firefox(\\n+            executable_path=GeckoDriverManager().install(), options=options\\n+        )\\n+    elif CFG.selenium_web_browser == \"safari\":\\n+        # Requires a bit more setup on the users end\\n+        # See https://developer.apple.com/documentation/webkit/testing_with_webdriver_in_safari\\n+        driver = webdriver.Safari(options=options)\\n+    else:\\n+        if platform == \"linux\" or platform == \"linux2\":\\n+            options.add_argument(\"--disable-dev-shm-usage\")\\n+            options.add_argument(\"--remote-debugging-port=9222\")\\n+        options.add_argument(\"--no-sandbox\")\\n+        driver = webdriver.Chrome(\\n+            executable_path=ChromeDriverManager().install(), options=options\\n+        )\\n+    driver.get(url)\\n+\\n+    WebDriverWait(driver, 10).until(\\n+        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\\n+    )\\n+\\n+    # Get the HTML content directly from the browser's DOM\\n+    page_source = driver.execute_script(\"return document.body.outerHTML;\")\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    #text = soup.get_text()\\n+    text = get_text(soup)\\n+\\n+    lines = (line.strip() for line in text.splitlines())\\n+    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\\n+    text = \"\\n\".join(chunk for chunk in chunks if chunk)\\n+    return driver, text\\n+\\n+def get_text(soup):\\n+    text = \"\"\\n+    tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'p']\\n+    for element in soup.find_all(tags):  # Find all the &lt;p&gt; elements\\n+        text += element.text + \"\\n\\n\"\\n+    return text\\n+\\n+def scrape_links_with_selenium(driver: WebDriver, url: str) -&gt; list[str]:\\n+    \"\"\"Scrape links from a website using selenium\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to scrape the links\\n+\\n+    Returns:\\n+        List[str]: The links scraped from the website\\n+    \"\"\"\\n+    page_source = driver.page_source\\n+    soup = BeautifulSoup(page_source, \"html.parser\")\\n+\\n+    for script in soup([\"script\", \"style\"]):\\n+        script.extract()\\n+\\n+    hyperlinks = extract_hyperlinks(soup, url)\\n+\\n+    return format_hyperlinks(hyperlinks)\\n+\\n+\\n+def close_browser(driver: WebDriver) -&gt; None:\\n+    \"\"\"Close the browser\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to close\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.quit()\\n+\\n+\\n+def add_header(driver: WebDriver) -&gt; None:\\n+    \"\"\"Add a header to the website\\n+\\n+    Args:\\n+        driver (WebDriver): The webdriver to use to add the header\\n+\\n+    Returns:\\n+        None\\n+    \"\"\"\\n+    driver.execute_script(open(f\"{FILE_DIR}/js/overlay.js\", \"r\").read())\\n</td>\n",
              "      <td>source</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>flask</td>\n",
              "      <td>NaN</td>\n",
              "      <td>actions/web_search.py</td>\n",
              "      <td>653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d</td>\n",
              "      <td>e983f3a0d3e45ced42c0d309244a17cebfba32f4</td>\n",
              "      <td>added all base files</td>\n",
              "      <td>@@ -0,0 +1,25 @@\\n+from __future__ import annotations\\n+import json\\n+from duckduckgo_search import DDGS\\n+\\n+ddgs = DDGS()\\n+\\n+def web_search(query: str, num_results: int = 5) -&gt; str:\\n+    \"\"\"Useful for general internet search queries.\"\"\"\\n+    print(\"Searching with query {0}...\".format(query))\\n+    search_results = []\\n+    if not query:\\n+        return json.dumps(search_results)\\n+\\n+    results = ddgs.text(query)\\n+    if not results:\\n+        return json.dumps(search_results)\\n+\\n+    total_added = 0\\n+    for j in results:\\n+        search_results.append(j)\\n+        total_added += 1\\n+        if total_added &gt;= num_results:\\n+            break\\n+\\n+    return json.dumps(search_results, ensure_ascii=False, indent=4)\\n</td>\n",
              "      <td>diff --git a/actions/web_search.py b/actions/web_search.py\\nnew file mode 100644\\nindex 00000000..7385c6ff\\n--- /dev/null\\n+++ b/actions/web_search.py\\n@@ -0,0 +1,25 @@\\n+from __future__ import annotations\\n+import json\\n+from duckduckgo_search import DDGS\\n+\\n+ddgs = DDGS()\\n+\\n+def web_search(query: str, num_results: int = 5) -&gt; str:\\n+    \"\"\"Useful for general internet search queries.\"\"\"\\n+    print(\"Searching with query {0}...\".format(query))\\n+    search_results = []\\n+    if not query:\\n+        return json.dumps(search_results)\\n+\\n+    results = ddgs.text(query)\\n+    if not results:\\n+        return json.dumps(search_results)\\n+\\n+    total_added = 0\\n+    for j in results:\\n+        search_results.append(j)\\n+        total_added += 1\\n+        if total_added &gt;= num_results:\\n+            break\\n+\\n+    return json.dumps(search_results, ensure_ascii=False, indent=4)\\n</td>\n",
              "      <td>source</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>flask</td>\n",
              "      <td>NaN</td>\n",
              "      <td>agent/prompts.py</td>\n",
              "      <td>653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d</td>\n",
              "      <td>e983f3a0d3e45ced42c0d309244a17cebfba32f4</td>\n",
              "      <td>added all base files</td>\n",
              "      <td>@@ -0,0 +1,16 @@\\n+AGENT_ROLE_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"\\n+\\n+def generate_agent_role_prompt():\\n+    return AGENT_ROLE_PROMPT\\n+\\n+def generate_report_prompt(question, research_summary):\\n+    return f'\"\"\"{research_summary}\"\"\" Using the above information, answer the following'\\\\n+           f' question or topic: \"{question}\" in a detailed report --'\\\\n+           \" The report should focus on the answer to the question, should be well structured, \" \\\\n+           \"informative, in depth, with facts and numbers if available, a minimum of 1,200 words and with markdown syntax. \"\\\\n+            \"Write all source urls at the end of the report, including urls that weren't used (explain why you didn't use them).\"\\n+\\n+def generate_search_queries_prompt(question):\\n+    return f'Write 4 google search queries to search online that form an objective opinion from the following: \"{question}\"'\\\\n+           f'You must respond with a list of strings in the following format: [\"query 1\", \"query 2\", \"query 3\", \"query 4\"]'\\n+\\n</td>\n",
              "      <td>diff --git a/agent/prompts.py b/agent/prompts.py\\nnew file mode 100644\\nindex 00000000..705c096e\\n--- /dev/null\\n+++ b/agent/prompts.py\\n@@ -0,0 +1,16 @@\\n+AGENT_ROLE_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"\\n+\\n+def generate_agent_role_prompt():\\n+    return AGENT_ROLE_PROMPT\\n+\\n+def generate_report_prompt(question, research_summary):\\n+    return f'\"\"\"{research_summary}\"\"\" Using the above information, answer the following'\\\\n+           f' question or topic: \"{question}\" in a detailed report --'\\\\n+           \" The report should focus on the answer to the question, should be well structured, \" \\\\n+           \"informative, in depth, with facts and numbers if available, a minimum of 1,200 words and with markdown syntax. \"\\\\n+            \"Write all source urls at the end of the report, including urls that weren't used (explain why you didn't use them).\"\\n+\\n+def generate_search_queries_prompt(question):\\n+    return f'Write 4 google search queries to search online that form an objective opinion from the following: \"{question}\"'\\\\n+           f'You must respond with a list of strings in the following format: [\"query 1\", \"query 2\", \"query 3\", \"query 4\"]'\\n+\\n</td>\n",
              "      <td>source</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>flask</td>\n",
              "      <td>NaN</td>\n",
              "      <td>agent/research_assistant.py</td>\n",
              "      <td>653e1ca15c9b6c1f4a0b4bd1df8fe7c1bde8054d</td>\n",
              "      <td>e983f3a0d3e45ced42c0d309244a17cebfba32f4</td>\n",
              "      <td>added all base files</td>\n",
              "      <td>@@ -0,0 +1,102 @@\\n+import asyncio\\n+import json\\n+from actions.web_search import web_search\\n+from actions.web_scrape import async_browse\\n+from processing.text import write_to_file, create_message, create_chat_completion, md_to_pdf, read_txt_files\\n+from config import Config\\n+from agent import prompts\\n+import os\\n+\\n+CFG = Config()\\n+\\n+\\n+class ResearchAssistant:\\n+    def __init__(self, question):\\n+        self.question = question\\n+        self.visited_urls = set()\\n+        self.research_summary = \"\"\\n+        self.directory_name = question[:100] if len(question) &gt; 100 else question\\n+        self.dir_path = os.path.dirname(f\"./outputs/{self.directory_name}/\")\\n+\\n+    def summarize(self, text, topic):\\n+        messages = [create_message(text, topic)]\\n+        print(\"Summarizing text for query: \", text)\\n+        return create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+\\n+    def get_new_urls(self, url_set_input):\\n+        new_urls = []\\n+        for url in url_set_input:\\n+            if url not in self.visited_urls:\\n+                print(\"New url found: \", url)\\n+                self.visited_urls.add(url)\\n+                new_urls.append(url)\\n+        return new_urls\\n+\\n+    def create_search_queries(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_search_queries_prompt(self.question),\\n+        }]\\n+        result = create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+        print(f\"Search queries: {result}\")\\n+        return json.loads(result)\\n+\\n+    def write_report(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_report_prompt(self.question, self.research_summary),\\n+        }]\\n+        print(f\"Writing report for query: {self.question}...\")\\n+        answer = create_chat_completion(\\n+            model=\"gpt-4\",\\n+            messages=messages,\\n+            stream=True,\\n+        )\\n+        file_path = f\"./outputs/{self.directory_name}/report\"\\n+        write_to_file(f\"{file_path}.md\", answer)\\n+        md_to_pdf(f\"{file_path}.md\", f\"{file_path}.pdf\")\\n+        print(f\"Report written to {file_path}.pdf\")\\n+        return answer\\n+\\n+    async def async_search(self, query):\\n+        search_results = json.loads(web_search(query))\\n+        new_search_urls = self.get_new_urls([url.get(\"href\") for url in search_results])\\n+        tasks = [asyncio.create_task(async_browse(url, query)) for url in new_search_urls]\\n+        print(\"Visited urls: \", self.visited_urls)\\n+        return await asyncio.gather(*tasks)\\n+\\n+    def run_search_summary(self, query):\\n+        print(f\"Running research for {query}...\")\\n+        loop = asyncio.get_event_loop()\\n+        responses = loop.run_until_complete(self.async_search(query))\\n+\\n+        result = \"\\n\".join(responses)\\n+        os.makedirs(os.path.dirname(f\"./outputs/{self.directory_name}/research-{query}.txt\"), exist_ok=True)\\n+        write_to_file(f\"./outputs/{self.directory_name}/research-{query}.txt\", result)\\n+        return result\\n+\\n+    def conduct_research(self):\\n+        self.research_summary = read_txt_files(self.dir_path) if os.path.isdir(self.dir_path) else \"\"\\n+\\n+        if not self.research_summary:\\n+            search_queries = self.create_search_queries()  # + [self.question]\\n+            for query in search_queries:\\n+                research_result = self.run_search_summary(query)  # summarize(run_search_summary(query), query)\\n+                self.research_summary += f\"{research_result}\\n\\n\"  # f\"{query}\\n{research_result}\\n\\n\"\\n+                print(\"Research summary so far: \", self.research_summary)\\n+\\n+        print(self.research_summary)\\n+        print(\"Total research words: {0}\".format(len(self.research_summary.split(\" \"))))\\n+        return self.research_summary\\n\\ No newline at end of file\\n</td>\n",
              "      <td>diff --git a/agent/research_assistant.py b/agent/research_assistant.py\\nnew file mode 100644\\nindex 00000000..32554db4\\n--- /dev/null\\n+++ b/agent/research_assistant.py\\n@@ -0,0 +1,102 @@\\n+import asyncio\\n+import json\\n+from actions.web_search import web_search\\n+from actions.web_scrape import async_browse\\n+from processing.text import write_to_file, create_message, create_chat_completion, md_to_pdf, read_txt_files\\n+from config import Config\\n+from agent import prompts\\n+import os\\n+\\n+CFG = Config()\\n+\\n+\\n+class ResearchAssistant:\\n+    def __init__(self, question):\\n+        self.question = question\\n+        self.visited_urls = set()\\n+        self.research_summary = \"\"\\n+        self.directory_name = question[:100] if len(question) &gt; 100 else question\\n+        self.dir_path = os.path.dirname(f\"./outputs/{self.directory_name}/\")\\n+\\n+    def summarize(self, text, topic):\\n+        messages = [create_message(text, topic)]\\n+        print(\"Summarizing text for query: \", text)\\n+        return create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+\\n+    def get_new_urls(self, url_set_input):\\n+        new_urls = []\\n+        for url in url_set_input:\\n+            if url not in self.visited_urls:\\n+                print(\"New url found: \", url)\\n+                self.visited_urls.add(url)\\n+                new_urls.append(url)\\n+        return new_urls\\n+\\n+    def create_search_queries(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_search_queries_prompt(self.question),\\n+        }]\\n+        result = create_chat_completion(\\n+            model=CFG.fast_llm_model,\\n+            messages=messages,\\n+        )\\n+        print(f\"Search queries: {result}\")\\n+        return json.loads(result)\\n+\\n+    def write_report(self):\\n+        messages = [{\\n+            \"role\": \"system\",\\n+            \"content\": prompts.generate_agent_role_prompt(),\\n+        }, {\\n+            \"role\": \"user\",\\n+            \"content\": prompts.generate_report_prompt(self.question, self.research_summary),\\n+        }]\\n+        print(f\"Writing report for query: {self.question}...\")\\n+        answer = create_chat_completion(\\n+            model=\"gpt-4\",\\n+            messages=messages,\\n+            stream=True,\\n+        )\\n+        file_path = f\"./outputs/{self.directory_name}/report\"\\n+        write_to_file(f\"{file_path}.md\", answer)\\n+        md_to_pdf(f\"{file_path}.md\", f\"{file_path}.pdf\")\\n+        print(f\"Report written to {file_path}.pdf\")\\n+        return answer\\n+\\n+    async def async_search(self, query):\\n+        search_results = json.loads(web_search(query))\\n+        new_search_urls = self.get_new_urls([url.get(\"href\") for url in search_results])\\n+        tasks = [asyncio.create_task(async_browse(url, query)) for url in new_search_urls]\\n+        print(\"Visited urls: \", self.visited_urls)\\n+        return await asyncio.gather(*tasks)\\n+\\n+    def run_search_summary(self, query):\\n+        print(f\"Running research for {query}...\")\\n+        loop = asyncio.get_event_loop()\\n+        responses = loop.run_until_complete(self.async_search(query))\\n+\\n+        result = \"\\n\".join(responses)\\n+        os.makedirs(os.path.dirname(f\"./outputs/{self.directory_name}/research-{query}.txt\"), exist_ok=True)\\n+        write_to_file(f\"./outputs/{self.directory_name}/research-{query}.txt\", result)\\n+        return result\\n+\\n+    def conduct_research(self):\\n+        self.research_summary = read_txt_files(self.dir_path) if os.path.isdir(self.dir_path) else \"\"\\n+\\n+        if not self.research_summary:\\n+            search_queries = self.create_search_queries()  # + [self.question]\\n+            for query in search_queries:\\n+                research_result = self.run_search_summary(query)  # summarize(run_search_summary(query), query)\\n+                self.research_summary += f\"{research_result}\\n\\n\"  # f\"{query}\\n{research_result}\\n\\n\"\\n+                print(\"Research summary so far: \", self.research_summary)\\n+\\n+        print(self.research_summary)\\n+        print(\"Total research words: {0}\".format(len(self.research_summary.split(\" \"))))\\n+        return self.research_summary\\n\\ No newline at end of file\\n</td>\n",
              "      <td>source</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45c72861-2c07-44e8-9e35-213ef2452014')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45c72861-2c07-44e8-9e35-213ef2452014 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45c72861-2c07-44e8-9e35-213ef2452014');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0a4c09a3-ed03-4649-8c4d-e2b4c36e03ca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a4c09a3-ed03-4649-8c4d-e2b4c36e03ca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0a4c09a3-ed03-4649-8c4d-e2b4c36e03ca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TLEUF9mtg9Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uLqrbaWYg9bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uE22kDMVg9es"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}